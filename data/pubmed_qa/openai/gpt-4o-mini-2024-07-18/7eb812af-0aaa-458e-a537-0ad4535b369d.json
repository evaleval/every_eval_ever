{
    "schema_version": "0.2.0",
    "evaluation_id": "pubmed_qa/openai_azure_gpt-4o-mini-2024-07-18/1751553870.0",
    "evaluation_timestamp": "1751553870.0",
    "retrieved_timestamp": "1770603901.646302",
    "source_metadata": {
        "source_name": "inspect_ai",
        "source_type": "evaluation_run",
        "source_organization_name": "unknown",
        "evaluator_relationship": "third_party"
    },
    "model_info": {
        "name": "openai/azure/gpt-4o-mini-2024-07-18",
        "id": "openai/gpt-4o-mini-2024-07-18",
        "developer": "openai",
        "inference_platform": "azure"
    },
    "evaluation_results": [
        {
            "evaluation_name": "choice",
            "source_data": {
                "source_type": "hf_dataset",
                "dataset_name": "pubmed_qa",
                "hf_repo": "bigbio/pubmed_qa",
                "samples_number": 500,
                "sample_ids": [
                    "12377809",
                    "26163474"
                ],
                "additional_details": {
                    "shuffled": false
                }
            },
            "evaluation_timestamp": "1751553870.0",
            "metric_config": {
                "evaluation_description": "accuracy",
                "lower_is_better": false,
                "score_type": "continuous",
                "min_score": 0.0,
                "max_score": 1.0
            },
            "score_details": {
                "score": 1.0,
                "confidence_interval": {
                    "lower": 1.0,
                    "upper": 1.0
                }
            },
            "generation_config": {
                "generation_args": {
                    "reasoning": false,
                    "agentic_eval_config": {
                        "available_tools": []
                    },
                    "eval_plan": {
                        "name": "plan",
                        "steps": [
                            {
                                "solver": "multiple_choice",
                                "params": {
                                    "template": "Answer the following multiple choice question about medical knowledge given the context.\nThe entire content of your response should be of the following format: 'ANSWER: $LETTER'\n(without quotes) where LETTER is one of {letters}.\n\n{question}\n\n{choices}"
                                },
                                "params_passed": {
                                    "template": "Answer the following multiple choice question about medical knowledge given the context.\nThe entire content of your response should be of the following format: 'ANSWER: $LETTER'\n(without quotes) where LETTER is one of {letters}.\n\n{question}\n\n{choices}"
                                }
                            }
                        ],
                        "config": {}
                    },
                    "eval_limits": {},
                    "sandbox": {}
                },
                "additional_details": {}
            }
        }
    ],
    "detailed_evaluation_results": {
        "format": "jsonl",
        "file_path": "instance_level_data/pubmed_qa_openai_azure_gpt-4o-mini-2024-07-18_1751553870.jsonl",
        "hash_algorithm": "sha256",
        "checksum": "f571fa273f61a616dfab785daa0870e57e602064d5e792bd509bbcf059e0d497",
        "total_rows": 2
    }
}