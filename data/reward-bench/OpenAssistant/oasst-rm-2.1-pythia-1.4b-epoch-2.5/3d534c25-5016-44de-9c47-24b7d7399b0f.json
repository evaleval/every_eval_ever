{
  "schema_version": "0.1.0",
  "evaluation_id": "reward-bench-2/OpenAssistant_oasst-rm-2.1-pythia-1.4b-epoch-2.5/1766412838.146816",
  "retrieved_timestamp": "1766412838.146816",
  "source_data": [
    "https://huggingface.co/datasets/allenai/reward-bench-2-results"
  ],
  "source_metadata": {
    "source_name": "RewardBench 2",
    "source_type": "documentation",
    "source_organization_name": "Allen Institute for AI",
    "source_organization_url": "https://allenai.org",
    "evaluator_relationship": "third_party"
  },
  "model_info": {
    "name": "OpenAssistant/oasst-rm-2.1-pythia-1.4b-epoch-2.5",
    "id": "OpenAssistant/oasst-rm-2.1-pythia-1.4b-epoch-2.5",
    "developer": "OpenAssistant",
    "additional_details": {
      "model_type": "Seq. Classifier"
    }
  },
  "evaluation_results": [
    {
      "evaluation_name": "Score",
      "metric_config": {
        "evaluation_description": "Overall RewardBench 2 Score (mean of all metrics)",
        "lower_is_better": false,
        "score_type": "continuous",
        "min_score": 0.0,
        "max_score": 1.0
      },
      "score_details": {
        "score": 0.2648
      }
    },
    {
      "evaluation_name": "Factuality",
      "metric_config": {
        "evaluation_description": "Factuality score - measures factual accuracy",
        "lower_is_better": false,
        "score_type": "continuous",
        "min_score": 0.0,
        "max_score": 1.0
      },
      "score_details": {
        "score": 0.3179
      }
    },
    {
      "evaluation_name": "Precise IF",
      "metric_config": {
        "evaluation_description": "Precise Instruction Following score",
        "lower_is_better": false,
        "score_type": "continuous",
        "min_score": 0.0,
        "max_score": 1.0
      },
      "score_details": {
        "score": 0.2625
      }
    },
    {
      "evaluation_name": "Math",
      "metric_config": {
        "evaluation_description": "Math score - measures mathematical reasoning",
        "lower_is_better": false,
        "score_type": "continuous",
        "min_score": 0.0,
        "max_score": 1.0
      },
      "score_details": {
        "score": 0.3934
      }
    },
    {
      "evaluation_name": "Safety",
      "metric_config": {
        "evaluation_description": "Safety score - measures safety awareness",
        "lower_is_better": false,
        "score_type": "continuous",
        "min_score": 0.0,
        "max_score": 1.0
      },
      "score_details": {
        "score": 0.3244
      }
    },
    {
      "evaluation_name": "Focus",
      "metric_config": {
        "evaluation_description": "Focus score - measures response focus",
        "lower_is_better": false,
        "score_type": "continuous",
        "min_score": 0.0,
        "max_score": 1.0
      },
      "score_details": {
        "score": 0.2707
      }
    },
    {
      "evaluation_name": "Ties",
      "metric_config": {
        "evaluation_description": "Ties score - ability to identify tie cases",
        "lower_is_better": false,
        "score_type": "continuous",
        "min_score": 0.0,
        "max_score": 1.0
      },
      "score_details": {
        "score": 0.0198
      }
    }
  ]
}