{
  "schema_version": "0.1.0",
  "evaluation_id": "helm/openai/gpt2/narrativeqa/1763479296",
  "retrieved_timestamp": "1763479296",
  "source_data": {
    "dataset_name": "narrativeqa",
    "hf_repo": null,
    "hf_split": null,
    "samples_number": 5,
    "sample_ids": [
      "id1413",
      "id1332",
      "id1123",
      "id1514",
      "id1340"
    ],
    "additional_details": {
      "scenario_name": "helm.benchmark.scenarios.narrativeqa_scenario.NarrativeQAScenario",
      "scenario_args": {}
    }
  },
  "source_metadata": {
    "source_name": "helm",
    "source_type": "evaluation_run",
    "source_organization_name": "Unknown",
    "source_organization_url": null,
    "source_organization_logo_url": null,
    "evaluator_relationship": "other"
  },
  "model_info": {
    "name": "openai/gpt2",
    "id": "openai/gpt2",
    "developer": "openai",
    "inference_platform": "huggingface",
    "inference_engine": null,
    "additional_details": null
  },
  "evaluation_results": [
    {
      "evaluation_name": "generation",
      "evaluation_timestamp": "1763479296",
      "metric_config": {
        "evaluation_description": "exact_match",
        "lower_is_better": false,
        "score_type": null,
        "level_names": null,
        "level_metadata": null,
        "has_unknown_level": null,
        "min_score": null,
        "max_score": null
      },
      "score_details": {
        "score": 0.0,
        "details": {
          "count": 1,
          "sum": 0.0,
          "sum_squared": 0.0,
          "min": 0.0,
          "max": 0.0,
          "mean": 0.0,
          "variance": 0.0,
          "stddev": 0.0,
          "split": "test",
          "perturbation": null
        }
      },
      "detailed_evaluation_results_url": null,
      "generation_config": {
        "temperature": 0.0,
        "max_tokens": 100,
        "stop_sequences": [
          "\n"
        ],
        "instructions": "",
        "input_prefix": "Passage: ",
        "input_suffix": "\n",
        "output_prefix": "Answer: ",
        "output_suffix": "\n",
        "instance_prefix": "\n"
      }
    },
    {
      "evaluation_name": "generation",
      "evaluation_timestamp": "1763479296",
      "metric_config": {
        "evaluation_description": "exact_match",
        "lower_is_better": false,
        "score_type": null,
        "level_names": null,
        "level_metadata": null,
        "has_unknown_level": null,
        "min_score": null,
        "max_score": null
      },
      "score_details": {
        "score": 0.0,
        "details": {
          "count": 1,
          "sum": 0.0,
          "sum_squared": 0.0,
          "min": 0.0,
          "max": 0.0,
          "mean": 0.0,
          "variance": 0.0,
          "stddev": 0.0,
          "split": "valid",
          "perturbation": null
        }
      },
      "detailed_evaluation_results_url": null,
      "generation_config": {
        "temperature": 0.0,
        "max_tokens": 100,
        "stop_sequences": [
          "\n"
        ],
        "instructions": "",
        "input_prefix": "Passage: ",
        "input_suffix": "\n",
        "output_prefix": "Answer: ",
        "output_suffix": "\n",
        "instance_prefix": "\n"
      }
    },
    {
      "evaluation_name": "generation",
      "evaluation_timestamp": "1763479296",
      "metric_config": {
        "evaluation_description": "exact_match",
        "lower_is_better": false,
        "score_type": null,
        "level_names": null,
        "level_metadata": null,
        "has_unknown_level": null,
        "min_score": null,
        "max_score": null
      },
      "score_details": {
        "score": 0.0,
        "details": {
          "count": 1,
          "sum": 0.0,
          "sum_squared": 0.0,
          "min": 0.0,
          "max": 0.0,
          "mean": 0.0,
          "variance": 0.0,
          "stddev": 0.0,
          "split": "test",
          "perturbation": {
            "name": "robustness",
            "robustness": true,
            "fairness": false,
            "computed_on": "worst",
            "seed": null
          }
        }
      },
      "detailed_evaluation_results_url": null,
      "generation_config": {
        "temperature": 0.0,
        "max_tokens": 100,
        "stop_sequences": [
          "\n"
        ],
        "instructions": "",
        "input_prefix": "Passage: ",
        "input_suffix": "\n",
        "output_prefix": "Answer: ",
        "output_suffix": "\n",
        "instance_prefix": "\n"
      }
    },
    {
      "evaluation_name": "generation",
      "evaluation_timestamp": "1763479296",
      "metric_config": {
        "evaluation_description": "exact_match",
        "lower_is_better": false,
        "score_type": null,
        "level_names": null,
        "level_metadata": null,
        "has_unknown_level": null,
        "min_score": null,
        "max_score": null
      },
      "score_details": {
        "score": 0.0,
        "details": {
          "count": 1,
          "sum": 0.0,
          "sum_squared": 0.0,
          "min": 0.0,
          "max": 0.0,
          "mean": 0.0,
          "variance": 0.0,
          "stddev": 0.0,
          "split": "test",
          "perturbation": {
            "name": "fairness",
            "robustness": false,
            "fairness": true,
            "computed_on": "worst",
            "seed": null
          }
        }
      },
      "detailed_evaluation_results_url": null,
      "generation_config": {
        "temperature": 0.0,
        "max_tokens": 100,
        "stop_sequences": [
          "\n"
        ],
        "instructions": "",
        "input_prefix": "Passage: ",
        "input_suffix": "\n",
        "output_prefix": "Answer: ",
        "output_suffix": "\n",
        "instance_prefix": "\n"
      }
    },
    {
      "evaluation_name": "generation",
      "evaluation_timestamp": "1763479296",
      "metric_config": {
        "evaluation_description": "exact_match",
        "lower_is_better": false,
        "score_type": null,
        "level_names": null,
        "level_metadata": null,
        "has_unknown_level": null,
        "min_score": null,
        "max_score": null
      },
      "score_details": {
        "score": 0.0,
        "details": {
          "count": 1,
          "sum": 0.0,
          "sum_squared": 0.0,
          "min": 0.0,
          "max": 0.0,
          "mean": 0.0,
          "variance": 0.0,
          "stddev": 0.0,
          "split": "valid",
          "perturbation": {
            "name": "robustness",
            "robustness": true,
            "fairness": false,
            "computed_on": "worst",
            "seed": null
          }
        }
      },
      "detailed_evaluation_results_url": null,
      "generation_config": {
        "temperature": 0.0,
        "max_tokens": 100,
        "stop_sequences": [
          "\n"
        ],
        "instructions": "",
        "input_prefix": "Passage: ",
        "input_suffix": "\n",
        "output_prefix": "Answer: ",
        "output_suffix": "\n",
        "instance_prefix": "\n"
      }
    },
    {
      "evaluation_name": "generation",
      "evaluation_timestamp": "1763479296",
      "metric_config": {
        "evaluation_description": "exact_match",
        "lower_is_better": false,
        "score_type": null,
        "level_names": null,
        "level_metadata": null,
        "has_unknown_level": null,
        "min_score": null,
        "max_score": null
      },
      "score_details": {
        "score": 0.0,
        "details": {
          "count": 1,
          "sum": 0.0,
          "sum_squared": 0.0,
          "min": 0.0,
          "max": 0.0,
          "mean": 0.0,
          "variance": 0.0,
          "stddev": 0.0,
          "split": "valid",
          "perturbation": {
            "name": "fairness",
            "robustness": false,
            "fairness": true,
            "computed_on": "worst",
            "seed": null
          }
        }
      },
      "detailed_evaluation_results_url": null,
      "generation_config": {
        "temperature": 0.0,
        "max_tokens": 100,
        "stop_sequences": [
          "\n"
        ],
        "instructions": "",
        "input_prefix": "Passage: ",
        "input_suffix": "\n",
        "output_prefix": "Answer: ",
        "output_suffix": "\n",
        "instance_prefix": "\n"
      }
    },
    {
      "evaluation_name": "generation",
      "evaluation_timestamp": "1763479296",
      "metric_config": {
        "evaluation_description": "quasi_exact_match",
        "lower_is_better": false,
        "score_type": null,
        "level_names": null,
        "level_metadata": null,
        "has_unknown_level": null,
        "min_score": null,
        "max_score": null
      },
      "score_details": {
        "score": 0.0,
        "details": {
          "count": 1,
          "sum": 0.0,
          "sum_squared": 0.0,
          "min": 0.0,
          "max": 0.0,
          "mean": 0.0,
          "variance": 0.0,
          "stddev": 0.0,
          "split": "test",
          "perturbation": null
        }
      },
      "detailed_evaluation_results_url": null,
      "generation_config": {
        "temperature": 0.0,
        "max_tokens": 100,
        "stop_sequences": [
          "\n"
        ],
        "instructions": "",
        "input_prefix": "Passage: ",
        "input_suffix": "\n",
        "output_prefix": "Answer: ",
        "output_suffix": "\n",
        "instance_prefix": "\n"
      }
    },
    {
      "evaluation_name": "generation",
      "evaluation_timestamp": "1763479296",
      "metric_config": {
        "evaluation_description": "quasi_exact_match",
        "lower_is_better": false,
        "score_type": null,
        "level_names": null,
        "level_metadata": null,
        "has_unknown_level": null,
        "min_score": null,
        "max_score": null
      },
      "score_details": {
        "score": 0.0,
        "details": {
          "count": 1,
          "sum": 0.0,
          "sum_squared": 0.0,
          "min": 0.0,
          "max": 0.0,
          "mean": 0.0,
          "variance": 0.0,
          "stddev": 0.0,
          "split": "valid",
          "perturbation": null
        }
      },
      "detailed_evaluation_results_url": null,
      "generation_config": {
        "temperature": 0.0,
        "max_tokens": 100,
        "stop_sequences": [
          "\n"
        ],
        "instructions": "",
        "input_prefix": "Passage: ",
        "input_suffix": "\n",
        "output_prefix": "Answer: ",
        "output_suffix": "\n",
        "instance_prefix": "\n"
      }
    },
    {
      "evaluation_name": "generation",
      "evaluation_timestamp": "1763479296",
      "metric_config": {
        "evaluation_description": "quasi_exact_match",
        "lower_is_better": false,
        "score_type": null,
        "level_names": null,
        "level_metadata": null,
        "has_unknown_level": null,
        "min_score": null,
        "max_score": null
      },
      "score_details": {
        "score": 0.0,
        "details": {
          "count": 1,
          "sum": 0.0,
          "sum_squared": 0.0,
          "min": 0.0,
          "max": 0.0,
          "mean": 0.0,
          "variance": 0.0,
          "stddev": 0.0,
          "split": "test",
          "perturbation": {
            "name": "robustness",
            "robustness": true,
            "fairness": false,
            "computed_on": "worst",
            "seed": null
          }
        }
      },
      "detailed_evaluation_results_url": null,
      "generation_config": {
        "temperature": 0.0,
        "max_tokens": 100,
        "stop_sequences": [
          "\n"
        ],
        "instructions": "",
        "input_prefix": "Passage: ",
        "input_suffix": "\n",
        "output_prefix": "Answer: ",
        "output_suffix": "\n",
        "instance_prefix": "\n"
      }
    },
    {
      "evaluation_name": "generation",
      "evaluation_timestamp": "1763479296",
      "metric_config": {
        "evaluation_description": "quasi_exact_match",
        "lower_is_better": false,
        "score_type": null,
        "level_names": null,
        "level_metadata": null,
        "has_unknown_level": null,
        "min_score": null,
        "max_score": null
      },
      "score_details": {
        "score": 0.0,
        "details": {
          "count": 1,
          "sum": 0.0,
          "sum_squared": 0.0,
          "min": 0.0,
          "max": 0.0,
          "mean": 0.0,
          "variance": 0.0,
          "stddev": 0.0,
          "split": "test",
          "perturbation": {
            "name": "fairness",
            "robustness": false,
            "fairness": true,
            "computed_on": "worst",
            "seed": null
          }
        }
      },
      "detailed_evaluation_results_url": null,
      "generation_config": {
        "temperature": 0.0,
        "max_tokens": 100,
        "stop_sequences": [
          "\n"
        ],
        "instructions": "",
        "input_prefix": "Passage: ",
        "input_suffix": "\n",
        "output_prefix": "Answer: ",
        "output_suffix": "\n",
        "instance_prefix": "\n"
      }
    },
    {
      "evaluation_name": "generation",
      "evaluation_timestamp": "1763479296",
      "metric_config": {
        "evaluation_description": "quasi_exact_match",
        "lower_is_better": false,
        "score_type": null,
        "level_names": null,
        "level_metadata": null,
        "has_unknown_level": null,
        "min_score": null,
        "max_score": null
      },
      "score_details": {
        "score": 0.0,
        "details": {
          "count": 1,
          "sum": 0.0,
          "sum_squared": 0.0,
          "min": 0.0,
          "max": 0.0,
          "mean": 0.0,
          "variance": 0.0,
          "stddev": 0.0,
          "split": "valid",
          "perturbation": {
            "name": "robustness",
            "robustness": true,
            "fairness": false,
            "computed_on": "worst",
            "seed": null
          }
        }
      },
      "detailed_evaluation_results_url": null,
      "generation_config": {
        "temperature": 0.0,
        "max_tokens": 100,
        "stop_sequences": [
          "\n"
        ],
        "instructions": "",
        "input_prefix": "Passage: ",
        "input_suffix": "\n",
        "output_prefix": "Answer: ",
        "output_suffix": "\n",
        "instance_prefix": "\n"
      }
    },
    {
      "evaluation_name": "generation",
      "evaluation_timestamp": "1763479296",
      "metric_config": {
        "evaluation_description": "quasi_exact_match",
        "lower_is_better": false,
        "score_type": null,
        "level_names": null,
        "level_metadata": null,
        "has_unknown_level": null,
        "min_score": null,
        "max_score": null
      },
      "score_details": {
        "score": 0.0,
        "details": {
          "count": 1,
          "sum": 0.0,
          "sum_squared": 0.0,
          "min": 0.0,
          "max": 0.0,
          "mean": 0.0,
          "variance": 0.0,
          "stddev": 0.0,
          "split": "valid",
          "perturbation": {
            "name": "fairness",
            "robustness": false,
            "fairness": true,
            "computed_on": "worst",
            "seed": null
          }
        }
      },
      "detailed_evaluation_results_url": null,
      "generation_config": {
        "temperature": 0.0,
        "max_tokens": 100,
        "stop_sequences": [
          "\n"
        ],
        "instructions": "",
        "input_prefix": "Passage: ",
        "input_suffix": "\n",
        "output_prefix": "Answer: ",
        "output_suffix": "\n",
        "instance_prefix": "\n"
      }
    },
    {
      "evaluation_name": "generation",
      "evaluation_timestamp": "1763479296",
      "metric_config": {
        "evaluation_description": "f1_score",
        "lower_is_better": false,
        "score_type": null,
        "level_names": null,
        "level_metadata": null,
        "has_unknown_level": null,
        "min_score": null,
        "max_score": null
      },
      "score_details": {
        "score": 0.17424242424242425,
        "details": {
          "count": 1,
          "sum": 0.17424242424242425,
          "sum_squared": 0.030360422405876955,
          "min": 0.17424242424242425,
          "max": 0.17424242424242425,
          "mean": 0.17424242424242425,
          "variance": 0.0,
          "stddev": 0.0,
          "split": "test",
          "perturbation": null
        }
      },
      "detailed_evaluation_results_url": null,
      "generation_config": {
        "temperature": 0.0,
        "max_tokens": 100,
        "stop_sequences": [
          "\n"
        ],
        "instructions": "",
        "input_prefix": "Passage: ",
        "input_suffix": "\n",
        "output_prefix": "Answer: ",
        "output_suffix": "\n",
        "instance_prefix": "\n"
      }
    },
    {
      "evaluation_name": "generation",
      "evaluation_timestamp": "1763479296",
      "metric_config": {
        "evaluation_description": "f1_score",
        "lower_is_better": false,
        "score_type": null,
        "level_names": null,
        "level_metadata": null,
        "has_unknown_level": null,
        "min_score": null,
        "max_score": null
      },
      "score_details": {
        "score": 0.0,
        "details": {
          "count": 1,
          "sum": 0.0,
          "sum_squared": 0.0,
          "min": 0.0,
          "max": 0.0,
          "mean": 0.0,
          "variance": 0.0,
          "stddev": 0.0,
          "split": "valid",
          "perturbation": null
        }
      },
      "detailed_evaluation_results_url": null,
      "generation_config": {
        "temperature": 0.0,
        "max_tokens": 100,
        "stop_sequences": [
          "\n"
        ],
        "instructions": "",
        "input_prefix": "Passage: ",
        "input_suffix": "\n",
        "output_prefix": "Answer: ",
        "output_suffix": "\n",
        "instance_prefix": "\n"
      }
    },
    {
      "evaluation_name": "generation",
      "evaluation_timestamp": "1763479296",
      "metric_config": {
        "evaluation_description": "f1_score",
        "lower_is_better": false,
        "score_type": null,
        "level_names": null,
        "level_metadata": null,
        "has_unknown_level": null,
        "min_score": null,
        "max_score": null
      },
      "score_details": {
        "score": 0.17424242424242425,
        "details": {
          "count": 1,
          "sum": 0.17424242424242425,
          "sum_squared": 0.030360422405876955,
          "min": 0.17424242424242425,
          "max": 0.17424242424242425,
          "mean": 0.17424242424242425,
          "variance": 0.0,
          "stddev": 0.0,
          "split": "test",
          "perturbation": {
            "name": "robustness",
            "robustness": true,
            "fairness": false,
            "computed_on": "worst",
            "seed": null
          }
        }
      },
      "detailed_evaluation_results_url": null,
      "generation_config": {
        "temperature": 0.0,
        "max_tokens": 100,
        "stop_sequences": [
          "\n"
        ],
        "instructions": "",
        "input_prefix": "Passage: ",
        "input_suffix": "\n",
        "output_prefix": "Answer: ",
        "output_suffix": "\n",
        "instance_prefix": "\n"
      }
    },
    {
      "evaluation_name": "generation",
      "evaluation_timestamp": "1763479296",
      "metric_config": {
        "evaluation_description": "f1_score",
        "lower_is_better": false,
        "score_type": null,
        "level_names": null,
        "level_metadata": null,
        "has_unknown_level": null,
        "min_score": null,
        "max_score": null
      },
      "score_details": {
        "score": 0.17424242424242425,
        "details": {
          "count": 1,
          "sum": 0.17424242424242425,
          "sum_squared": 0.030360422405876955,
          "min": 0.17424242424242425,
          "max": 0.17424242424242425,
          "mean": 0.17424242424242425,
          "variance": 0.0,
          "stddev": 0.0,
          "split": "test",
          "perturbation": {
            "name": "fairness",
            "robustness": false,
            "fairness": true,
            "computed_on": "worst",
            "seed": null
          }
        }
      },
      "detailed_evaluation_results_url": null,
      "generation_config": {
        "temperature": 0.0,
        "max_tokens": 100,
        "stop_sequences": [
          "\n"
        ],
        "instructions": "",
        "input_prefix": "Passage: ",
        "input_suffix": "\n",
        "output_prefix": "Answer: ",
        "output_suffix": "\n",
        "instance_prefix": "\n"
      }
    },
    {
      "evaluation_name": "generation",
      "evaluation_timestamp": "1763479296",
      "metric_config": {
        "evaluation_description": "f1_score",
        "lower_is_better": false,
        "score_type": null,
        "level_names": null,
        "level_metadata": null,
        "has_unknown_level": null,
        "min_score": null,
        "max_score": null
      },
      "score_details": {
        "score": 0.0,
        "details": {
          "count": 1,
          "sum": 0.0,
          "sum_squared": 0.0,
          "min": 0.0,
          "max": 0.0,
          "mean": 0.0,
          "variance": 0.0,
          "stddev": 0.0,
          "split": "valid",
          "perturbation": {
            "name": "robustness",
            "robustness": true,
            "fairness": false,
            "computed_on": "worst",
            "seed": null
          }
        }
      },
      "detailed_evaluation_results_url": null,
      "generation_config": {
        "temperature": 0.0,
        "max_tokens": 100,
        "stop_sequences": [
          "\n"
        ],
        "instructions": "",
        "input_prefix": "Passage: ",
        "input_suffix": "\n",
        "output_prefix": "Answer: ",
        "output_suffix": "\n",
        "instance_prefix": "\n"
      }
    },
    {
      "evaluation_name": "generation",
      "evaluation_timestamp": "1763479296",
      "metric_config": {
        "evaluation_description": "f1_score",
        "lower_is_better": false,
        "score_type": null,
        "level_names": null,
        "level_metadata": null,
        "has_unknown_level": null,
        "min_score": null,
        "max_score": null
      },
      "score_details": {
        "score": 0.0,
        "details": {
          "count": 1,
          "sum": 0.0,
          "sum_squared": 0.0,
          "min": 0.0,
          "max": 0.0,
          "mean": 0.0,
          "variance": 0.0,
          "stddev": 0.0,
          "split": "valid",
          "perturbation": {
            "name": "fairness",
            "robustness": false,
            "fairness": true,
            "computed_on": "worst",
            "seed": null
          }
        }
      },
      "detailed_evaluation_results_url": null,
      "generation_config": {
        "temperature": 0.0,
        "max_tokens": 100,
        "stop_sequences": [
          "\n"
        ],
        "instructions": "",
        "input_prefix": "Passage: ",
        "input_suffix": "\n",
        "output_prefix": "Answer: ",
        "output_suffix": "\n",
        "instance_prefix": "\n"
      }
    },
    {
      "evaluation_name": "generation",
      "evaluation_timestamp": "1763479296",
      "metric_config": {
        "evaluation_description": "rouge_l",
        "lower_is_better": false,
        "score_type": null,
        "level_names": null,
        "level_metadata": null,
        "has_unknown_level": null,
        "min_score": null,
        "max_score": null
      },
      "score_details": {
        "score": 0.05365510777881912,
        "details": {
          "count": 1,
          "sum": 0.05365510777881912,
          "sum_squared": 0.002878870590756696,
          "min": 0.05365510777881912,
          "max": 0.05365510777881912,
          "mean": 0.05365510777881912,
          "variance": 0.0,
          "stddev": 0.0,
          "split": "test",
          "perturbation": null
        }
      },
      "detailed_evaluation_results_url": null,
      "generation_config": {
        "temperature": 0.0,
        "max_tokens": 100,
        "stop_sequences": [
          "\n"
        ],
        "instructions": "",
        "input_prefix": "Passage: ",
        "input_suffix": "\n",
        "output_prefix": "Answer: ",
        "output_suffix": "\n",
        "instance_prefix": "\n"
      }
    },
    {
      "evaluation_name": "generation",
      "evaluation_timestamp": "1763479296",
      "metric_config": {
        "evaluation_description": "rouge_l",
        "lower_is_better": false,
        "score_type": null,
        "level_names": null,
        "level_metadata": null,
        "has_unknown_level": null,
        "min_score": null,
        "max_score": null
      },
      "score_details": {
        "score": 0.03636363636363636,
        "details": {
          "count": 1,
          "sum": 0.03636363636363636,
          "sum_squared": 0.0013223140495867767,
          "min": 0.03636363636363636,
          "max": 0.03636363636363636,
          "mean": 0.03636363636363636,
          "variance": 0.0,
          "stddev": 0.0,
          "split": "valid",
          "perturbation": null
        }
      },
      "detailed_evaluation_results_url": null,
      "generation_config": {
        "temperature": 0.0,
        "max_tokens": 100,
        "stop_sequences": [
          "\n"
        ],
        "instructions": "",
        "input_prefix": "Passage: ",
        "input_suffix": "\n",
        "output_prefix": "Answer: ",
        "output_suffix": "\n",
        "instance_prefix": "\n"
      }
    },
    {
      "evaluation_name": "generation",
      "evaluation_timestamp": "1763479296",
      "metric_config": {
        "evaluation_description": "rouge_l",
        "lower_is_better": false,
        "score_type": null,
        "level_names": null,
        "level_metadata": null,
        "has_unknown_level": null,
        "min_score": null,
        "max_score": null
      },
      "score_details": {
        "score": 0.05365510777881912,
        "details": {
          "count": 1,
          "sum": 0.05365510777881912,
          "sum_squared": 0.002878870590756696,
          "min": 0.05365510777881912,
          "max": 0.05365510777881912,
          "mean": 0.05365510777881912,
          "variance": 0.0,
          "stddev": 0.0,
          "split": "test",
          "perturbation": {
            "name": "robustness",
            "robustness": true,
            "fairness": false,
            "computed_on": "worst",
            "seed": null
          }
        }
      },
      "detailed_evaluation_results_url": null,
      "generation_config": {
        "temperature": 0.0,
        "max_tokens": 100,
        "stop_sequences": [
          "\n"
        ],
        "instructions": "",
        "input_prefix": "Passage: ",
        "input_suffix": "\n",
        "output_prefix": "Answer: ",
        "output_suffix": "\n",
        "instance_prefix": "\n"
      }
    },
    {
      "evaluation_name": "generation",
      "evaluation_timestamp": "1763479296",
      "metric_config": {
        "evaluation_description": "rouge_l",
        "lower_is_better": false,
        "score_type": null,
        "level_names": null,
        "level_metadata": null,
        "has_unknown_level": null,
        "min_score": null,
        "max_score": null
      },
      "score_details": {
        "score": 0.05365510777881912,
        "details": {
          "count": 1,
          "sum": 0.05365510777881912,
          "sum_squared": 0.002878870590756696,
          "min": 0.05365510777881912,
          "max": 0.05365510777881912,
          "mean": 0.05365510777881912,
          "variance": 0.0,
          "stddev": 0.0,
          "split": "test",
          "perturbation": {
            "name": "fairness",
            "robustness": false,
            "fairness": true,
            "computed_on": "worst",
            "seed": null
          }
        }
      },
      "detailed_evaluation_results_url": null,
      "generation_config": {
        "temperature": 0.0,
        "max_tokens": 100,
        "stop_sequences": [
          "\n"
        ],
        "instructions": "",
        "input_prefix": "Passage: ",
        "input_suffix": "\n",
        "output_prefix": "Answer: ",
        "output_suffix": "\n",
        "instance_prefix": "\n"
      }
    },
    {
      "evaluation_name": "generation",
      "evaluation_timestamp": "1763479296",
      "metric_config": {
        "evaluation_description": "rouge_l",
        "lower_is_better": false,
        "score_type": null,
        "level_names": null,
        "level_metadata": null,
        "has_unknown_level": null,
        "min_score": null,
        "max_score": null
      },
      "score_details": {
        "score": 0.03636363636363636,
        "details": {
          "count": 1,
          "sum": 0.03636363636363636,
          "sum_squared": 0.0013223140495867767,
          "min": 0.03636363636363636,
          "max": 0.03636363636363636,
          "mean": 0.03636363636363636,
          "variance": 0.0,
          "stddev": 0.0,
          "split": "valid",
          "perturbation": {
            "name": "robustness",
            "robustness": true,
            "fairness": false,
            "computed_on": "worst",
            "seed": null
          }
        }
      },
      "detailed_evaluation_results_url": null,
      "generation_config": {
        "temperature": 0.0,
        "max_tokens": 100,
        "stop_sequences": [
          "\n"
        ],
        "instructions": "",
        "input_prefix": "Passage: ",
        "input_suffix": "\n",
        "output_prefix": "Answer: ",
        "output_suffix": "\n",
        "instance_prefix": "\n"
      }
    },
    {
      "evaluation_name": "generation",
      "evaluation_timestamp": "1763479296",
      "metric_config": {
        "evaluation_description": "rouge_l",
        "lower_is_better": false,
        "score_type": null,
        "level_names": null,
        "level_metadata": null,
        "has_unknown_level": null,
        "min_score": null,
        "max_score": null
      },
      "score_details": {
        "score": 0.03636363636363636,
        "details": {
          "count": 1,
          "sum": 0.03636363636363636,
          "sum_squared": 0.0013223140495867767,
          "min": 0.03636363636363636,
          "max": 0.03636363636363636,
          "mean": 0.03636363636363636,
          "variance": 0.0,
          "stddev": 0.0,
          "split": "valid",
          "perturbation": {
            "name": "fairness",
            "robustness": false,
            "fairness": true,
            "computed_on": "worst",
            "seed": null
          }
        }
      },
      "detailed_evaluation_results_url": null,
      "generation_config": {
        "temperature": 0.0,
        "max_tokens": 100,
        "stop_sequences": [
          "\n"
        ],
        "instructions": "",
        "input_prefix": "Passage: ",
        "input_suffix": "\n",
        "output_prefix": "Answer: ",
        "output_suffix": "\n",
        "instance_prefix": "\n"
      }
    },
    {
      "evaluation_name": "generation",
      "evaluation_timestamp": "1763479296",
      "metric_config": {
        "evaluation_description": "bleu_1",
        "lower_is_better": false,
        "score_type": null,
        "level_names": null,
        "level_metadata": null,
        "has_unknown_level": null,
        "min_score": null,
        "max_score": null
      },
      "score_details": {
        "score": 0.03568840579710145,
        "details": {
          "count": 1,
          "sum": 0.03568840579710145,
          "sum_squared": 0.001273662308338584,
          "min": 0.03568840579710145,
          "max": 0.03568840579710145,
          "mean": 0.03568840579710145,
          "variance": 0.0,
          "stddev": 0.0,
          "split": "test",
          "perturbation": null
        }
      },
      "detailed_evaluation_results_url": null,
      "generation_config": {
        "temperature": 0.0,
        "max_tokens": 100,
        "stop_sequences": [
          "\n"
        ],
        "instructions": "",
        "input_prefix": "Passage: ",
        "input_suffix": "\n",
        "output_prefix": "Answer: ",
        "output_suffix": "\n",
        "instance_prefix": "\n"
      }
    },
    {
      "evaluation_name": "generation",
      "evaluation_timestamp": "1763479296",
      "metric_config": {
        "evaluation_description": "bleu_1",
        "lower_is_better": false,
        "score_type": null,
        "level_names": null,
        "level_metadata": null,
        "has_unknown_level": null,
        "min_score": null,
        "max_score": null
      },
      "score_details": {
        "score": 0.03508771929824561,
        "details": {
          "count": 1,
          "sum": 0.03508771929824561,
          "sum_squared": 0.0012311480455524776,
          "min": 0.03508771929824561,
          "max": 0.03508771929824561,
          "mean": 0.03508771929824561,
          "variance": 0.0,
          "stddev": 0.0,
          "split": "valid",
          "perturbation": null
        }
      },
      "detailed_evaluation_results_url": null,
      "generation_config": {
        "temperature": 0.0,
        "max_tokens": 100,
        "stop_sequences": [
          "\n"
        ],
        "instructions": "",
        "input_prefix": "Passage: ",
        "input_suffix": "\n",
        "output_prefix": "Answer: ",
        "output_suffix": "\n",
        "instance_prefix": "\n"
      }
    },
    {
      "evaluation_name": "generation",
      "evaluation_timestamp": "1763479296",
      "metric_config": {
        "evaluation_description": "bleu_1",
        "lower_is_better": false,
        "score_type": null,
        "level_names": null,
        "level_metadata": null,
        "has_unknown_level": null,
        "min_score": null,
        "max_score": null
      },
      "score_details": {
        "score": 0.03568840579710145,
        "details": {
          "count": 1,
          "sum": 0.03568840579710145,
          "sum_squared": 0.001273662308338584,
          "min": 0.03568840579710145,
          "max": 0.03568840579710145,
          "mean": 0.03568840579710145,
          "variance": 0.0,
          "stddev": 0.0,
          "split": "test",
          "perturbation": {
            "name": "robustness",
            "robustness": true,
            "fairness": false,
            "computed_on": "worst",
            "seed": null
          }
        }
      },
      "detailed_evaluation_results_url": null,
      "generation_config": {
        "temperature": 0.0,
        "max_tokens": 100,
        "stop_sequences": [
          "\n"
        ],
        "instructions": "",
        "input_prefix": "Passage: ",
        "input_suffix": "\n",
        "output_prefix": "Answer: ",
        "output_suffix": "\n",
        "instance_prefix": "\n"
      }
    },
    {
      "evaluation_name": "generation",
      "evaluation_timestamp": "1763479296",
      "metric_config": {
        "evaluation_description": "bleu_1",
        "lower_is_better": false,
        "score_type": null,
        "level_names": null,
        "level_metadata": null,
        "has_unknown_level": null,
        "min_score": null,
        "max_score": null
      },
      "score_details": {
        "score": 0.03568840579710145,
        "details": {
          "count": 1,
          "sum": 0.03568840579710145,
          "sum_squared": 0.001273662308338584,
          "min": 0.03568840579710145,
          "max": 0.03568840579710145,
          "mean": 0.03568840579710145,
          "variance": 0.0,
          "stddev": 0.0,
          "split": "test",
          "perturbation": {
            "name": "fairness",
            "robustness": false,
            "fairness": true,
            "computed_on": "worst",
            "seed": null
          }
        }
      },
      "detailed_evaluation_results_url": null,
      "generation_config": {
        "temperature": 0.0,
        "max_tokens": 100,
        "stop_sequences": [
          "\n"
        ],
        "instructions": "",
        "input_prefix": "Passage: ",
        "input_suffix": "\n",
        "output_prefix": "Answer: ",
        "output_suffix": "\n",
        "instance_prefix": "\n"
      }
    },
    {
      "evaluation_name": "generation",
      "evaluation_timestamp": "1763479296",
      "metric_config": {
        "evaluation_description": "bleu_1",
        "lower_is_better": false,
        "score_type": null,
        "level_names": null,
        "level_metadata": null,
        "has_unknown_level": null,
        "min_score": null,
        "max_score": null
      },
      "score_details": {
        "score": 0.03508771929824561,
        "details": {
          "count": 1,
          "sum": 0.03508771929824561,
          "sum_squared": 0.0012311480455524776,
          "min": 0.03508771929824561,
          "max": 0.03508771929824561,
          "mean": 0.03508771929824561,
          "variance": 0.0,
          "stddev": 0.0,
          "split": "valid",
          "perturbation": {
            "name": "robustness",
            "robustness": true,
            "fairness": false,
            "computed_on": "worst",
            "seed": null
          }
        }
      },
      "detailed_evaluation_results_url": null,
      "generation_config": {
        "temperature": 0.0,
        "max_tokens": 100,
        "stop_sequences": [
          "\n"
        ],
        "instructions": "",
        "input_prefix": "Passage: ",
        "input_suffix": "\n",
        "output_prefix": "Answer: ",
        "output_suffix": "\n",
        "instance_prefix": "\n"
      }
    },
    {
      "evaluation_name": "generation",
      "evaluation_timestamp": "1763479296",
      "metric_config": {
        "evaluation_description": "bleu_1",
        "lower_is_better": false,
        "score_type": null,
        "level_names": null,
        "level_metadata": null,
        "has_unknown_level": null,
        "min_score": null,
        "max_score": null
      },
      "score_details": {
        "score": 0.03508771929824561,
        "details": {
          "count": 1,
          "sum": 0.03508771929824561,
          "sum_squared": 0.0012311480455524776,
          "min": 0.03508771929824561,
          "max": 0.03508771929824561,
          "mean": 0.03508771929824561,
          "variance": 0.0,
          "stddev": 0.0,
          "split": "valid",
          "perturbation": {
            "name": "fairness",
            "robustness": false,
            "fairness": true,
            "computed_on": "worst",
            "seed": null
          }
        }
      },
      "detailed_evaluation_results_url": null,
      "generation_config": {
        "temperature": 0.0,
        "max_tokens": 100,
        "stop_sequences": [
          "\n"
        ],
        "instructions": "",
        "input_prefix": "Passage: ",
        "input_suffix": "\n",
        "output_prefix": "Answer: ",
        "output_suffix": "\n",
        "instance_prefix": "\n"
      }
    },
    {
      "evaluation_name": "generation",
      "evaluation_timestamp": "1763479296",
      "metric_config": {
        "evaluation_description": "bleu_4",
        "lower_is_better": false,
        "score_type": null,
        "level_names": null,
        "level_metadata": null,
        "has_unknown_level": null,
        "min_score": null,
        "max_score": null
      },
      "score_details": {
        "score": 1.1125369292536313e-308,
        "details": {
          "count": 1,
          "sum": 1.1125369292536313e-308,
          "sum_squared": 0.0,
          "min": 1.1125369292536313e-308,
          "max": 1.1125369292536313e-308,
          "mean": 1.1125369292536313e-308,
          "variance": 0.0,
          "stddev": 0.0,
          "split": "test",
          "perturbation": null
        }
      },
      "detailed_evaluation_results_url": null,
      "generation_config": {
        "temperature": 0.0,
        "max_tokens": 100,
        "stop_sequences": [
          "\n"
        ],
        "instructions": "",
        "input_prefix": "Passage: ",
        "input_suffix": "\n",
        "output_prefix": "Answer: ",
        "output_suffix": "\n",
        "instance_prefix": "\n"
      }
    },
    {
      "evaluation_name": "generation",
      "evaluation_timestamp": "1763479296",
      "metric_config": {
        "evaluation_description": "bleu_4",
        "lower_is_better": false,
        "score_type": null,
        "level_names": null,
        "level_metadata": null,
        "has_unknown_level": null,
        "min_score": null,
        "max_score": null
      },
      "score_details": {
        "score": 2.2250738585072626e-308,
        "details": {
          "count": 1,
          "sum": 2.2250738585072626e-308,
          "sum_squared": 0.0,
          "min": 2.2250738585072626e-308,
          "max": 2.2250738585072626e-308,
          "mean": 2.2250738585072626e-308,
          "variance": 0.0,
          "stddev": 0.0,
          "split": "valid",
          "perturbation": null
        }
      },
      "detailed_evaluation_results_url": null,
      "generation_config": {
        "temperature": 0.0,
        "max_tokens": 100,
        "stop_sequences": [
          "\n"
        ],
        "instructions": "",
        "input_prefix": "Passage: ",
        "input_suffix": "\n",
        "output_prefix": "Answer: ",
        "output_suffix": "\n",
        "instance_prefix": "\n"
      }
    },
    {
      "evaluation_name": "generation",
      "evaluation_timestamp": "1763479296",
      "metric_config": {
        "evaluation_description": "bleu_4",
        "lower_is_better": false,
        "score_type": null,
        "level_names": null,
        "level_metadata": null,
        "has_unknown_level": null,
        "min_score": null,
        "max_score": null
      },
      "score_details": {
        "score": 1.1125369292536313e-308,
        "details": {
          "count": 1,
          "sum": 1.1125369292536313e-308,
          "sum_squared": 0.0,
          "min": 1.1125369292536313e-308,
          "max": 1.1125369292536313e-308,
          "mean": 1.1125369292536313e-308,
          "variance": 0.0,
          "stddev": 0.0,
          "split": "test",
          "perturbation": {
            "name": "robustness",
            "robustness": true,
            "fairness": false,
            "computed_on": "worst",
            "seed": null
          }
        }
      },
      "detailed_evaluation_results_url": null,
      "generation_config": {
        "temperature": 0.0,
        "max_tokens": 100,
        "stop_sequences": [
          "\n"
        ],
        "instructions": "",
        "input_prefix": "Passage: ",
        "input_suffix": "\n",
        "output_prefix": "Answer: ",
        "output_suffix": "\n",
        "instance_prefix": "\n"
      }
    },
    {
      "evaluation_name": "generation",
      "evaluation_timestamp": "1763479296",
      "metric_config": {
        "evaluation_description": "bleu_4",
        "lower_is_better": false,
        "score_type": null,
        "level_names": null,
        "level_metadata": null,
        "has_unknown_level": null,
        "min_score": null,
        "max_score": null
      },
      "score_details": {
        "score": 1.1125369292536313e-308,
        "details": {
          "count": 1,
          "sum": 1.1125369292536313e-308,
          "sum_squared": 0.0,
          "min": 1.1125369292536313e-308,
          "max": 1.1125369292536313e-308,
          "mean": 1.1125369292536313e-308,
          "variance": 0.0,
          "stddev": 0.0,
          "split": "test",
          "perturbation": {
            "name": "fairness",
            "robustness": false,
            "fairness": true,
            "computed_on": "worst",
            "seed": null
          }
        }
      },
      "detailed_evaluation_results_url": null,
      "generation_config": {
        "temperature": 0.0,
        "max_tokens": 100,
        "stop_sequences": [
          "\n"
        ],
        "instructions": "",
        "input_prefix": "Passage: ",
        "input_suffix": "\n",
        "output_prefix": "Answer: ",
        "output_suffix": "\n",
        "instance_prefix": "\n"
      }
    },
    {
      "evaluation_name": "generation",
      "evaluation_timestamp": "1763479296",
      "metric_config": {
        "evaluation_description": "bleu_4",
        "lower_is_better": false,
        "score_type": null,
        "level_names": null,
        "level_metadata": null,
        "has_unknown_level": null,
        "min_score": null,
        "max_score": null
      },
      "score_details": {
        "score": 2.2250738585072626e-308,
        "details": {
          "count": 1,
          "sum": 2.2250738585072626e-308,
          "sum_squared": 0.0,
          "min": 2.2250738585072626e-308,
          "max": 2.2250738585072626e-308,
          "mean": 2.2250738585072626e-308,
          "variance": 0.0,
          "stddev": 0.0,
          "split": "valid",
          "perturbation": {
            "name": "robustness",
            "robustness": true,
            "fairness": false,
            "computed_on": "worst",
            "seed": null
          }
        }
      },
      "detailed_evaluation_results_url": null,
      "generation_config": {
        "temperature": 0.0,
        "max_tokens": 100,
        "stop_sequences": [
          "\n"
        ],
        "instructions": "",
        "input_prefix": "Passage: ",
        "input_suffix": "\n",
        "output_prefix": "Answer: ",
        "output_suffix": "\n",
        "instance_prefix": "\n"
      }
    },
    {
      "evaluation_name": "generation",
      "evaluation_timestamp": "1763479296",
      "metric_config": {
        "evaluation_description": "bleu_4",
        "lower_is_better": false,
        "score_type": null,
        "level_names": null,
        "level_metadata": null,
        "has_unknown_level": null,
        "min_score": null,
        "max_score": null
      },
      "score_details": {
        "score": 2.2250738585072626e-308,
        "details": {
          "count": 1,
          "sum": 2.2250738585072626e-308,
          "sum_squared": 0.0,
          "min": 2.2250738585072626e-308,
          "max": 2.2250738585072626e-308,
          "mean": 2.2250738585072626e-308,
          "variance": 0.0,
          "stddev": 0.0,
          "split": "valid",
          "perturbation": {
            "name": "fairness",
            "robustness": false,
            "fairness": true,
            "computed_on": "worst",
            "seed": null
          }
        }
      },
      "detailed_evaluation_results_url": null,
      "generation_config": {
        "temperature": 0.0,
        "max_tokens": 100,
        "stop_sequences": [
          "\n"
        ],
        "instructions": "",
        "input_prefix": "Passage: ",
        "input_suffix": "\n",
        "output_prefix": "Answer: ",
        "output_suffix": "\n",
        "instance_prefix": "\n"
      }
    }
  ],
  "detailed_evaluation_results_per_samples": [
    {
      "sample_id": "id1413",
      "input": "Olive Penderghast, a 17-year-old girl living in Ojai, California lies to her best friend Rhiannon Abernathy about going on a date in order to get out of camping with Rhiannon's hippie parents. Instead, she hangs around the house all weekend listening to Natasha Bedingfield's \"Pocketful of Sunshine\", which is played by a greeting card she was sent. The following Monday, pressed by Rhiannon, Olive lies about losing her virginity to a college guy. Marianne Bryant, a prissy and strictly religious Christian at their school, overhears her telling the lie and soon it spreads like wildfire. The school's conservative church group run by Marianne decides Olive will be their next project. Olive confides the truth to her friend Brandon, and he explains how others bully him because of his homosexuality. He later asks Olive to pretend to sleep with him so that he will be accepted by everyone as a 'straight stud'.\nBrandon convinces Olive to help him and they pretend to have sex at a party. After having a fight with Rhiannon over Olive's new identity as a \"dirty skank\", Olive decides to counteract the harassment by embracing her new image as the school tramp. She begins to wear more provocative clothing and stitches a red \"A\" to everything she wears. Boys who usually have had no luck with girls in the past beg Olive to say they have had sex with her in order to increase their own popularity, in exchange for gift cards to various stores, in turn increasing her reputation. Things get worse when Micah, Marianne's 22-year-old boyfriend, contracts chlamydia from sleeping with Mrs. Griffith, the school guidance counsellor, and blames it all on Olive. Olive agrees to lie to cover up the affair so that the marriage of her favorite teacher, Mr. Griffith, would be spared.\nMarianne's religious clique, which now includes Rhiannon, begins harassing Olive in order to get her to leave school. After an ill-fated date with Anson, a boy who wants to pay her to actually sleep with him and not just pretend she did, Olive reconnects with Todd, her old crush, who is also the school's mascot. Todd then tells her that he does not believe the rumors because he remembers when she lied for him when he was not ready for his first kiss years ago. Olive then begins to ask everyone she lied for to help her out by telling the truth, but Brandon and Micah have abruptly left town and everyone else is enjoying their newfound popularity and do not want the truth to get out. Mrs. Griffith also refuses to tell the truth and when Olive threatens to expose her, Mrs. Griffith rebuffs her, saying no one would believe her.\nOlive, out of spite, then immediately tells Mr. Griffith, who believes her and separates from Mrs. Griffith. After a friendly talk with her eccentric, open-minded mother Rosemary, Olive comes up with a plan to get everything finally out in the open. She then does a song and dance number at a school pep rally to get people's attention to watch her via web cam, where she confesses what she has done (the web cam is the framing device of the film). The various boys whose reputations Olive helped improve are also shown watching. Later, Olive texts Rhiannon, apologizing for lying to her. When she is finishing up her web cast, Todd comes by riding a lawnmower and tells her to come outside. She signs off by saying she may lose her virginity to Todd, and proudly declares it's nobody's business (much to Marianne's disgrace). She goes outside to meet him, they kiss and the two are shown riding off on the lawnmower.\nQuestion: Who is Todd besides Olive's old crush?",
      "prompt": "Passage: Olive Penderghast, a 17-year-old girl living in Ojai, California lies to her best friend Rhiannon Abernathy about going on a date in order to get out of camping with Rhiannon's hippie parents. Instead, she hangs around the house all weekend listening to Natasha Bedingfield's \"Pocketful of Sunshine\", which is played by a greeting card she was sent. The following Monday, pressed by Rhiannon, Olive lies about losing her virginity to a college guy. Marianne Bryant, a prissy and strictly religious Christian at their school, overhears her telling the lie and soon it spreads like wildfire. The school's conservative church group run by Marianne decides Olive will be their next project. Olive confides the truth to her friend Brandon, and he explains how others bully him because of his homosexuality. He later asks Olive to pretend to sleep with him so that he will be accepted by everyone as a 'straight stud'.\nBrandon convinces Olive to help him and they pretend to have sex at a party. After having a fight with Rhiannon over Olive's new identity as a \"dirty skank\", Olive decides to counteract the harassment by embracing her new image as the school tramp. She begins to wear more provocative clothing and stitches a red \"A\" to everything she wears. Boys who usually have had no luck with girls in the past beg Olive to say they have had sex with her in order to increase their own popularity, in exchange for gift cards to various stores, in turn increasing her reputation. Things get worse when Micah, Marianne's 22-year-old boyfriend, contracts chlamydia from sleeping with Mrs. Griffith, the school guidance counsellor, and blames it all on Olive. Olive agrees to lie to cover up the affair so that the marriage of her favorite teacher, Mr. Griffith, would be spared.\nMarianne's religious clique, which now includes Rhiannon, begins harassing Olive in order to get her to leave school. After an ill-fated date with Anson, a boy who wants to pay her to actually sleep with him and not just pretend she did, Olive reconnects with Todd, her old crush, who is also the school's mascot. Todd then tells her that he does not believe the rumors because he remembers when she lied for him when he was not ready for his first kiss years ago. Olive then begins to ask everyone she lied for to help her out by telling the truth, but Brandon and Micah have abruptly left town and everyone else is enjoying their newfound popularity and do not want the truth to get out. Mrs. Griffith also refuses to tell the truth and when Olive threatens to expose her, Mrs. Griffith rebuffs her, saying no one would believe her.\nOlive, out of spite, then immediately tells Mr. Griffith, who believes her and separates from Mrs. Griffith. After a friendly talk with her eccentric, open-minded mother Rosemary, Olive comes up with a plan to get everything finally out in the open. She then does a song and dance number at a school pep rally to get people's attention to watch her via web cam, where she confesses what she has done (the web cam is the framing device of the film). The various boys whose reputations Olive helped improve are also shown watching. Later, Olive texts Rhiannon, apologizing for lying to her. When she is finishing up her web cast, Todd comes by riding a lawnmower and tells her to come outside. She signs off by saying she may lose her virginity to Todd, and proudly declares it's nobody's business (much to Marianne's disgrace). She goes outside to meet him, they kiss and the two are shown riding off on the lawnmower.\nQuestion: Who is Todd besides Olive's old crush?\nAnswer:",
      "ground_truth": [
        "The school Mascot",
        "the schools mascot"
      ],
      "response": "Olive.",
      "choices": null,
      "full_logprobs": null
    },
    {
      "sample_id": "id1332",
      "input": "Indefer Jones is the aged squire, between seventy and eighty years of age, of a large manor, Llanfeare, in Carmarthen, Wales. His niece, Isabel Brodrick, has lived with him for years after the remarriage of her father, and endeared herself to everyone. However, according to his strong traditional beliefs, the estate should be bequeathed to a male heir.\nHis sole male blood relative is his nephew Henry Jones, a London clerk. Henry has, in the past, incurred debts that the squire had paid off, been \"sent away from Oxford\", and generally made a poor impression on his occasional visits to Llanfeare. Nevertheless, Henry is told of his uncle's intention to make him the heir to the estate and is invited to pay a visit. Isabel rejects her uncle's suggestion that she solve his dilemma by marrying Henry, as she cannot stand her cousin. Indefer Jones finds his nephew to be just as detestable as ever. As a result, he overcomes his prejudice and changes his will one final time, in Isabel's favour. Unfortunately, he dies before he can tell anyone.\nFinding the document hidden in a book of sermons by accident, Henry vacillates between keeping silent and revealing its location. He is neither good enough to give up the estate nor evil enough to burn the document, fearing disgrace, a long jail sentence and, not least, eternal damnation. Instead, he comforts himself by reasoning that doing nothing cannot be a crime.\nIndefer Jones had had his last will witnessed by two of his tenants, but since the will cannot be found despite a thorough search of the house, Henry inherits the estate. However, already extant suspicions are only strengthened by his guilty manner. He endures abuse from everyone; his own servants either quit or treat him with disrespect. He takes to spending hours in the library, where the will is hidden.\nThe local newspaper begins to publish accounts of the affair that are insulting and seemingly libelous to Henry. It accuses him of destroying the will and usurping the estate from Isabel, whom everybody knows and respects. The old squire's lawyer, Mr Apjohn, himself suspecting that Henry knows more than he lets on, approaches the new squire about the articles, pressuring the unwilling young man into taking legal action against the editor. Henry finds that this only makes things worse. The prospect of being cross examined in the witness box fills him with dread. He realises the truth would be dragged out of him in court.\nMr Apjohn, by clever questioning, gets a good idea about where the will is. Henry knows that time is running out, but once again procrastinates. Mr Apjohn and Mr Brodrick, Isabel's father, visit Henry at home and find the document, despite Henry's ineffectual efforts to stop them. Because he did not destroy the will, Henry is permitted to return to his job in London with his reputation intact and 4000, the amount Isabel was bequeathed in the other will.\nQuestion: How is Isabel Brodrick related to Indefer Jones?",
      "prompt": "Passage: Indefer Jones is the aged squire, between seventy and eighty years of age, of a large manor, Llanfeare, in Carmarthen, Wales. His niece, Isabel Brodrick, has lived with him for years after the remarriage of her father, and endeared herself to everyone. However, according to his strong traditional beliefs, the estate should be bequeathed to a male heir.\nHis sole male blood relative is his nephew Henry Jones, a London clerk. Henry has, in the past, incurred debts that the squire had paid off, been \"sent away from Oxford\", and generally made a poor impression on his occasional visits to Llanfeare. Nevertheless, Henry is told of his uncle's intention to make him the heir to the estate and is invited to pay a visit. Isabel rejects her uncle's suggestion that she solve his dilemma by marrying Henry, as she cannot stand her cousin. Indefer Jones finds his nephew to be just as detestable as ever. As a result, he overcomes his prejudice and changes his will one final time, in Isabel's favour. Unfortunately, he dies before he can tell anyone.\nFinding the document hidden in a book of sermons by accident, Henry vacillates between keeping silent and revealing its location. He is neither good enough to give up the estate nor evil enough to burn the document, fearing disgrace, a long jail sentence and, not least, eternal damnation. Instead, he comforts himself by reasoning that doing nothing cannot be a crime.\nIndefer Jones had had his last will witnessed by two of his tenants, but since the will cannot be found despite a thorough search of the house, Henry inherits the estate. However, already extant suspicions are only strengthened by his guilty manner. He endures abuse from everyone; his own servants either quit or treat him with disrespect. He takes to spending hours in the library, where the will is hidden.\nThe local newspaper begins to publish accounts of the affair that are insulting and seemingly libelous to Henry. It accuses him of destroying the will and usurping the estate from Isabel, whom everybody knows and respects. The old squire's lawyer, Mr Apjohn, himself suspecting that Henry knows more than he lets on, approaches the new squire about the articles, pressuring the unwilling young man into taking legal action against the editor. Henry finds that this only makes things worse. The prospect of being cross examined in the witness box fills him with dread. He realises the truth would be dragged out of him in court.\nMr Apjohn, by clever questioning, gets a good idea about where the will is. Henry knows that time is running out, but once again procrastinates. Mr Apjohn and Mr Brodrick, Isabel's father, visit Henry at home and find the document, despite Henry's ineffectual efforts to stop them. Because he did not destroy the will, Henry is permitted to return to his job in London with his reputation intact and 4000, the amount Isabel was bequeathed in the other will.\nQuestion: How is Isabel Brodrick related to Indefer Jones?\nAnswer:",
      "ground_truth": [
        "She is his neice.",
        "His niece."
      ],
      "response": "Isabel is a very good and intelligent woman. She is a very good and intelligent woman. She is a very good and intelligent woman. She is a very good and intelligent woman. She is a very good and intelligent woman.",
      "choices": null,
      "full_logprobs": null
    },
    {
      "sample_id": "id1123",
      "input": "The subject of Cratylus is the correctness of names (  ), in other words, it is a critique on the subject of naming (Baxter).\nWhen discussing a   (onoma ) and how it would relate to its subject, Socrates compares the original creation of a word to the work of an artist. An artist uses color to express the essence of his subject in a painting. In much the same way, the creator of words uses letters containing certain sounds to express the essence of a word's subject. There is a letter that is best for soft things, one for liquid things, and so on. He comments;\nthe best possible way to speak consists in using names all (or most) of which are like the things they name (that is, are appropriate to them), while the worst is to use the opposite kind of names.\nOne countering position, held by Hermogenes, is that names have come about due to custom and convention. They do not express the essence of their subject, so they can be swapped with something unrelated by the individuals or communities who use them.\nThe line between the two perspectives is often blurred. During more than half of the dialogue, Socrates makes guesses at Hermogenes' request as to where names and words have come from. These include the names of the Olympian gods, personified deities, and many words that describe abstract concepts. He examines whether, for example, giving names of \"streams\" to Cronus and Rhea (  flow or space) are purely accidental.\nDon't you think he who gave to the ancestors of the other gods the names Rhea and Cronus had the same thought as Heracleitus? Do you think he gave both of them the names of streams ( ) merely by chance?\nThe Greek term \"\" may refer to the flow of any medium and is not restricted to the flow of water or liquids. Many of the words which Socrates uses as examples may have come from an idea originally linked to the name, but have changed over time. Those of which he cannot find a link, he often assumes have come from foreign origins or have changed so much as to lose all resemblance to the original word. He states, \"names have been so twisted in all manner of ways, that I should not be surprised if the old language when compared with that now in use would appear to us to be a barbarous tongue.\"\nThe final theory of relations between name and object named is posited by Cratylus, a disciple of Heraclitus, who believes that names arrive from divine origins, making them necessarily correct. Socrates rebukes this theory by reminding Cratylus of the imperfection of certain names in capturing the objects they seek to signify. From this point, Socrates ultimately rejects the study of language, believing it to be philosophically inferior to a study of things themselves.\nQuestion: What does the old language sound compared with the new language?",
      "prompt": "Passage: The subject of Cratylus is the correctness of names (  ), in other words, it is a critique on the subject of naming (Baxter).\nWhen discussing a   (onoma ) and how it would relate to its subject, Socrates compares the original creation of a word to the work of an artist. An artist uses color to express the essence of his subject in a painting. In much the same way, the creator of words uses letters containing certain sounds to express the essence of a word's subject. There is a letter that is best for soft things, one for liquid things, and so on. He comments;\nthe best possible way to speak consists in using names all (or most) of which are like the things they name (that is, are appropriate to them), while the worst is to use the opposite kind of names.\nOne countering position, held by Hermogenes, is that names have come about due to custom and convention. They do not express the essence of their subject, so they can be swapped with something unrelated by the individuals or communities who use them.\nThe line between the two perspectives is often blurred. During more than half of the dialogue, Socrates makes guesses at Hermogenes' request as to where names and words have come from. These include the names of the Olympian gods, personified deities, and many words that describe abstract concepts. He examines whether, for example, giving names of \"streams\" to Cronus and Rhea (  flow or space) are purely accidental.\nDon't you think he who gave to the ancestors of the other gods the names Rhea and Cronus had the same thought as Heracleitus? Do you think he gave both of them the names of streams ( ) merely by chance?\nThe Greek term \"\" may refer to the flow of any medium and is not restricted to the flow of water or liquids. Many of the words which Socrates uses as examples may have come from an idea originally linked to the name, but have changed over time. Those of which he cannot find a link, he often assumes have come from foreign origins or have changed so much as to lose all resemblance to the original word. He states, \"names have been so twisted in all manner of ways, that I should not be surprised if the old language when compared with that now in use would appear to us to be a barbarous tongue.\"\nThe final theory of relations between name and object named is posited by Cratylus, a disciple of Heraclitus, who believes that names arrive from divine origins, making them necessarily correct. Socrates rebukes this theory by reminding Cratylus of the imperfection of certain names in capturing the objects they seek to signify. From this point, Socrates ultimately rejects the study of language, believing it to be philosophically inferior to a study of things themselves.\nQuestion: What does the old language sound compared with the new language?\nAnswer:",
      "ground_truth": [
        "like a barbaric tongue.",
        "barbarous tongue"
      ],
      "response": "The old language is a dialect of the Greek language, which is the language of the Greeks. The old language is a dialect of the Greek language, which is the language of the Greeks. The old language is a dialect of the Greek language, which is the language of the Greeks.",
      "choices": null,
      "full_logprobs": null
    },
    {
      "sample_id": "id1514",
      "input": "The novel begins in Manchester, where we are introduced to the Bartons and the Wilsons, two working-class families. John Barton is a questioner of the distribution of wealth and the relations between rich and poor. Soon his wife dieshe blames it on her grief over the disappearance of her sister Esther. Having already lost his son Tom at a young age, Barton is left to raise his daughter, Mary, alone and now falls into depression and begins to involve himself in the Chartist, trade-union movement.\nChapter 1 takes place in countryside where Moss Side is now.\nMary takes up work at a dressmaker's (her father having objected to her working in a factory) and becomes subject to the affections of hard-working Jem Wilson and Harry Carson, son of a wealthy mill owner. She fondly hopes, by marrying Carson, to secure a comfortable life for herself and her father, but immediately after refusing Jem's offer of marriage she realises that she truly loves him. She therefore decides to evade Carson, planning to show her feelings to Jem in the course of time. Jem believes her decision to be final, though this does not change his feelings for her.\nMeanwhile, Esther, a \"street-walker,\" returns to warn John Barton that he must save Mary from becoming like her. He simply pushes her away, however, and she's sent to jail for a month on the charge of vagrancy. Upon her release she talks to Jem with the same purpose. He promises that he will protect Mary and confronts Carson, eventually entering into a fight with him, which is witnessed by a policeman passing by.\nNot long afterwards, Carson is shot dead, and Jem is arrested for the crime, his gun having been found at the scene. Esther decides to investigate the matter further and discovers that the wadding for the gun was a piece of paper on which is written Mary's name.\nShe visits her niece to warn her to save the one she loves, and after she leaves Mary realises that the murderer is not Jem but her father. She is now faced with having to save her lover without giving away her father. With the help of Job Legh (the intelligent grandfather of her blind friend Margaret), Mary travels to Liverpool to find the only person who could provide an alibi for Jem  Will Wilson, Jem's cousin and a sailor, who was with him on the night of the murder. Unfortunately, Will's ship is already departing, so that, after Mary chases after the ship in a small boat, the only thing Will can do is promise to return in the pilot ship and testify the next day.\nDuring the trial, Jem learns of Mary's great love for him. Will arrives in court to testify, and Jem is found \"not guilty\". Mary has fallen ill during the trial and is nursed by Mr Sturgis, an old sailor, and his wife. When she finally returns to Manchester she has to face her father, who is crushed by his remorse. He summons John Carson, Harry's father, to confess to him that he is the murderer. Carson is still set on justice, but after turning to the Bible he forgives Barton, who dies soon afterwards in Carson's arms. Not long after this Esther comes back to Mary's home, where she, too, soon dies.\nJem decides to leave England, where, his reputation damaged, it would be difficult for him to find a new job. The novel ends with the wedded Mary and Jem, their little child, and Mrs Wilson living happily in Canada. News comes that Margaret has regained her sight and that she and Will, soon to be married, will visit.\nQuestion: Who actually killed Harry Carson?",
      "prompt": "Passage: The novel begins in Manchester, where we are introduced to the Bartons and the Wilsons, two working-class families. John Barton is a questioner of the distribution of wealth and the relations between rich and poor. Soon his wife dieshe blames it on her grief over the disappearance of her sister Esther. Having already lost his son Tom at a young age, Barton is left to raise his daughter, Mary, alone and now falls into depression and begins to involve himself in the Chartist, trade-union movement.\nChapter 1 takes place in countryside where Moss Side is now.\nMary takes up work at a dressmaker's (her father having objected to her working in a factory) and becomes subject to the affections of hard-working Jem Wilson and Harry Carson, son of a wealthy mill owner. She fondly hopes, by marrying Carson, to secure a comfortable life for herself and her father, but immediately after refusing Jem's offer of marriage she realises that she truly loves him. She therefore decides to evade Carson, planning to show her feelings to Jem in the course of time. Jem believes her decision to be final, though this does not change his feelings for her.\nMeanwhile, Esther, a \"street-walker,\" returns to warn John Barton that he must save Mary from becoming like her. He simply pushes her away, however, and she's sent to jail for a month on the charge of vagrancy. Upon her release she talks to Jem with the same purpose. He promises that he will protect Mary and confronts Carson, eventually entering into a fight with him, which is witnessed by a policeman passing by.\nNot long afterwards, Carson is shot dead, and Jem is arrested for the crime, his gun having been found at the scene. Esther decides to investigate the matter further and discovers that the wadding for the gun was a piece of paper on which is written Mary's name.\nShe visits her niece to warn her to save the one she loves, and after she leaves Mary realises that the murderer is not Jem but her father. She is now faced with having to save her lover without giving away her father. With the help of Job Legh (the intelligent grandfather of her blind friend Margaret), Mary travels to Liverpool to find the only person who could provide an alibi for Jem  Will Wilson, Jem's cousin and a sailor, who was with him on the night of the murder. Unfortunately, Will's ship is already departing, so that, after Mary chases after the ship in a small boat, the only thing Will can do is promise to return in the pilot ship and testify the next day.\nDuring the trial, Jem learns of Mary's great love for him. Will arrives in court to testify, and Jem is found \"not guilty\". Mary has fallen ill during the trial and is nursed by Mr Sturgis, an old sailor, and his wife. When she finally returns to Manchester she has to face her father, who is crushed by his remorse. He summons John Carson, Harry's father, to confess to him that he is the murderer. Carson is still set on justice, but after turning to the Bible he forgives Barton, who dies soon afterwards in Carson's arms. Not long after this Esther comes back to Mary's home, where she, too, soon dies.\nJem decides to leave England, where, his reputation damaged, it would be difficult for him to find a new job. The novel ends with the wedded Mary and Jem, their little child, and Mrs Wilson living happily in Canada. News comes that Margaret has regained her sight and that she and Will, soon to be married, will visit.\nQuestion: Who actually killed Harry Carson?\nAnswer:",
      "ground_truth": [
        "John Barton",
        "John Barton"
      ],
      "response": "The Wilsons.",
      "choices": null,
      "full_logprobs": null
    },
    {
      "sample_id": "id1340",
      "input": "Tarzan returns to Opar, the source of the gold where a lost colony of fabled Atlantis is located, in order to make good on some financial reverses he has recently suffered. While Atlantis itself sank beneath the waves thousands of years ago, the workers of Opar continued to mine all of the gold, which means there is a rather huge stockpile but which is now lost to the memory of the Oparians and only Tarzan knows its secret location.\nA greedy, outlawed Belgian army officer, Albert Werper, in the employ of a criminal Arab, secretly follows Tarzan to Opar. There, Tarzan loses his memory after being struck on the head by a falling rock in the treasure room during an earthquake. On encountering La, the high priestess who is the servant of the Flaming God of Opar, and who is also very beautiful, Tarzan once again rejects her love which enrages her and she tries to have him killed; she had fallen in love with the apeman during their first encounter and La and her high priests are not going to allow Tarzan to escape their sacrificial knives this time.\nIn the meanwhile, Jane has been kidnapped by the Arab and wonders what is keeping her husband from once again coming to her rescue. A now amnesiac Tarzan and the Werper escape from Opar, bearing away the sacrificial knife of Opar which La and some retainers set out to recover. There is intrigue and counter intrigue the rest of the way.\nQuestion: Who is La?",
      "prompt": "Passage: The Little White Bird is a series of short episodes, including both accounts of the narrator's day-to-day activities in contemporary London and fanciful tales set in Kensington Gardens and elsewhere.The story is set in several locations; the earlier chapters are set in the town of London, contemporaneous to the time of Barrie's writing, and involving some time travel of a few years, and other fantasy elements, while remaining within the London setting. The middle chapters that later became Peter Pan in Kensington Gardens are set in London's famous Kensington Gardens, introduced by the statement that \"All perambulators lead to Kensington Gardens\". The Kensington Gardens chapters include detailed descriptions of the features of the Gardens, along with fantasy names given to the locations by the story's characters, especially after \"Lock-Out Time\", described by Barrie as the time at the end of the day when the park gates are closed to the public, and the fairies and other magical inhabitants of the park can move about more freely than during the daylight, when they must hide from ordinary people. The third section of the book, following the Kensington Gardens chapters, are again set generally in London, though there are some short returns to the Gardens that are not part of the Peter Pan stories. In a two-page diversion in chapter 24, Barrie brings the story to Patagonia, and a journey by ship returning to England at the \"white cliffs of Albion\".\nQuestion: Where  was the ship in Pentagonia returned to?\nAnswer: England\n\nPassage: Tarzan returns to Opar, the source of the gold where a lost colony of fabled Atlantis is located, in order to make good on some financial reverses he has recently suffered. While Atlantis itself sank beneath the waves thousands of years ago, the workers of Opar continued to mine all of the gold, which means there is a rather huge stockpile but which is now lost to the memory of the Oparians and only Tarzan knows its secret location.\nA greedy, outlawed Belgian army officer, Albert Werper, in the employ of a criminal Arab, secretly follows Tarzan to Opar. There, Tarzan loses his memory after being struck on the head by a falling rock in the treasure room during an earthquake. On encountering La, the high priestess who is the servant of the Flaming God of Opar, and who is also very beautiful, Tarzan once again rejects her love which enrages her and she tries to have him killed; she had fallen in love with the apeman during their first encounter and La and her high priests are not going to allow Tarzan to escape their sacrificial knives this time.\nIn the meanwhile, Jane has been kidnapped by the Arab and wonders what is keeping her husband from once again coming to her rescue. A now amnesiac Tarzan and the Werper escape from Opar, bearing away the sacrificial knife of Opar which La and some retainers set out to recover. There is intrigue and counter intrigue the rest of the way.\nQuestion: Who is La?\nAnswer:",
      "ground_truth": [
        "La is the high priestess that serves the Flaming God of Opar.",
        "A high priestess."
      ],
      "response": "La is a young woman who is a member of the royal family of Opar. She is a member of the royal family of Opar, and is a member of the royal family of Opar. She is a member of the royal family of Opar, and is a member of the royal family of Opar. She is a member of the royal family of Opar, and is a member of the royal family of Opar. She is a member of the royal family of Opar",
      "choices": null,
      "full_logprobs": null
    }
  ]
}