{
  "schema_version": "0.2.0",
  "evaluation_id": "helm_classic/yandex_YaLM-100B/1770834891.1472661",
  "retrieved_timestamp": "1770834891.1472661",
  "source_metadata": {
    "source_name": "helm_classic",
    "source_type": "documentation",
    "source_organization_name": "crfm",
    "evaluator_relationship": "third_party"
  },
  "model_info": {
    "name": "YaLM 100B",
    "id": "yandex/YaLM-100B",
    "developer": "yandex",
    "inference_platform": "unknown"
  },
  "evaluation_results": [
    {
      "evaluation_name": "Mean win rate",
      "source_data": {
        "dataset_name": "helm_classic",
        "source_type": "url",
        "url": [
          "https://storage.googleapis.com/crfm-helm-public/benchmark_output/releases/v0.4.0/groups/core_scenarios.json"
        ]
      },
      "metric_config": {
        "evaluation_description": "How many models this model outperform on average (over columns).",
        "lower_is_better": false,
        "score_type": "continuous",
        "min_score": 0.0,
        "max_score": 1.0
      },
      "score_details": {
        "score": 0.075,
        "details": {
          "tab": "Accuracy",
          "Mean win rate - Calibration": {
            "description": null,
            "tab": "Calibration",
            "score": 0.40175763182238666
          },
          "Mean win rate - Robustness": {
            "description": null,
            "tab": "Robustness",
            "score": 0.20536130536130537
          },
          "Mean win rate - Fairness": {
            "description": null,
            "tab": "Fairness",
            "score": 0.16727272727272727
          },
          "Mean win rate - Efficiency": {
            "description": null,
            "tab": "Efficiency",
            "score": 0.2658333333333333
          },
          "Mean win rate - General information": {
            "description": null,
            "tab": "General information",
            "score": null
          },
          "Mean win rate - Bias": {
            "description": null,
            "tab": "Bias",
            "score": 0.37929404953000706
          },
          "Mean win rate - Toxicity": {
            "description": null,
            "tab": "Toxicity",
            "score": 0.24189051689051688
          },
          "Mean win rate - Summarization metrics": {
            "description": null,
            "tab": "Summarization metrics",
            "score": 0.04536340852130326
          }
        }
      },
      "generation_config": {
        "additional_details": {}
      }
    },
    {
      "evaluation_name": "MMLU",
      "source_data": {
        "dataset_name": "MMLU",
        "source_type": "url",
        "url": [
          "https://storage.googleapis.com/crfm-helm-public/benchmark_output/releases/v0.4.0/groups/core_scenarios.json"
        ]
      },
      "metric_config": {
        "evaluation_description": "EM on MMLU",
        "lower_is_better": false,
        "score_type": "continuous",
        "min_score": 0.0,
        "max_score": 1.0
      },
      "score_details": {
        "score": 0.243,
        "details": {
          "description": "min=0.2, mean=0.243, max=0.28, sum=3.651 (15)",
          "tab": "Accuracy",
          "MMLU - ECE (10-bin)": {
            "description": "min=0.619, mean=0.708, max=0.769, sum=10.615 (15)",
            "tab": "Calibration",
            "score": 0.7076962372990694
          },
          "MMLU - EM (Robustness)": {
            "description": "min=0.2, mean=0.243, max=0.28, sum=3.651 (15)",
            "tab": "Robustness",
            "score": 0.2433684210526316
          },
          "MMLU - EM (Fairness)": {
            "description": "min=0.2, mean=0.243, max=0.28, sum=3.651 (15)",
            "tab": "Fairness",
            "score": 0.2433684210526316
          },
          "MMLU - Denoised inference time (s)": {
            "description": "min=0.09, mean=0.143, max=0.217, sum=2.144 (15)",
            "tab": "Efficiency",
            "score": 0.14296402070471761
          },
          "MMLU - # eval": {
            "description": "min=100, mean=102.8, max=114, sum=1542 (15)",
            "tab": "General information",
            "score": 102.8
          },
          "MMLU - # train": {
            "description": "min=5, mean=5, max=5, sum=75 (15)",
            "tab": "General information",
            "score": 5.0
          },
          "MMLU - truncated": {
            "description": "min=0, mean=0, max=0, sum=0 (15)",
            "tab": "General information",
            "score": 0.0
          },
          "MMLU - # prompt tokens": {
            "description": "min=354.96, mean=453.383, max=580.833, sum=6800.74 (15)",
            "tab": "General information",
            "score": 453.38266666666664
          },
          "MMLU - # output tokens": {
            "description": "min=1, mean=1, max=1, sum=15 (15)",
            "tab": "General information",
            "score": 1.0
          },
          "MMLU - # trials": {
            "description": "min=3, mean=3, max=3, sum=45 (15)",
            "tab": "General information",
            "score": 3.0
          }
        }
      },
      "generation_config": {
        "additional_details": {}
      }
    },
    {
      "evaluation_name": "BoolQ",
      "source_data": {
        "dataset_name": "BoolQ",
        "source_type": "url",
        "url": [
          "https://storage.googleapis.com/crfm-helm-public/benchmark_output/releases/v0.4.0/groups/core_scenarios.json"
        ]
      },
      "metric_config": {
        "evaluation_description": "EM on BoolQ",
        "lower_is_better": false,
        "score_type": "continuous",
        "min_score": 0.0,
        "max_score": 1.0
      },
      "score_details": {
        "score": 0.634,
        "details": {
          "description": "min=0.631, mean=0.634, max=0.64, sum=1.902 (3)",
          "tab": "Accuracy",
          "BoolQ - ECE (10-bin)": {
            "description": "min=0.114, mean=0.147, max=0.167, sum=0.442 (3)",
            "tab": "Calibration",
            "score": 0.14717484078898194
          },
          "BoolQ - EM (Robustness)": {
            "description": "min=0.437, mean=0.566, max=0.631, sum=1.698 (3)",
            "tab": "Robustness",
            "score": 0.566
          },
          "BoolQ - EM (Fairness)": {
            "description": "min=0.486, mean=0.583, max=0.631, sum=1.748 (3)",
            "tab": "Fairness",
            "score": 0.5826666666666667
          },
          "BoolQ - Denoised inference time (s)": {
            "description": "min=0.546, mean=0.828, max=1.136, sum=2.485 (3)",
            "tab": "Efficiency",
            "score": 0.8282727491158176
          },
          "BoolQ - # eval": {
            "description": "min=1000, mean=1000, max=1000, sum=3000 (3)",
            "tab": "General information",
            "score": 1000.0
          },
          "BoolQ - # train": {
            "description": "min=5, mean=5, max=5, sum=15 (3)",
            "tab": "General information",
            "score": 5.0
          },
          "BoolQ - truncated": {
            "description": "min=0, mean=0, max=0, sum=0 (3)",
            "tab": "General information",
            "score": 0.0
          },
          "BoolQ - # prompt tokens": {
            "description": "min=649.339, mean=899.006, max=1233.339, sum=2697.017 (3)",
            "tab": "General information",
            "score": 899.0056666666666
          },
          "BoolQ - # output tokens": {
            "description": "min=5, mean=5, max=5, sum=15 (3)",
            "tab": "General information",
            "score": 5.0
          },
          "BoolQ - # trials": {
            "description": "min=3, mean=3, max=3, sum=9 (3)",
            "tab": "General information",
            "score": 3.0
          },
          "BoolQ - Stereotypes (race)": {
            "description": "(0)",
            "tab": "Bias",
            "score": null
          },
          "BoolQ - Stereotypes (gender)": {
            "description": "(0)",
            "tab": "Bias",
            "score": null
          },
          "BoolQ - Representation (race)": {
            "description": "(0)",
            "tab": "Bias",
            "score": null
          },
          "BoolQ - Representation (gender)": {
            "description": "(0)",
            "tab": "Bias",
            "score": null
          },
          "BoolQ - Toxic fraction": {
            "description": "min=0, mean=0, max=0, sum=0 (3)",
            "tab": "Toxicity",
            "score": 0.0
          }
        }
      },
      "generation_config": {
        "additional_details": {}
      }
    },
    {
      "evaluation_name": "NarrativeQA",
      "source_data": {
        "dataset_name": "NarrativeQA",
        "source_type": "url",
        "url": [
          "https://storage.googleapis.com/crfm-helm-public/benchmark_output/releases/v0.4.0/groups/core_scenarios.json"
        ]
      },
      "metric_config": {
        "evaluation_description": "F1 on NarrativeQA",
        "lower_is_better": false,
        "score_type": "continuous",
        "min_score": 0.0,
        "max_score": 1.0
      },
      "score_details": {
        "score": 0.252,
        "details": {
          "description": "min=0.213, mean=0.252, max=0.297, sum=0.756 (3)",
          "tab": "Accuracy",
          "NarrativeQA - ECE (10-bin)": {
            "description": "min=0.029, mean=0.06, max=0.101, sum=0.179 (3)",
            "tab": "Calibration",
            "score": 0.05960283323299867
          },
          "NarrativeQA - F1 (Robustness)": {
            "description": "min=0.078, mean=0.088, max=0.096, sum=0.264 (3)",
            "tab": "Robustness",
            "score": 0.08788676556219112
          },
          "NarrativeQA - F1 (Fairness)": {
            "description": "min=0.131, mean=0.146, max=0.169, sum=0.437 (3)",
            "tab": "Fairness",
            "score": 0.14573784149261218
          },
          "NarrativeQA - Denoised inference time (s)": {
            "description": "min=2.158, mean=2.314, max=2.397, sum=6.943 (3)",
            "tab": "Efficiency",
            "score": 2.314193915889056
          },
          "NarrativeQA - # eval": {
            "description": "min=355, mean=355, max=355, sum=1065 (3)",
            "tab": "General information",
            "score": 355.0
          },
          "NarrativeQA - # train": {
            "description": "min=1.028, mean=1.604, max=2.008, sum=4.811 (3)",
            "tab": "General information",
            "score": 1.603755868544601
          },
          "NarrativeQA - truncated": {
            "description": "min=0, mean=0, max=0, sum=0 (3)",
            "tab": "General information",
            "score": 0.0
          },
          "NarrativeQA - # prompt tokens": {
            "description": "min=1603.569, mean=1644.878, max=1690.352, sum=4934.634 (3)",
            "tab": "General information",
            "score": 1644.8779342723003
          },
          "NarrativeQA - # output tokens": {
            "description": "min=94.115, mean=96.018, max=98.566, sum=288.054 (3)",
            "tab": "General information",
            "score": 96.01784037558686
          },
          "NarrativeQA - # trials": {
            "description": "min=3, mean=3, max=3, sum=9 (3)",
            "tab": "General information",
            "score": 3.0
          },
          "NarrativeQA - Stereotypes (race)": {
            "description": "min=0.667, mean=0.667, max=0.667, sum=2 (3)",
            "tab": "Bias",
            "score": 0.6666666666666666
          },
          "NarrativeQA - Stereotypes (gender)": {
            "description": "min=0.434, mean=0.449, max=0.478, sum=1.347 (3)",
            "tab": "Bias",
            "score": 0.449065994913171
          },
          "NarrativeQA - Representation (race)": {
            "description": "min=0.429, mean=0.568, max=0.667, sum=1.703 (3)",
            "tab": "Bias",
            "score": 0.5676937441643325
          },
          "NarrativeQA - Representation (gender)": {
            "description": "min=0.127, mean=0.177, max=0.216, sum=0.53 (3)",
            "tab": "Bias",
            "score": 0.17681914997964296
          },
          "NarrativeQA - Toxic fraction": {
            "description": "min=0.014, mean=0.017, max=0.02, sum=0.051 (3)",
            "tab": "Toxicity",
            "score": 0.016901408450704227
          }
        }
      },
      "generation_config": {
        "additional_details": {}
      }
    },
    {
      "evaluation_name": "NaturalQuestions (open-book)",
      "source_data": {
        "dataset_name": "NaturalQuestions (open-book)",
        "source_type": "url",
        "url": [
          "https://storage.googleapis.com/crfm-helm-public/benchmark_output/releases/v0.4.0/groups/core_scenarios.json"
        ]
      },
      "metric_config": {
        "evaluation_description": "F1 on NaturalQuestions (open-book)",
        "lower_is_better": false,
        "score_type": "continuous",
        "min_score": 0.0,
        "max_score": 1.0
      },
      "score_details": {
        "score": 0.227,
        "details": {
          "description": "min=0.197, mean=0.227, max=0.258, sum=0.68 (3)",
          "tab": "Accuracy",
          "NaturalQuestions (closed-book) - ECE (10-bin)": {
            "description": "min=0.019, mean=0.02, max=0.02, sum=0.059 (3)",
            "tab": "Calibration",
            "score": 0.019790335675494927
          },
          "NaturalQuestions (open-book) - ECE (10-bin)": {
            "description": "min=0.069, mean=0.086, max=0.12, sum=0.259 (3)",
            "tab": "Calibration",
            "score": 0.08637064333353452
          },
          "NaturalQuestions (closed-book) - F1 (Robustness)": {
            "description": "min=0.045, mean=0.047, max=0.05, sum=0.14 (3)",
            "tab": "Robustness",
            "score": 0.04678550801735826
          },
          "NaturalQuestions (open-book) - F1 (Robustness)": {
            "description": "min=0.111, mean=0.125, max=0.146, sum=0.375 (3)",
            "tab": "Robustness",
            "score": 0.12496123369617401
          },
          "NaturalQuestions (closed-book) - F1 (Fairness)": {
            "description": "min=0.051, mean=0.052, max=0.053, sum=0.155 (3)",
            "tab": "Fairness",
            "score": 0.0516362934670568
          },
          "NaturalQuestions (open-book) - F1 (Fairness)": {
            "description": "min=0.15, mean=0.177, max=0.207, sum=0.53 (3)",
            "tab": "Fairness",
            "score": 0.1768275232054711
          },
          "NaturalQuestions (closed-book) - Denoised inference time (s)": {
            "description": "min=2.669, mean=2.722, max=2.827, sum=8.167 (3)",
            "tab": "Efficiency",
            "score": 2.7221932611479644
          },
          "NaturalQuestions (open-book) - Denoised inference time (s)": {
            "description": "min=4.373, mean=4.463, max=4.531, sum=13.389 (3)",
            "tab": "Efficiency",
            "score": 4.463013303365339
          },
          "NaturalQuestions (closed-book) - # eval": {
            "description": "min=1000, mean=1000, max=1000, sum=3000 (3)",
            "tab": "General information",
            "score": 1000.0
          },
          "NaturalQuestions (closed-book) - # train": {
            "description": "min=5, mean=5, max=5, sum=15 (3)",
            "tab": "General information",
            "score": 5.0
          },
          "NaturalQuestions (closed-book) - truncated": {
            "description": "min=0, mean=0, max=0, sum=0 (3)",
            "tab": "General information",
            "score": 0.0
          },
          "NaturalQuestions (closed-book) - # prompt tokens": {
            "description": "min=108.201, mean=111.534, max=117.201, sum=334.603 (3)",
            "tab": "General information",
            "score": 111.53433333333332
          },
          "NaturalQuestions (closed-book) - # output tokens": {
            "description": "min=298.545, mean=299.515, max=300, sum=898.545 (3)",
            "tab": "General information",
            "score": 299.51500000000004
          },
          "NaturalQuestions (closed-book) - # trials": {
            "description": "min=3, mean=3, max=3, sum=9 (3)",
            "tab": "General information",
            "score": 3.0
          },
          "NaturalQuestions (open-book) - # eval": {
            "description": "min=1000, mean=1000, max=1000, sum=3000 (3)",
            "tab": "General information",
            "score": 1000.0
          },
          "NaturalQuestions (open-book) - # train": {
            "description": "min=4.669, mean=4.702, max=4.738, sum=14.107 (3)",
            "tab": "General information",
            "score": 4.702333333333333
          },
          "NaturalQuestions (open-book) - truncated": {
            "description": "min=0.038, mean=0.038, max=0.038, sum=0.114 (3)",
            "tab": "General information",
            "score": 0.038
          },
          "NaturalQuestions (open-book) - # prompt tokens": {
            "description": "min=1218.159, mean=1409.24, max=1510.891, sum=4227.721 (3)",
            "tab": "General information",
            "score": 1409.2403333333332
          },
          "NaturalQuestions (open-book) - # output tokens": {
            "description": "min=289.149, mean=291.572, max=293.886, sum=874.715 (3)",
            "tab": "General information",
            "score": 291.57166666666666
          },
          "NaturalQuestions (open-book) - # trials": {
            "description": "min=3, mean=3, max=3, sum=9 (3)",
            "tab": "General information",
            "score": 3.0
          },
          "NaturalQuestions (closed-book) - Stereotypes (race)": {
            "description": "min=0.667, mean=0.667, max=0.667, sum=2 (3)",
            "tab": "Bias",
            "score": 0.6666666666666666
          },
          "NaturalQuestions (closed-book) - Stereotypes (gender)": {
            "description": "min=0.433, mean=0.478, max=0.5, sum=1.433 (3)",
            "tab": "Bias",
            "score": 0.4776758409785933
          },
          "NaturalQuestions (closed-book) - Representation (race)": {
            "description": "min=0.324, mean=0.327, max=0.33, sum=0.982 (3)",
            "tab": "Bias",
            "score": 0.3274145329078469
          },
          "NaturalQuestions (closed-book) - Representation (gender)": {
            "description": "min=0.014, mean=0.168, max=0.277, sum=0.504 (3)",
            "tab": "Bias",
            "score": 0.16816448651008897
          },
          "NaturalQuestions (open-book) - Stereotypes (race)": {
            "description": "min=0.667, mean=0.667, max=0.667, sum=2 (3)",
            "tab": "Bias",
            "score": 0.6666666666666666
          },
          "NaturalQuestions (open-book) - Stereotypes (gender)": {
            "description": "min=0.5, mean=0.5, max=0.5, sum=0.5 (1)",
            "tab": "Bias",
            "score": 0.5
          },
          "NaturalQuestions (open-book) - Representation (race)": {
            "description": "min=0.204, mean=0.385, max=0.523, sum=1.154 (3)",
            "tab": "Bias",
            "score": 0.38473904949347787
          },
          "NaturalQuestions (open-book) - Representation (gender)": {
            "description": "min=0.102, mean=0.175, max=0.25, sum=0.526 (3)",
            "tab": "Bias",
            "score": 0.17544176986611967
          },
          "NaturalQuestions (closed-book) - Toxic fraction": {
            "description": "min=0.007, mean=0.008, max=0.009, sum=0.024 (3)",
            "tab": "Toxicity",
            "score": 0.008
          },
          "NaturalQuestions (open-book) - Toxic fraction": {
            "description": "min=0.003, mean=0.003, max=0.003, sum=0.009 (3)",
            "tab": "Toxicity",
            "score": 0.0030000000000000005
          }
        }
      },
      "generation_config": {
        "additional_details": {}
      }
    },
    {
      "evaluation_name": "QuAC",
      "source_data": {
        "dataset_name": "QuAC",
        "source_type": "url",
        "url": [
          "https://storage.googleapis.com/crfm-helm-public/benchmark_output/releases/v0.4.0/groups/core_scenarios.json"
        ]
      },
      "metric_config": {
        "evaluation_description": "F1 on QuAC",
        "lower_is_better": false,
        "score_type": "continuous",
        "min_score": 0.0,
        "max_score": 1.0
      },
      "score_details": {
        "score": 0.162,
        "details": {
          "description": "min=0.156, mean=0.162, max=0.172, sum=0.485 (3)",
          "tab": "Accuracy",
          "QuAC - ECE (10-bin)": {
            "description": "min=0.012, mean=0.029, max=0.039, sum=0.087 (3)",
            "tab": "Calibration",
            "score": 0.028959032200530792
          },
          "QuAC - F1 (Robustness)": {
            "description": "min=0.077, mean=0.08, max=0.082, sum=0.239 (3)",
            "tab": "Robustness",
            "score": 0.0795025876916194
          },
          "QuAC - F1 (Fairness)": {
            "description": "min=0.092, mean=0.1, max=0.108, sum=0.301 (3)",
            "tab": "Fairness",
            "score": 0.10047785618783804
          },
          "QuAC - Denoised inference time (s)": {
            "description": "min=2.259, mean=2.278, max=2.297, sum=6.834 (3)",
            "tab": "Efficiency",
            "score": 2.278147567048529
          },
          "QuAC - # eval": {
            "description": "min=1000, mean=1000, max=1000, sum=3000 (3)",
            "tab": "General information",
            "score": 1000.0
          },
          "QuAC - # train": {
            "description": "min=0.841, mean=0.951, max=1.111, sum=2.853 (3)",
            "tab": "General information",
            "score": 0.951
          },
          "QuAC - truncated": {
            "description": "min=0.016, mean=0.016, max=0.016, sum=0.048 (3)",
            "tab": "General information",
            "score": 0.016
          },
          "QuAC - # prompt tokens": {
            "description": "min=1630.348, mean=1646.729, max=1667.958, sum=4940.188 (3)",
            "tab": "General information",
            "score": 1646.7293333333334
          },
          "QuAC - # output tokens": {
            "description": "min=99.146, mean=99.146, max=99.146, sum=297.438 (3)",
            "tab": "General information",
            "score": 99.146
          },
          "QuAC - # trials": {
            "description": "min=3, mean=3, max=3, sum=9 (3)",
            "tab": "General information",
            "score": 3.0
          },
          "QuAC - Stereotypes (race)": {
            "description": "min=0.667, mean=0.667, max=0.667, sum=2 (3)",
            "tab": "Bias",
            "score": 0.6666666666666666
          },
          "QuAC - Stereotypes (gender)": {
            "description": "min=0.44, mean=0.454, max=0.465, sum=1.363 (3)",
            "tab": "Bias",
            "score": 0.4543925551127126
          },
          "QuAC - Representation (race)": {
            "description": "min=0.312, mean=0.465, max=0.582, sum=1.396 (3)",
            "tab": "Bias",
            "score": 0.4653480174056855
          },
          "QuAC - Representation (gender)": {
            "description": "min=0.335, mean=0.343, max=0.358, sum=1.029 (3)",
            "tab": "Bias",
            "score": 0.3431307584494557
          },
          "QuAC - Toxic fraction": {
            "description": "min=0, mean=0.001, max=0.003, sum=0.003 (3)",
            "tab": "Toxicity",
            "score": 0.001
          }
        }
      },
      "generation_config": {
        "additional_details": {}
      }
    },
    {
      "evaluation_name": "HellaSwag",
      "source_data": {
        "dataset_name": "HellaSwag",
        "source_type": "url",
        "url": [
          "https://storage.googleapis.com/crfm-helm-public/benchmark_output/releases/v0.4.0/groups/core_scenarios.json"
        ]
      },
      "metric_config": {
        "evaluation_description": "EM on HellaSwag",
        "lower_is_better": false,
        "score_type": "continuous",
        "min_score": 0.0,
        "max_score": 1.0
      },
      "score_details": {
        "score": -1.0,
        "details": {
          "description": "No matching runs",
          "tab": "Accuracy",
          "HellaSwag - ECE (10-bin)": {
            "description": "No matching runs",
            "tab": "Calibration",
            "score": null
          },
          "HellaSwag - EM (Robustness)": {
            "description": "No matching runs",
            "tab": "Robustness",
            "score": null
          },
          "HellaSwag - EM (Fairness)": {
            "description": "No matching runs",
            "tab": "Fairness",
            "score": null
          },
          "HellaSwag - Denoised inference time (s)": {
            "description": "No matching runs",
            "tab": "Efficiency",
            "score": null
          },
          "HellaSwag - # eval": {
            "description": "No matching runs",
            "tab": "General information",
            "score": null
          },
          "HellaSwag - # train": {
            "description": "No matching runs",
            "tab": "General information",
            "score": null
          },
          "HellaSwag - truncated": {
            "description": "No matching runs",
            "tab": "General information",
            "score": null
          },
          "HellaSwag - # prompt tokens": {
            "description": "No matching runs",
            "tab": "General information",
            "score": null
          },
          "HellaSwag - # output tokens": {
            "description": "No matching runs",
            "tab": "General information",
            "score": null
          },
          "HellaSwag - # trials": {
            "description": "No matching runs",
            "tab": "General information",
            "score": null
          }
        }
      },
      "generation_config": {
        "additional_details": {}
      }
    },
    {
      "evaluation_name": "OpenbookQA",
      "source_data": {
        "dataset_name": "OpenbookQA",
        "source_type": "url",
        "url": [
          "https://storage.googleapis.com/crfm-helm-public/benchmark_output/releases/v0.4.0/groups/core_scenarios.json"
        ]
      },
      "metric_config": {
        "evaluation_description": "EM on OpenbookQA",
        "lower_is_better": false,
        "score_type": "continuous",
        "min_score": 0.0,
        "max_score": 1.0
      },
      "score_details": {
        "score": -1.0,
        "details": {
          "description": "No matching runs",
          "tab": "Accuracy",
          "OpenbookQA - ECE (10-bin)": {
            "description": "No matching runs",
            "tab": "Calibration",
            "score": null
          },
          "OpenbookQA - EM (Robustness)": {
            "description": "No matching runs",
            "tab": "Robustness",
            "score": null
          },
          "OpenbookQA - EM (Fairness)": {
            "description": "No matching runs",
            "tab": "Fairness",
            "score": null
          },
          "OpenbookQA - Denoised inference time (s)": {
            "description": "No matching runs",
            "tab": "Efficiency",
            "score": null
          },
          "OpenbookQA - # eval": {
            "description": "No matching runs",
            "tab": "General information",
            "score": null
          },
          "OpenbookQA - # train": {
            "description": "No matching runs",
            "tab": "General information",
            "score": null
          },
          "OpenbookQA - truncated": {
            "description": "No matching runs",
            "tab": "General information",
            "score": null
          },
          "OpenbookQA - # prompt tokens": {
            "description": "No matching runs",
            "tab": "General information",
            "score": null
          },
          "OpenbookQA - # output tokens": {
            "description": "No matching runs",
            "tab": "General information",
            "score": null
          },
          "OpenbookQA - # trials": {
            "description": "No matching runs",
            "tab": "General information",
            "score": null
          }
        }
      },
      "generation_config": {
        "additional_details": {}
      }
    },
    {
      "evaluation_name": "TruthfulQA",
      "source_data": {
        "dataset_name": "TruthfulQA",
        "source_type": "url",
        "url": [
          "https://storage.googleapis.com/crfm-helm-public/benchmark_output/releases/v0.4.0/groups/core_scenarios.json"
        ]
      },
      "metric_config": {
        "evaluation_description": "EM on TruthfulQA",
        "lower_is_better": false,
        "score_type": "continuous",
        "min_score": 0.0,
        "max_score": 1.0
      },
      "score_details": {
        "score": 0.202,
        "details": {
          "description": "min=0.197, mean=0.202, max=0.203, sum=0.807 (4)",
          "tab": "Accuracy",
          "TruthfulQA - ECE (10-bin)": {
            "description": "min=0.621, mean=0.679, max=0.751, sum=2.716 (4)",
            "tab": "Calibration",
            "score": 0.6789622806094777
          },
          "TruthfulQA - EM (Robustness)": {
            "description": "min=0.197, mean=0.202, max=0.203, sum=0.807 (4)",
            "tab": "Robustness",
            "score": 0.2018348623853211
          },
          "TruthfulQA - EM (Fairness)": {
            "description": "min=0.197, mean=0.202, max=0.203, sum=0.807 (4)",
            "tab": "Fairness",
            "score": 0.2018348623853211
          },
          "TruthfulQA - Denoised inference time (s)": {
            "description": "min=0.058, mean=0.092, max=0.136, sum=0.37 (4)",
            "tab": "Efficiency",
            "score": 0.09243018414244196
          },
          "TruthfulQA - # eval": {
            "description": "min=654, mean=654, max=654, sum=2616 (4)",
            "tab": "General information",
            "score": 654.0
          },
          "TruthfulQA - # train": {
            "description": "min=0, mean=3.75, max=5, sum=15 (4)",
            "tab": "General information",
            "score": 3.75
          },
          "TruthfulQA - truncated": {
            "description": "min=0, mean=0, max=0, sum=0 (4)",
            "tab": "General information",
            "score": 0.0
          },
          "TruthfulQA - # prompt tokens": {
            "description": "min=85.664, mean=405.414, max=531.664, sum=1621.654 (4)",
            "tab": "General information",
            "score": 405.41360856269114
          },
          "TruthfulQA - # output tokens": {
            "description": "min=1, mean=1, max=1, sum=4 (4)",
            "tab": "General information",
            "score": 1.0
          },
          "TruthfulQA - # trials": {
            "description": "min=1, mean=2.5, max=3, sum=10 (4)",
            "tab": "General information",
            "score": 2.5
          }
        }
      },
      "generation_config": {
        "additional_details": {}
      }
    },
    {
      "evaluation_name": "MS MARCO (TREC)",
      "source_data": {
        "dataset_name": "MS MARCO (TREC)",
        "source_type": "url",
        "url": [
          "https://storage.googleapis.com/crfm-helm-public/benchmark_output/releases/v0.4.0/groups/core_scenarios.json"
        ]
      },
      "metric_config": {
        "evaluation_description": "NDCG@10 on MS MARCO (TREC)",
        "lower_is_better": false,
        "score_type": "continuous",
        "min_score": 0.0,
        "max_score": 1.0
      },
      "score_details": {
        "score": -1.0,
        "details": {
          "description": "No matching runs",
          "tab": "Accuracy",
          "MS MARCO (regular) - RR@10 (Robustness)": {
            "description": "No matching runs",
            "tab": "Robustness",
            "score": null
          },
          "MS MARCO (TREC) - NDCG@10 (Robustness)": {
            "description": "No matching runs",
            "tab": "Robustness",
            "score": null
          },
          "MS MARCO (regular) - RR@10 (Fairness)": {
            "description": "No matching runs",
            "tab": "Fairness",
            "score": null
          },
          "MS MARCO (TREC) - NDCG@10 (Fairness)": {
            "description": "No matching runs",
            "tab": "Fairness",
            "score": null
          },
          "MS MARCO (regular) - Denoised inference time (s)": {
            "description": "No matching runs",
            "tab": "Efficiency",
            "score": null
          },
          "MS MARCO (TREC) - Denoised inference time (s)": {
            "description": "No matching runs",
            "tab": "Efficiency",
            "score": null
          },
          "MS MARCO (regular) - # eval": {
            "description": "No matching runs",
            "tab": "General information",
            "score": null
          },
          "MS MARCO (regular) - # train": {
            "description": "No matching runs",
            "tab": "General information",
            "score": null
          },
          "MS MARCO (regular) - truncated": {
            "description": "No matching runs",
            "tab": "General information",
            "score": null
          },
          "MS MARCO (regular) - # prompt tokens": {
            "description": "No matching runs",
            "tab": "General information",
            "score": null
          },
          "MS MARCO (regular) - # output tokens": {
            "description": "No matching runs",
            "tab": "General information",
            "score": null
          },
          "MS MARCO (regular) - # trials": {
            "description": "No matching runs",
            "tab": "General information",
            "score": null
          },
          "MS MARCO (TREC) - # eval": {
            "description": "No matching runs",
            "tab": "General information",
            "score": null
          },
          "MS MARCO (TREC) - # train": {
            "description": "No matching runs",
            "tab": "General information",
            "score": null
          },
          "MS MARCO (TREC) - truncated": {
            "description": "No matching runs",
            "tab": "General information",
            "score": null
          },
          "MS MARCO (TREC) - # prompt tokens": {
            "description": "No matching runs",
            "tab": "General information",
            "score": null
          },
          "MS MARCO (TREC) - # output tokens": {
            "description": "No matching runs",
            "tab": "General information",
            "score": null
          },
          "MS MARCO (TREC) - # trials": {
            "description": "No matching runs",
            "tab": "General information",
            "score": null
          },
          "MS MARCO (regular) - Stereotypes (race)": {
            "description": "No matching runs",
            "tab": "Bias",
            "score": null
          },
          "MS MARCO (regular) - Stereotypes (gender)": {
            "description": "No matching runs",
            "tab": "Bias",
            "score": null
          },
          "MS MARCO (regular) - Representation (race)": {
            "description": "No matching runs",
            "tab": "Bias",
            "score": null
          },
          "MS MARCO (regular) - Representation (gender)": {
            "description": "No matching runs",
            "tab": "Bias",
            "score": null
          },
          "MS MARCO (TREC) - Stereotypes (race)": {
            "description": "No matching runs",
            "tab": "Bias",
            "score": null
          },
          "MS MARCO (TREC) - Stereotypes (gender)": {
            "description": "No matching runs",
            "tab": "Bias",
            "score": null
          },
          "MS MARCO (TREC) - Representation (race)": {
            "description": "No matching runs",
            "tab": "Bias",
            "score": null
          },
          "MS MARCO (TREC) - Representation (gender)": {
            "description": "No matching runs",
            "tab": "Bias",
            "score": null
          },
          "MS MARCO (regular) - Toxic fraction": {
            "description": "No matching runs",
            "tab": "Toxicity",
            "score": null
          },
          "MS MARCO (TREC) - Toxic fraction": {
            "description": "No matching runs",
            "tab": "Toxicity",
            "score": null
          }
        }
      },
      "generation_config": {
        "additional_details": {}
      }
    },
    {
      "evaluation_name": "CNN/DailyMail",
      "source_data": {
        "dataset_name": "CNN/DailyMail",
        "source_type": "url",
        "url": [
          "https://storage.googleapis.com/crfm-helm-public/benchmark_output/releases/v0.4.0/groups/core_scenarios.json"
        ]
      },
      "metric_config": {
        "evaluation_description": "ROUGE-2 on CNN/DailyMail",
        "lower_is_better": false,
        "score_type": "continuous",
        "min_score": 0.0,
        "max_score": 1.0
      },
      "score_details": {
        "score": 0.017,
        "details": {
          "description": "min=0.009, mean=0.017, max=0.022, sum=0.103 (6)",
          "tab": "Accuracy",
          "CNN/DailyMail - Denoised inference time (s)": {
            "description": "min=2.334, mean=2.346, max=2.352, sum=14.074 (6)",
            "tab": "Efficiency",
            "score": 2.3457143735281405
          },
          "CNN/DailyMail - # eval": {
            "description": "min=466, mean=466, max=466, sum=2796 (6)",
            "tab": "General information",
            "score": 466.0
          },
          "CNN/DailyMail - # train": {
            "description": "min=5, mean=5, max=5, sum=30 (6)",
            "tab": "General information",
            "score": 5.0
          },
          "CNN/DailyMail - truncated": {
            "description": "min=0, mean=0, max=0, sum=0 (6)",
            "tab": "General information",
            "score": 0.0
          },
          "CNN/DailyMail - # prompt tokens": {
            "description": "min=1536.099, mean=1544.765, max=1562.099, sum=9268.592 (6)",
            "tab": "General information",
            "score": 1544.7653791130188
          },
          "CNN/DailyMail - # output tokens": {
            "description": "min=90.71, mean=102.407, max=108.32, sum=614.442 (6)",
            "tab": "General information",
            "score": 102.40701001430614
          },
          "CNN/DailyMail - # trials": {
            "description": "min=3, mean=3, max=3, sum=18 (6)",
            "tab": "General information",
            "score": 3.0
          },
          "CNN/DailyMail - Stereotypes (race)": {
            "description": "min=0.667, mean=0.667, max=0.667, sum=4 (6)",
            "tab": "Bias",
            "score": 0.6666666666666666
          },
          "CNN/DailyMail - Stereotypes (gender)": {
            "description": "min=0.406, mean=0.42, max=0.438, sum=2.518 (6)",
            "tab": "Bias",
            "score": 0.4196869049681346
          },
          "CNN/DailyMail - Representation (race)": {
            "description": "min=0.429, mean=0.588, max=0.667, sum=3.525 (6)",
            "tab": "Bias",
            "score": 0.5875706214689266
          },
          "CNN/DailyMail - Representation (gender)": {
            "description": "min=0.171, mean=0.206, max=0.237, sum=1.238 (6)",
            "tab": "Bias",
            "score": 0.20635612913269732
          },
          "CNN/DailyMail - Toxic fraction": {
            "description": "min=0, mean=0.001, max=0.002, sum=0.004 (6)",
            "tab": "Toxicity",
            "score": 0.000715307582260372
          },
          "CNN/DailyMail - SummaC": {
            "description": "min=-0.35, mean=-0.322, max=-0.296, sum=-0.965 (3)",
            "tab": "Summarization metrics",
            "score": -0.3217409663792838
          },
          "CNN/DailyMail - QAFactEval": {
            "description": "2 matching runs, but no matching metrics",
            "tab": "Summarization metrics",
            "score": null
          },
          "CNN/DailyMail - BERTScore (F1)": {
            "description": "min=-0.154, mean=-0.145, max=-0.127, sum=-0.435 (3)",
            "tab": "Summarization metrics",
            "score": -0.14496527560996572
          },
          "CNN/DailyMail - Coverage": {
            "description": "min=0.406, mean=0.541, max=0.615, sum=3.249 (6)",
            "tab": "Summarization metrics",
            "score": 0.5414806522156069
          },
          "CNN/DailyMail - Density": {
            "description": "min=0.681, mean=1.09, max=1.303, sum=6.541 (6)",
            "tab": "Summarization metrics",
            "score": 1.0902141864760964
          },
          "CNN/DailyMail - Compression": {
            "description": "min=6.289, mean=6.936, max=8.148, sum=41.615 (6)",
            "tab": "Summarization metrics",
            "score": 6.935882429972025
          },
          "CNN/DailyMail - HumanEval-faithfulness": {
            "description": "2 matching runs, but no matching metrics",
            "tab": "Summarization metrics",
            "score": null
          },
          "CNN/DailyMail - HumanEval-relevance": {
            "description": "2 matching runs, but no matching metrics",
            "tab": "Summarization metrics",
            "score": null
          },
          "CNN/DailyMail - HumanEval-coherence": {
            "description": "2 matching runs, but no matching metrics",
            "tab": "Summarization metrics",
            "score": null
          }
        }
      },
      "generation_config": {
        "additional_details": {}
      }
    },
    {
      "evaluation_name": "XSUM",
      "source_data": {
        "dataset_name": "XSUM",
        "source_type": "url",
        "url": [
          "https://storage.googleapis.com/crfm-helm-public/benchmark_output/releases/v0.4.0/groups/core_scenarios.json"
        ]
      },
      "metric_config": {
        "evaluation_description": "ROUGE-2 on XSUM",
        "lower_is_better": false,
        "score_type": "continuous",
        "min_score": 0.0,
        "max_score": 1.0
      },
      "score_details": {
        "score": 0.021,
        "details": {
          "description": "min=0.019, mean=0.021, max=0.022, sum=0.124 (6)",
          "tab": "Accuracy",
          "XSUM - Denoised inference time (s)": {
            "description": "min=1.653, mean=1.671, max=1.681, sum=10.028 (6)",
            "tab": "Efficiency",
            "score": 1.6713877910966286
          },
          "XSUM - # eval": {
            "description": "min=518, mean=518, max=518, sum=3108 (6)",
            "tab": "General information",
            "score": 518.0
          },
          "XSUM - # train": {
            "description": "min=5, mean=5, max=5, sum=30 (6)",
            "tab": "General information",
            "score": 5.0
          },
          "XSUM - truncated": {
            "description": "min=0, mean=0, max=0, sum=0 (6)",
            "tab": "General information",
            "score": 0.0
          },
          "XSUM - # prompt tokens": {
            "description": "min=1452.164, mean=1507.497, max=1536.164, sum=9044.985 (6)",
            "tab": "General information",
            "score": 1507.497425997426
          },
          "XSUM - # output tokens": {
            "description": "min=46.541, mean=49.401, max=51.544, sum=296.405 (6)",
            "tab": "General information",
            "score": 49.4009009009009
          },
          "XSUM - # trials": {
            "description": "min=3, mean=3, max=3, sum=18 (6)",
            "tab": "General information",
            "score": 3.0
          },
          "XSUM - Stereotypes (race)": {
            "description": "min=0.667, mean=0.667, max=0.667, sum=4 (6)",
            "tab": "Bias",
            "score": 0.6666666666666666
          },
          "XSUM - Stereotypes (gender)": {
            "description": "min=0.434, mean=0.442, max=0.456, sum=2.652 (6)",
            "tab": "Bias",
            "score": 0.4419820754826329
          },
          "XSUM - Representation (race)": {
            "description": "min=0.333, mean=0.501, max=0.595, sum=3.009 (6)",
            "tab": "Bias",
            "score": 0.5014430014430014
          },
          "XSUM - Representation (gender)": {
            "description": "min=0.209, mean=0.248, max=0.286, sum=1.485 (6)",
            "tab": "Bias",
            "score": 0.24754799603959324
          },
          "XSUM - Toxic fraction": {
            "description": "min=0, mean=0, max=0, sum=0 (6)",
            "tab": "Toxicity",
            "score": 0.0
          },
          "XSUM - SummaC": {
            "description": "min=-0.352, mean=-0.347, max=-0.344, sum=-1.04 (3)",
            "tab": "Summarization metrics",
            "score": -0.3466731809697447
          },
          "XSUM - QAFactEval": {
            "description": "min=0.856, mean=1.176, max=1.555, sum=7.058 (6)",
            "tab": "Summarization metrics",
            "score": 1.1763058409064706
          },
          "XSUM - BERTScore (F1)": {
            "description": "min=0.007, mean=0.031, max=0.057, sum=0.093 (3)",
            "tab": "Summarization metrics",
            "score": 0.031129963643441894
          },
          "XSUM - Coverage": {
            "description": "min=0.557, mean=0.567, max=0.574, sum=3.405 (6)",
            "tab": "Summarization metrics",
            "score": 0.5674251187038739
          },
          "XSUM - Density": {
            "description": "min=1.005, mean=1.041, max=1.081, sum=6.248 (6)",
            "tab": "Summarization metrics",
            "score": 1.0413571284332044
          },
          "XSUM - Compression": {
            "description": "min=9.397, mean=9.951, max=10.96, sum=59.706 (6)",
            "tab": "Summarization metrics",
            "score": 9.951019350255967
          },
          "XSUM - HumanEval-faithfulness": {
            "description": "2 matching runs, but no matching metrics",
            "tab": "Summarization metrics",
            "score": null
          },
          "XSUM - HumanEval-relevance": {
            "description": "2 matching runs, but no matching metrics",
            "tab": "Summarization metrics",
            "score": null
          },
          "XSUM - HumanEval-coherence": {
            "description": "2 matching runs, but no matching metrics",
            "tab": "Summarization metrics",
            "score": null
          }
        }
      },
      "generation_config": {
        "additional_details": {}
      }
    },
    {
      "evaluation_name": "IMDB",
      "source_data": {
        "dataset_name": "IMDB",
        "source_type": "url",
        "url": [
          "https://storage.googleapis.com/crfm-helm-public/benchmark_output/releases/v0.4.0/groups/core_scenarios.json"
        ]
      },
      "metric_config": {
        "evaluation_description": "EM on IMDB",
        "lower_is_better": false,
        "score_type": "continuous",
        "min_score": 0.0,
        "max_score": 1.0
      },
      "score_details": {
        "score": 0.836,
        "details": {
          "description": "min=0.776, mean=0.836, max=0.876, sum=2.509 (3)",
          "tab": "Accuracy",
          "IMDB - ECE (10-bin)": {
            "description": "min=0.369, mean=0.418, max=0.496, sum=1.255 (3)",
            "tab": "Calibration",
            "score": 0.41834259640752514
          },
          "IMDB - EM (Robustness)": {
            "description": "min=0.578, mean=0.719, max=0.79, sum=2.158 (3)",
            "tab": "Robustness",
            "score": 0.7193333333333333
          },
          "IMDB - EM (Fairness)": {
            "description": "min=0.709, mean=0.8, max=0.853, sum=2.4 (3)",
            "tab": "Fairness",
            "score": 0.7999999999999999
          },
          "IMDB - Denoised inference time (s)": {
            "description": "min=1.076, mean=1.137, max=1.23, sum=3.41 (3)",
            "tab": "Efficiency",
            "score": 1.1365543731623833
          },
          "IMDB - # eval": {
            "description": "min=1000, mean=1000, max=1000, sum=3000 (3)",
            "tab": "General information",
            "score": 1000.0
          },
          "IMDB - # train": {
            "description": "min=4.845, mean=4.929, max=4.982, sum=14.788 (3)",
            "tab": "General information",
            "score": 4.929333333333333
          },
          "IMDB - truncated": {
            "description": "min=0, mean=0, max=0, sum=0 (3)",
            "tab": "General information",
            "score": 0.0
          },
          "IMDB - # prompt tokens": {
            "description": "min=1161.789, mean=1402.276, max=1747.837, sum=4206.828 (3)",
            "tab": "General information",
            "score": 1402.2759999999998
          },
          "IMDB - # output tokens": {
            "description": "min=5, mean=5, max=5, sum=15 (3)",
            "tab": "General information",
            "score": 5.0
          },
          "IMDB - # trials": {
            "description": "min=3, mean=3, max=3, sum=9 (3)",
            "tab": "General information",
            "score": 3.0
          },
          "IMDB - Stereotypes (race)": {
            "description": "1 matching runs, but no matching metrics",
            "tab": "Bias",
            "score": null
          },
          "IMDB - Stereotypes (gender)": {
            "description": "1 matching runs, but no matching metrics",
            "tab": "Bias",
            "score": null
          },
          "IMDB - Representation (race)": {
            "description": "1 matching runs, but no matching metrics",
            "tab": "Bias",
            "score": null
          },
          "IMDB - Representation (gender)": {
            "description": "1 matching runs, but no matching metrics",
            "tab": "Bias",
            "score": null
          },
          "IMDB - Toxic fraction": {
            "description": "1 matching runs, but no matching metrics",
            "tab": "Toxicity",
            "score": null
          }
        }
      },
      "generation_config": {
        "additional_details": {}
      }
    },
    {
      "evaluation_name": "CivilComments",
      "source_data": {
        "dataset_name": "CivilComments",
        "source_type": "url",
        "url": [
          "https://storage.googleapis.com/crfm-helm-public/benchmark_output/releases/v0.4.0/groups/core_scenarios.json"
        ]
      },
      "metric_config": {
        "evaluation_description": "EM on CivilComments",
        "lower_is_better": false,
        "score_type": "continuous",
        "min_score": 0.0,
        "max_score": 1.0
      },
      "score_details": {
        "score": 0.49,
        "details": {
          "description": "min=0, mean=0.49, max=1, sum=26.448 (54)",
          "tab": "Accuracy",
          "CivilComments - ECE (10-bin)": {
            "description": "min=0.108, mean=0.437, max=0.784, sum=23.581 (54)",
            "tab": "Calibration",
            "score": 0.43669079652569004
          },
          "CivilComments - EM (Robustness)": {
            "description": "min=0, mean=0.463, max=1, sum=25.008 (54)",
            "tab": "Robustness",
            "score": 0.4631081891632545
          },
          "CivilComments - EM (Fairness)": {
            "description": "min=0, mean=0.456, max=0.998, sum=24.603 (54)",
            "tab": "Fairness",
            "score": 0.4556089334763174
          },
          "CivilComments - Denoised inference time (s)": {
            "description": "min=0.291, mean=0.41, max=0.737, sum=22.139 (54)",
            "tab": "Efficiency",
            "score": 0.4099806397254133
          },
          "CivilComments - # eval": {
            "description": "min=74, mean=371.556, max=683, sum=20064 (54)",
            "tab": "General information",
            "score": 371.55555555555554
          },
          "CivilComments - # train": {
            "description": "min=5, mean=5, max=5, sum=270 (54)",
            "tab": "General information",
            "score": 5.0
          },
          "CivilComments - truncated": {
            "description": "min=0, mean=0, max=0, sum=0 (54)",
            "tab": "General information",
            "score": 0.0
          },
          "CivilComments - # prompt tokens": {
            "description": "min=365, mean=729.671, max=1285.924, sum=39402.252 (54)",
            "tab": "General information",
            "score": 729.6713289334527
          },
          "CivilComments - # output tokens": {
            "description": "min=5, mean=5, max=5, sum=270 (54)",
            "tab": "General information",
            "score": 5.0
          },
          "CivilComments - # trials": {
            "description": "min=3, mean=3, max=3, sum=162 (54)",
            "tab": "General information",
            "score": 3.0
          },
          "CivilComments - Stereotypes (race)": {
            "description": "(0)",
            "tab": "Bias",
            "score": null
          },
          "CivilComments - Stereotypes (gender)": {
            "description": "(0)",
            "tab": "Bias",
            "score": null
          },
          "CivilComments - Representation (race)": {
            "description": "(0)",
            "tab": "Bias",
            "score": null
          },
          "CivilComments - Representation (gender)": {
            "description": "(0)",
            "tab": "Bias",
            "score": null
          },
          "CivilComments - Toxic fraction": {
            "description": "min=0, mean=0, max=0, sum=0 (54)",
            "tab": "Toxicity",
            "score": 0.0
          }
        }
      },
      "generation_config": {
        "additional_details": {}
      }
    },
    {
      "evaluation_name": "RAFT",
      "source_data": {
        "dataset_name": "RAFT",
        "source_type": "url",
        "url": [
          "https://storage.googleapis.com/crfm-helm-public/benchmark_output/releases/v0.4.0/groups/core_scenarios.json"
        ]
      },
      "metric_config": {
        "evaluation_description": "EM on RAFT",
        "lower_is_better": false,
        "score_type": "continuous",
        "min_score": 0.0,
        "max_score": 1.0
      },
      "score_details": {
        "score": 0.395,
        "details": {
          "description": "min=0, mean=0.395, max=0.975, sum=13.05 (33)",
          "tab": "Accuracy",
          "RAFT - ECE (10-bin)": {
            "description": "min=0.011, mean=0.278, max=0.881, sum=9.176 (33)",
            "tab": "Calibration",
            "score": 0.2780574023642052
          },
          "RAFT - EM (Robustness)": {
            "description": "min=0, mean=0.211, max=0.65, sum=6.975 (33)",
            "tab": "Robustness",
            "score": 0.21136363636363636
          },
          "RAFT - EM (Fairness)": {
            "description": "min=0, mean=0.342, max=0.975, sum=11.3 (33)",
            "tab": "Fairness",
            "score": 0.3424242424242424
          },
          "RAFT - Denoised inference time (s)": {
            "description": "min=0.132, mean=0.89, max=1.838, sum=29.385 (33)",
            "tab": "Efficiency",
            "score": 0.8904544346562409
          },
          "RAFT - # eval": {
            "description": "min=40, mean=40, max=40, sum=1320 (33)",
            "tab": "General information",
            "score": 40.0
          },
          "RAFT - # train": {
            "description": "min=0, mean=4.562, max=5, sum=150.55 (33)",
            "tab": "General information",
            "score": 4.5621212121212125
          },
          "RAFT - truncated": {
            "description": "min=0, mean=0, max=0, sum=0 (33)",
            "tab": "General information",
            "score": 0.0
          },
          "RAFT - # prompt tokens": {
            "description": "min=255.875, mean=784.961, max=1758.075, sum=25903.725 (33)",
            "tab": "General information",
            "score": 784.9613636363637
          },
          "RAFT - # output tokens": {
            "description": "min=5, mean=13.615, max=30, sum=449.3 (33)",
            "tab": "General information",
            "score": 13.615151515151515
          },
          "RAFT - # trials": {
            "description": "min=3, mean=3, max=3, sum=99 (33)",
            "tab": "General information",
            "score": 3.0
          },
          "RAFT - Stereotypes (race)": {
            "description": "(0)",
            "tab": "Bias",
            "score": null
          },
          "RAFT - Stereotypes (gender)": {
            "description": "(0)",
            "tab": "Bias",
            "score": null
          },
          "RAFT - Representation (race)": {
            "description": "(0)",
            "tab": "Bias",
            "score": null
          },
          "RAFT - Representation (gender)": {
            "description": "min=0.5, mean=0.5, max=0.5, sum=0.5 (1)",
            "tab": "Bias",
            "score": 0.5
          },
          "RAFT - Toxic fraction": {
            "description": "min=0, mean=0, max=0, sum=0 (33)",
            "tab": "Toxicity",
            "score": 0.0
          }
        }
      },
      "generation_config": {
        "additional_details": {}
      }
    }
  ]
}