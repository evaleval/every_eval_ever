{
  "schema_version": "0.2.0",
  "evaluation_id": "helm_classic/meta_OPT-66B/1770834891.1472661",
  "retrieved_timestamp": "1770834891.1472661",
  "source_metadata": {
    "source_name": "helm_classic",
    "source_type": "documentation",
    "source_organization_name": "crfm",
    "evaluator_relationship": "third_party"
  },
  "model_info": {
    "name": "OPT 66B",
    "id": "meta/OPT-66B",
    "developer": "meta",
    "inference_platform": "unknown"
  },
  "evaluation_results": [
    {
      "evaluation_name": "Mean win rate",
      "source_data": {
        "dataset_name": "helm_classic",
        "source_type": "url",
        "url": [
          "https://storage.googleapis.com/crfm-helm-public/benchmark_output/releases/v0.4.0/groups/core_scenarios.json"
        ]
      },
      "metric_config": {
        "evaluation_description": "How many models this model outperform on average (over columns).",
        "lower_is_better": false,
        "score_type": "continuous",
        "min_score": 0.0,
        "max_score": 1.0
      },
      "score_details": {
        "score": 0.448,
        "details": {
          "tab": "Accuracy",
          "Mean win rate - Calibration": {
            "description": null,
            "tab": "Calibration",
            "score": 0.2888771827640159
          },
          "Mean win rate - Robustness": {
            "description": null,
            "tab": "Robustness",
            "score": 0.43828848200372117
          },
          "Mean win rate - Fairness": {
            "description": null,
            "tab": "Fairness",
            "score": 0.4763117490592463
          },
          "Mean win rate - Efficiency": {
            "description": null,
            "tab": "Efficiency",
            "score": 0.466875
          },
          "Mean win rate - General information": {
            "description": null,
            "tab": "General information",
            "score": null
          },
          "Mean win rate - Bias": {
            "description": null,
            "tab": "Bias",
            "score": 0.6312224376358433
          },
          "Mean win rate - Toxicity": {
            "description": null,
            "tab": "Toxicity",
            "score": 0.3347556764223431
          },
          "Mean win rate - Summarization metrics": {
            "description": null,
            "tab": "Summarization metrics",
            "score": 0.5785714285714286
          }
        }
      },
      "generation_config": {
        "additional_details": {}
      }
    },
    {
      "evaluation_name": "MMLU",
      "source_data": {
        "dataset_name": "MMLU",
        "source_type": "url",
        "url": [
          "https://storage.googleapis.com/crfm-helm-public/benchmark_output/releases/v0.4.0/groups/core_scenarios.json"
        ]
      },
      "metric_config": {
        "evaluation_description": "EM on MMLU",
        "lower_is_better": false,
        "score_type": "continuous",
        "min_score": 0.0,
        "max_score": 1.0
      },
      "score_details": {
        "score": 0.276,
        "details": {
          "description": "min=0.2, mean=0.276, max=0.37, sum=4.141 (15)",
          "tab": "Accuracy",
          "MMLU - ECE (10-bin)": {
            "description": "min=0.101, mean=0.135, max=0.172, sum=2.031 (15)",
            "tab": "Calibration",
            "score": 0.13542563946906333
          },
          "MMLU - EM (Robustness)": {
            "description": "min=0.13, mean=0.216, max=0.32, sum=3.242 (15)",
            "tab": "Robustness",
            "score": 0.21610526315789472
          },
          "MMLU - EM (Fairness)": {
            "description": "min=0.18, mean=0.229, max=0.33, sum=3.44 (15)",
            "tab": "Fairness",
            "score": 0.22935672514619884
          },
          "MMLU - Denoised inference time (s)": {
            "description": "min=0.041, mean=0.055, max=0.081, sum=0.818 (15)",
            "tab": "Efficiency",
            "score": 0.05452067670741475
          },
          "MMLU - # eval": {
            "description": "min=100, mean=102.8, max=114, sum=1542 (15)",
            "tab": "General information",
            "score": 102.8
          },
          "MMLU - # train": {
            "description": "min=5, mean=5, max=5, sum=75 (15)",
            "tab": "General information",
            "score": 5.0
          },
          "MMLU - truncated": {
            "description": "min=0, mean=0, max=0, sum=0 (15)",
            "tab": "General information",
            "score": 0.0
          },
          "MMLU - # prompt tokens": {
            "description": "min=371.38, mean=472.274, max=624.07, sum=7084.111 (15)",
            "tab": "General information",
            "score": 472.2740350877193
          },
          "MMLU - # output tokens": {
            "description": "min=1, mean=1, max=1, sum=15 (15)",
            "tab": "General information",
            "score": 1.0
          },
          "MMLU - # trials": {
            "description": "min=3, mean=3, max=3, sum=45 (15)",
            "tab": "General information",
            "score": 3.0
          }
        }
      },
      "generation_config": {
        "additional_details": {}
      }
    },
    {
      "evaluation_name": "BoolQ",
      "source_data": {
        "dataset_name": "BoolQ",
        "source_type": "url",
        "url": [
          "https://storage.googleapis.com/crfm-helm-public/benchmark_output/releases/v0.4.0/groups/core_scenarios.json"
        ]
      },
      "metric_config": {
        "evaluation_description": "EM on BoolQ",
        "lower_is_better": false,
        "score_type": "continuous",
        "min_score": 0.0,
        "max_score": 1.0
      },
      "score_details": {
        "score": 0.76,
        "details": {
          "description": "min=0.753, mean=0.76, max=0.764, sum=2.281 (3)",
          "tab": "Accuracy",
          "BoolQ - ECE (10-bin)": {
            "description": "min=0.193, mean=0.2, max=0.206, sum=0.601 (3)",
            "tab": "Calibration",
            "score": 0.20047176103986394
          },
          "BoolQ - EM (Robustness)": {
            "description": "min=0.666, mean=0.683, max=0.701, sum=2.049 (3)",
            "tab": "Robustness",
            "score": 0.6829999999999999
          },
          "BoolQ - EM (Fairness)": {
            "description": "min=0.696, mean=0.71, max=0.721, sum=2.131 (3)",
            "tab": "Fairness",
            "score": 0.7103333333333333
          },
          "BoolQ - Denoised inference time (s)": {
            "description": "min=0.272, mean=0.834, max=1.907, sum=2.501 (3)",
            "tab": "Efficiency",
            "score": 0.8336340090708299
          },
          "BoolQ - # eval": {
            "description": "min=1000, mean=1000, max=1000, sum=3000 (3)",
            "tab": "General information",
            "score": 1000.0
          },
          "BoolQ - # train": {
            "description": "min=5, mean=5, max=5, sum=15 (3)",
            "tab": "General information",
            "score": 5.0
          },
          "BoolQ - truncated": {
            "description": "min=0, mean=0, max=0, sum=0 (3)",
            "tab": "General information",
            "score": 0.0
          },
          "BoolQ - # prompt tokens": {
            "description": "min=660.073, mean=908.406, max=1242.073, sum=2725.219 (3)",
            "tab": "General information",
            "score": 908.4063333333334
          },
          "BoolQ - # output tokens": {
            "description": "min=5, mean=5, max=5, sum=15 (3)",
            "tab": "General information",
            "score": 5.0
          },
          "BoolQ - # trials": {
            "description": "min=3, mean=3, max=3, sum=9 (3)",
            "tab": "General information",
            "score": 3.0
          },
          "BoolQ - Stereotypes (race)": {
            "description": "(0)",
            "tab": "Bias",
            "score": null
          },
          "BoolQ - Stereotypes (gender)": {
            "description": "(0)",
            "tab": "Bias",
            "score": null
          },
          "BoolQ - Representation (race)": {
            "description": "(0)",
            "tab": "Bias",
            "score": null
          },
          "BoolQ - Representation (gender)": {
            "description": "(0)",
            "tab": "Bias",
            "score": null
          },
          "BoolQ - Toxic fraction": {
            "description": "min=0, mean=0, max=0, sum=0 (3)",
            "tab": "Toxicity",
            "score": 0.0
          }
        }
      },
      "generation_config": {
        "additional_details": {}
      }
    },
    {
      "evaluation_name": "NarrativeQA",
      "source_data": {
        "dataset_name": "NarrativeQA",
        "source_type": "url",
        "url": [
          "https://storage.googleapis.com/crfm-helm-public/benchmark_output/releases/v0.4.0/groups/core_scenarios.json"
        ]
      },
      "metric_config": {
        "evaluation_description": "F1 on NarrativeQA",
        "lower_is_better": false,
        "score_type": "continuous",
        "min_score": 0.0,
        "max_score": 1.0
      },
      "score_details": {
        "score": 0.638,
        "details": {
          "description": "min=0.618, mean=0.638, max=0.655, sum=1.913 (3)",
          "tab": "Accuracy",
          "NarrativeQA - ECE (10-bin)": {
            "description": "min=0.224, mean=0.245, max=0.264, sum=0.734 (3)",
            "tab": "Calibration",
            "score": 0.2445466042880168
          },
          "NarrativeQA - F1 (Robustness)": {
            "description": "min=0.364, mean=0.397, max=0.421, sum=1.19 (3)",
            "tab": "Robustness",
            "score": 0.39653941552028354
          },
          "NarrativeQA - F1 (Fairness)": {
            "description": "min=0.497, mean=0.526, max=0.543, sum=1.579 (3)",
            "tab": "Fairness",
            "score": 0.5262433008374211
          },
          "NarrativeQA - Denoised inference time (s)": {
            "description": "min=0.939, mean=1.98, max=3.714, sum=5.939 (3)",
            "tab": "Efficiency",
            "score": 1.979606440811339
          },
          "NarrativeQA - # eval": {
            "description": "min=355, mean=355, max=355, sum=1065 (3)",
            "tab": "General information",
            "score": 355.0
          },
          "NarrativeQA - # train": {
            "description": "min=1.051, mean=1.647, max=2.085, sum=4.941 (3)",
            "tab": "General information",
            "score": 1.6469483568075116
          },
          "NarrativeQA - truncated": {
            "description": "min=0, mean=0, max=0, sum=0 (3)",
            "tab": "General information",
            "score": 0.0
          },
          "NarrativeQA - # prompt tokens": {
            "description": "min=1601.955, mean=1652.377, max=1705.003, sum=4957.132 (3)",
            "tab": "General information",
            "score": 1652.3774647887324
          },
          "NarrativeQA - # output tokens": {
            "description": "min=39.707, mean=50.904, max=65.363, sum=152.713 (3)",
            "tab": "General information",
            "score": 50.90422535211267
          },
          "NarrativeQA - # trials": {
            "description": "min=3, mean=3, max=3, sum=9 (3)",
            "tab": "General information",
            "score": 3.0
          },
          "NarrativeQA - Stereotypes (race)": {
            "description": "(0)",
            "tab": "Bias",
            "score": null
          },
          "NarrativeQA - Stereotypes (gender)": {
            "description": "min=0.406, mean=0.416, max=0.425, sum=1.248 (3)",
            "tab": "Bias",
            "score": 0.41597222222222224
          },
          "NarrativeQA - Representation (race)": {
            "description": "min=0.333, mean=0.556, max=0.667, sum=1.667 (3)",
            "tab": "Bias",
            "score": 0.5555555555555556
          },
          "NarrativeQA - Representation (gender)": {
            "description": "min=0.164, mean=0.191, max=0.207, sum=0.574 (3)",
            "tab": "Bias",
            "score": 0.1911771437726737
          },
          "NarrativeQA - Toxic fraction": {
            "description": "min=0.02, mean=0.022, max=0.025, sum=0.065 (3)",
            "tab": "Toxicity",
            "score": 0.0215962441314554
          }
        }
      },
      "generation_config": {
        "additional_details": {}
      }
    },
    {
      "evaluation_name": "NaturalQuestions (open-book)",
      "source_data": {
        "dataset_name": "NaturalQuestions (open-book)",
        "source_type": "url",
        "url": [
          "https://storage.googleapis.com/crfm-helm-public/benchmark_output/releases/v0.4.0/groups/core_scenarios.json"
        ]
      },
      "metric_config": {
        "evaluation_description": "F1 on NaturalQuestions (open-book)",
        "lower_is_better": false,
        "score_type": "continuous",
        "min_score": 0.0,
        "max_score": 1.0
      },
      "score_details": {
        "score": 0.596,
        "details": {
          "description": "min=0.582, mean=0.596, max=0.615, sum=1.788 (3)",
          "tab": "Accuracy",
          "NaturalQuestions (closed-book) - ECE (10-bin)": {
            "description": "min=0.134, mean=0.141, max=0.149, sum=0.423 (3)",
            "tab": "Calibration",
            "score": 0.14107540425227785
          },
          "NaturalQuestions (open-book) - ECE (10-bin)": {
            "description": "min=0.379, mean=0.384, max=0.387, sum=1.153 (3)",
            "tab": "Calibration",
            "score": 0.38437204570087863
          },
          "NaturalQuestions (closed-book) - F1 (Robustness)": {
            "description": "min=0.2, mean=0.206, max=0.216, sum=0.619 (3)",
            "tab": "Robustness",
            "score": 0.20625206311676839
          },
          "NaturalQuestions (open-book) - F1 (Robustness)": {
            "description": "min=0.419, mean=0.458, max=0.503, sum=1.373 (3)",
            "tab": "Robustness",
            "score": 0.45767430702477907
          },
          "NaturalQuestions (closed-book) - F1 (Fairness)": {
            "description": "min=0.215, mean=0.218, max=0.221, sum=0.654 (3)",
            "tab": "Fairness",
            "score": 0.2180459446078801
          },
          "NaturalQuestions (open-book) - F1 (Fairness)": {
            "description": "min=0.52, mean=0.536, max=0.558, sum=1.607 (3)",
            "tab": "Fairness",
            "score": 0.5357020972773482
          },
          "NaturalQuestions (closed-book) - Denoised inference time (s)": {
            "description": "min=0.471, mean=0.611, max=0.739, sum=1.834 (3)",
            "tab": "Efficiency",
            "score": 0.611190575244526
          },
          "NaturalQuestions (open-book) - Denoised inference time (s)": {
            "description": "min=2.887, mean=3.632, max=4.314, sum=10.896 (3)",
            "tab": "Efficiency",
            "score": 3.631964569965005
          },
          "NaturalQuestions (closed-book) - # eval": {
            "description": "min=1000, mean=1000, max=1000, sum=3000 (3)",
            "tab": "General information",
            "score": 1000.0
          },
          "NaturalQuestions (closed-book) - # train": {
            "description": "min=5, mean=5, max=5, sum=15 (3)",
            "tab": "General information",
            "score": 5.0
          },
          "NaturalQuestions (closed-book) - truncated": {
            "description": "min=0, mean=0, max=0, sum=0 (3)",
            "tab": "General information",
            "score": 0.0
          },
          "NaturalQuestions (closed-book) - # prompt tokens": {
            "description": "min=110.254, mean=112.254, max=116.254, sum=336.762 (3)",
            "tab": "General information",
            "score": 112.254
          },
          "NaturalQuestions (closed-book) - # output tokens": {
            "description": "min=128.956, mean=153.231, max=173.545, sum=459.692 (3)",
            "tab": "General information",
            "score": 153.23066666666668
          },
          "NaturalQuestions (closed-book) - # trials": {
            "description": "min=3, mean=3, max=3, sum=9 (3)",
            "tab": "General information",
            "score": 3.0
          },
          "NaturalQuestions (open-book) - # eval": {
            "description": "min=1000, mean=1000, max=1000, sum=3000 (3)",
            "tab": "General information",
            "score": 1000.0
          },
          "NaturalQuestions (open-book) - # train": {
            "description": "min=4.647, mean=4.691, max=4.724, sum=14.074 (3)",
            "tab": "General information",
            "score": 4.691333333333334
          },
          "NaturalQuestions (open-book) - truncated": {
            "description": "min=0.036, mean=0.036, max=0.036, sum=0.108 (3)",
            "tab": "General information",
            "score": 0.036
          },
          "NaturalQuestions (open-book) - # prompt tokens": {
            "description": "min=1231.212, mean=1419.574, max=1523.257, sum=4258.721 (3)",
            "tab": "General information",
            "score": 1419.5736666666664
          },
          "NaturalQuestions (open-book) - # output tokens": {
            "description": "min=168.231, mean=211.805, max=244.906, sum=635.415 (3)",
            "tab": "General information",
            "score": 211.80499999999998
          },
          "NaturalQuestions (open-book) - # trials": {
            "description": "min=3, mean=3, max=3, sum=9 (3)",
            "tab": "General information",
            "score": 3.0
          },
          "NaturalQuestions (closed-book) - Stereotypes (race)": {
            "description": "(0)",
            "tab": "Bias",
            "score": null
          },
          "NaturalQuestions (closed-book) - Stereotypes (gender)": {
            "description": "min=0, mean=0.278, max=0.5, sum=0.833 (3)",
            "tab": "Bias",
            "score": 0.27777777777777773
          },
          "NaturalQuestions (closed-book) - Representation (race)": {
            "description": "min=0.467, mean=0.481, max=0.491, sum=1.444 (3)",
            "tab": "Bias",
            "score": 0.481339792158324
          },
          "NaturalQuestions (closed-book) - Representation (gender)": {
            "description": "min=0.106, mean=0.156, max=0.233, sum=0.469 (3)",
            "tab": "Bias",
            "score": 0.156341189674523
          },
          "NaturalQuestions (open-book) - Stereotypes (race)": {
            "description": "min=0.667, mean=0.667, max=0.667, sum=0.667 (1)",
            "tab": "Bias",
            "score": 0.6666666666666666
          },
          "NaturalQuestions (open-book) - Stereotypes (gender)": {
            "description": "min=0.287, mean=0.338, max=0.395, sum=1.015 (3)",
            "tab": "Bias",
            "score": 0.33841269841269833
          },
          "NaturalQuestions (open-book) - Representation (race)": {
            "description": "min=0.4, mean=0.427, max=0.48, sum=1.281 (3)",
            "tab": "Bias",
            "score": 0.42701178032188486
          },
          "NaturalQuestions (open-book) - Representation (gender)": {
            "description": "min=0.116, mean=0.119, max=0.124, sum=0.357 (3)",
            "tab": "Bias",
            "score": 0.11888541157186479
          },
          "NaturalQuestions (closed-book) - Toxic fraction": {
            "description": "min=0.001, mean=0.001, max=0.001, sum=0.003 (3)",
            "tab": "Toxicity",
            "score": 0.001
          },
          "NaturalQuestions (open-book) - Toxic fraction": {
            "description": "min=0.001, mean=0.002, max=0.002, sum=0.005 (3)",
            "tab": "Toxicity",
            "score": 0.0016666666666666668
          }
        }
      },
      "generation_config": {
        "additional_details": {}
      }
    },
    {
      "evaluation_name": "QuAC",
      "source_data": {
        "dataset_name": "QuAC",
        "source_type": "url",
        "url": [
          "https://storage.googleapis.com/crfm-helm-public/benchmark_output/releases/v0.4.0/groups/core_scenarios.json"
        ]
      },
      "metric_config": {
        "evaluation_description": "F1 on QuAC",
        "lower_is_better": false,
        "score_type": "continuous",
        "min_score": 0.0,
        "max_score": 1.0
      },
      "score_details": {
        "score": 0.357,
        "details": {
          "description": "min=0.35, mean=0.357, max=0.366, sum=1.07 (3)",
          "tab": "Accuracy",
          "QuAC - ECE (10-bin)": {
            "description": "min=0.135, mean=0.154, max=0.176, sum=0.461 (3)",
            "tab": "Calibration",
            "score": 0.15357329550060583
          },
          "QuAC - F1 (Robustness)": {
            "description": "min=0.177, mean=0.199, max=0.217, sum=0.597 (3)",
            "tab": "Robustness",
            "score": 0.19914898808715295
          },
          "QuAC - F1 (Fairness)": {
            "description": "min=0.267, mean=0.268, max=0.27, sum=0.805 (3)",
            "tab": "Fairness",
            "score": 0.26839685415319225
          },
          "QuAC - Denoised inference time (s)": {
            "description": "min=2.636, mean=2.658, max=2.683, sum=7.974 (3)",
            "tab": "Efficiency",
            "score": 2.6581093871351746
          },
          "QuAC - # eval": {
            "description": "min=1000, mean=1000, max=1000, sum=3000 (3)",
            "tab": "General information",
            "score": 1000.0
          },
          "QuAC - # train": {
            "description": "min=0.845, mean=0.944, max=1.086, sum=2.833 (3)",
            "tab": "General information",
            "score": 0.9443333333333334
          },
          "QuAC - truncated": {
            "description": "min=0.016, mean=0.016, max=0.016, sum=0.048 (3)",
            "tab": "General information",
            "score": 0.016
          },
          "QuAC - # prompt tokens": {
            "description": "min=1625.523, mean=1644.831, max=1670.605, sum=4934.492 (3)",
            "tab": "General information",
            "score": 1644.8306666666667
          },
          "QuAC - # output tokens": {
            "description": "min=89.614, mean=91.909, max=95.996, sum=275.728 (3)",
            "tab": "General information",
            "score": 91.90933333333334
          },
          "QuAC - # trials": {
            "description": "min=3, mean=3, max=3, sum=9 (3)",
            "tab": "General information",
            "score": 3.0
          },
          "QuAC - Stereotypes (race)": {
            "description": "min=0.556, mean=0.592, max=0.619, sum=1.775 (3)",
            "tab": "Bias",
            "score": 0.5915343915343915
          },
          "QuAC - Stereotypes (gender)": {
            "description": "min=0.398, mean=0.413, max=0.424, sum=1.239 (3)",
            "tab": "Bias",
            "score": 0.41297615039041286
          },
          "QuAC - Representation (race)": {
            "description": "min=0.228, mean=0.272, max=0.324, sum=0.816 (3)",
            "tab": "Bias",
            "score": 0.27205505897640186
          },
          "QuAC - Representation (gender)": {
            "description": "min=0.239, mean=0.245, max=0.252, sum=0.734 (3)",
            "tab": "Bias",
            "score": 0.2445248639131045
          },
          "QuAC - Toxic fraction": {
            "description": "min=0.001, mean=0.001, max=0.002, sum=0.004 (3)",
            "tab": "Toxicity",
            "score": 0.0013333333333333333
          }
        }
      },
      "generation_config": {
        "additional_details": {}
      }
    },
    {
      "evaluation_name": "HellaSwag",
      "source_data": {
        "dataset_name": "HellaSwag",
        "source_type": "url",
        "url": [
          "https://storage.googleapis.com/crfm-helm-public/benchmark_output/releases/v0.4.0/groups/core_scenarios.json"
        ]
      },
      "metric_config": {
        "evaluation_description": "EM on HellaSwag",
        "lower_is_better": false,
        "score_type": "continuous",
        "min_score": 0.0,
        "max_score": 1.0
      },
      "score_details": {
        "score": 0.745,
        "details": {
          "description": "min=0.745, mean=0.745, max=0.745, sum=0.745 (1)",
          "tab": "Accuracy",
          "HellaSwag - ECE (10-bin)": {
            "description": "min=0.293, mean=0.293, max=0.293, sum=0.293 (1)",
            "tab": "Calibration",
            "score": 0.29326475041918015
          },
          "HellaSwag - EM (Robustness)": {
            "description": "min=0.699, mean=0.699, max=0.699, sum=0.699 (1)",
            "tab": "Robustness",
            "score": 0.699
          },
          "HellaSwag - EM (Fairness)": {
            "description": "min=0.597, mean=0.597, max=0.597, sum=0.597 (1)",
            "tab": "Fairness",
            "score": 0.597
          },
          "HellaSwag - Denoised inference time (s)": {
            "description": "min=0.971, mean=0.971, max=0.971, sum=0.971 (1)",
            "tab": "Efficiency",
            "score": 0.9708148735597889
          },
          "HellaSwag - # eval": {
            "description": "min=1000, mean=1000, max=1000, sum=1000 (1)",
            "tab": "General information",
            "score": 1000.0
          },
          "HellaSwag - # train": {
            "description": "min=0, mean=0, max=0, sum=0 (1)",
            "tab": "General information",
            "score": 0.0
          },
          "HellaSwag - truncated": {
            "description": "min=0, mean=0, max=0, sum=0 (1)",
            "tab": "General information",
            "score": 0.0
          },
          "HellaSwag - # prompt tokens": {
            "description": "min=87.888, mean=87.888, max=87.888, sum=87.888 (1)",
            "tab": "General information",
            "score": 87.888
          },
          "HellaSwag - # output tokens": {
            "description": "min=0.2, mean=0.2, max=0.2, sum=0.2 (1)",
            "tab": "General information",
            "score": 0.2
          },
          "HellaSwag - # trials": {
            "description": "min=1, mean=1, max=1, sum=1 (1)",
            "tab": "General information",
            "score": 1.0
          }
        }
      },
      "generation_config": {
        "additional_details": {}
      }
    },
    {
      "evaluation_name": "OpenbookQA",
      "source_data": {
        "dataset_name": "OpenbookQA",
        "source_type": "url",
        "url": [
          "https://storage.googleapis.com/crfm-helm-public/benchmark_output/releases/v0.4.0/groups/core_scenarios.json"
        ]
      },
      "metric_config": {
        "evaluation_description": "EM on OpenbookQA",
        "lower_is_better": false,
        "score_type": "continuous",
        "min_score": 0.0,
        "max_score": 1.0
      },
      "score_details": {
        "score": 0.534,
        "details": {
          "description": "min=0.534, mean=0.534, max=0.534, sum=0.534 (1)",
          "tab": "Accuracy",
          "OpenbookQA - ECE (10-bin)": {
            "description": "min=0.237, mean=0.237, max=0.237, sum=0.237 (1)",
            "tab": "Calibration",
            "score": 0.2373615873422732
          },
          "OpenbookQA - EM (Robustness)": {
            "description": "min=0.45, mean=0.45, max=0.45, sum=0.45 (1)",
            "tab": "Robustness",
            "score": 0.45
          },
          "OpenbookQA - EM (Fairness)": {
            "description": "min=0.454, mean=0.454, max=0.454, sum=0.454 (1)",
            "tab": "Fairness",
            "score": 0.454
          },
          "OpenbookQA - Denoised inference time (s)": {
            "description": "min=0.188, mean=0.188, max=0.188, sum=0.188 (1)",
            "tab": "Efficiency",
            "score": 0.18798254558309685
          },
          "OpenbookQA - # eval": {
            "description": "min=500, mean=500, max=500, sum=500 (1)",
            "tab": "General information",
            "score": 500.0
          },
          "OpenbookQA - # train": {
            "description": "min=0, mean=0, max=0, sum=0 (1)",
            "tab": "General information",
            "score": 0.0
          },
          "OpenbookQA - truncated": {
            "description": "min=0, mean=0, max=0, sum=0 (1)",
            "tab": "General information",
            "score": 0.0
          },
          "OpenbookQA - # prompt tokens": {
            "description": "min=5.27, mean=5.27, max=5.27, sum=5.27 (1)",
            "tab": "General information",
            "score": 5.27
          },
          "OpenbookQA - # output tokens": {
            "description": "min=1, mean=1, max=1, sum=1 (1)",
            "tab": "General information",
            "score": 1.0
          },
          "OpenbookQA - # trials": {
            "description": "min=1, mean=1, max=1, sum=1 (1)",
            "tab": "General information",
            "score": 1.0
          }
        }
      },
      "generation_config": {
        "additional_details": {}
      }
    },
    {
      "evaluation_name": "TruthfulQA",
      "source_data": {
        "dataset_name": "TruthfulQA",
        "source_type": "url",
        "url": [
          "https://storage.googleapis.com/crfm-helm-public/benchmark_output/releases/v0.4.0/groups/core_scenarios.json"
        ]
      },
      "metric_config": {
        "evaluation_description": "EM on TruthfulQA",
        "lower_is_better": false,
        "score_type": "continuous",
        "min_score": 0.0,
        "max_score": 1.0
      },
      "score_details": {
        "score": 0.201,
        "details": {
          "description": "min=0.185, mean=0.201, max=0.22, sum=0.804 (4)",
          "tab": "Accuracy",
          "TruthfulQA - ECE (10-bin)": {
            "description": "min=0.047, mean=0.073, max=0.084, sum=0.293 (4)",
            "tab": "Calibration",
            "score": 0.07328356622626138
          },
          "TruthfulQA - EM (Robustness)": {
            "description": "min=0.135, mean=0.174, max=0.206, sum=0.694 (4)",
            "tab": "Robustness",
            "score": 0.1735474006116208
          },
          "TruthfulQA - EM (Fairness)": {
            "description": "min=0.145, mean=0.173, max=0.206, sum=0.693 (4)",
            "tab": "Fairness",
            "score": 0.17316513761467892
          },
          "TruthfulQA - Denoised inference time (s)": {
            "description": "min=0.033, mean=0.041, max=0.046, sum=0.163 (4)",
            "tab": "Efficiency",
            "score": 0.04074840224276806
          },
          "TruthfulQA - # eval": {
            "description": "min=654, mean=654, max=654, sum=2616 (4)",
            "tab": "General information",
            "score": 654.0
          },
          "TruthfulQA - # train": {
            "description": "min=0, mean=3.75, max=5, sum=15 (4)",
            "tab": "General information",
            "score": 3.75
          },
          "TruthfulQA - truncated": {
            "description": "min=0, mean=0, max=0, sum=0 (4)",
            "tab": "General information",
            "score": 0.0
          },
          "TruthfulQA - # prompt tokens": {
            "description": "min=85.121, mean=404.621, max=529.121, sum=1618.483 (4)",
            "tab": "General information",
            "score": 404.62079510703364
          },
          "TruthfulQA - # output tokens": {
            "description": "min=1, mean=1, max=1, sum=4 (4)",
            "tab": "General information",
            "score": 1.0
          },
          "TruthfulQA - # trials": {
            "description": "min=1, mean=2.5, max=3, sum=10 (4)",
            "tab": "General information",
            "score": 2.5
          }
        }
      },
      "generation_config": {
        "additional_details": {}
      }
    },
    {
      "evaluation_name": "MS MARCO (TREC)",
      "source_data": {
        "dataset_name": "MS MARCO (TREC)",
        "source_type": "url",
        "url": [
          "https://storage.googleapis.com/crfm-helm-public/benchmark_output/releases/v0.4.0/groups/core_scenarios.json"
        ]
      },
      "metric_config": {
        "evaluation_description": "NDCG@10 on MS MARCO (TREC)",
        "lower_is_better": false,
        "score_type": "continuous",
        "min_score": 0.0,
        "max_score": 1.0
      },
      "score_details": {
        "score": 0.482,
        "details": {
          "description": "min=0.467, mean=0.482, max=0.511, sum=1.446 (3)",
          "tab": "Accuracy",
          "MS MARCO (regular) - RR@10 (Robustness)": {
            "description": "min=0.175, mean=0.179, max=0.187, sum=0.537 (3)",
            "tab": "Robustness",
            "score": 0.1788788359788358
          },
          "MS MARCO (TREC) - NDCG@10 (Robustness)": {
            "description": "min=0.421, mean=0.437, max=0.46, sum=1.31 (3)",
            "tab": "Robustness",
            "score": 0.436684763137285
          },
          "MS MARCO (regular) - RR@10 (Fairness)": {
            "description": "min=0.21, mean=0.214, max=0.221, sum=0.642 (3)",
            "tab": "Fairness",
            "score": 0.2139329365079363
          },
          "MS MARCO (TREC) - NDCG@10 (Fairness)": {
            "description": "min=0.45, mean=0.471, max=0.501, sum=1.412 (3)",
            "tab": "Fairness",
            "score": 0.4706976603850948
          },
          "MS MARCO (regular) - Denoised inference time (s)": {
            "description": "min=0.066, mean=0.076, max=0.089, sum=0.227 (3)",
            "tab": "Efficiency",
            "score": 0.07567241383876121
          },
          "MS MARCO (TREC) - Denoised inference time (s)": {
            "description": "min=0.061, mean=0.102, max=0.183, sum=0.305 (3)",
            "tab": "Efficiency",
            "score": 0.10182954292591756
          },
          "MS MARCO (regular) - # eval": {
            "description": "min=1000, mean=1000, max=1000, sum=3000 (3)",
            "tab": "General information",
            "score": 1000.0
          },
          "MS MARCO (regular) - # train": {
            "description": "min=2, mean=2, max=2, sum=6 (3)",
            "tab": "General information",
            "score": 2.0
          },
          "MS MARCO (regular) - truncated": {
            "description": "min=0, mean=0, max=0, sum=0 (3)",
            "tab": "General information",
            "score": 0.0
          },
          "MS MARCO (regular) - # prompt tokens": {
            "description": "min=495.232, mean=532.565, max=577.232, sum=1597.696 (3)",
            "tab": "General information",
            "score": 532.5653333333333
          },
          "MS MARCO (regular) - # output tokens": {
            "description": "min=5, mean=5, max=5, sum=15 (3)",
            "tab": "General information",
            "score": 5.0
          },
          "MS MARCO (regular) - # trials": {
            "description": "min=3, mean=3, max=3, sum=9 (3)",
            "tab": "General information",
            "score": 3.0
          },
          "MS MARCO (TREC) - # eval": {
            "description": "min=43, mean=43, max=43, sum=129 (3)",
            "tab": "General information",
            "score": 43.0
          },
          "MS MARCO (TREC) - # train": {
            "description": "min=2, mean=2, max=2, sum=6 (3)",
            "tab": "General information",
            "score": 2.0
          },
          "MS MARCO (TREC) - truncated": {
            "description": "min=0, mean=0, max=0, sum=0 (3)",
            "tab": "General information",
            "score": 0.0
          },
          "MS MARCO (TREC) - # prompt tokens": {
            "description": "min=478.488, mean=515.822, max=560.488, sum=1547.465 (3)",
            "tab": "General information",
            "score": 515.8217054263565
          },
          "MS MARCO (TREC) - # output tokens": {
            "description": "min=5, mean=5, max=5, sum=15 (3)",
            "tab": "General information",
            "score": 5.0
          },
          "MS MARCO (TREC) - # trials": {
            "description": "min=3, mean=3, max=3, sum=9 (3)",
            "tab": "General information",
            "score": 3.0
          },
          "MS MARCO (regular) - Stereotypes (race)": {
            "description": "1 matching runs, but no matching metrics",
            "tab": "Bias",
            "score": null
          },
          "MS MARCO (regular) - Stereotypes (gender)": {
            "description": "1 matching runs, but no matching metrics",
            "tab": "Bias",
            "score": null
          },
          "MS MARCO (regular) - Representation (race)": {
            "description": "1 matching runs, but no matching metrics",
            "tab": "Bias",
            "score": null
          },
          "MS MARCO (regular) - Representation (gender)": {
            "description": "1 matching runs, but no matching metrics",
            "tab": "Bias",
            "score": null
          },
          "MS MARCO (TREC) - Stereotypes (race)": {
            "description": "1 matching runs, but no matching metrics",
            "tab": "Bias",
            "score": null
          },
          "MS MARCO (TREC) - Stereotypes (gender)": {
            "description": "1 matching runs, but no matching metrics",
            "tab": "Bias",
            "score": null
          },
          "MS MARCO (TREC) - Representation (race)": {
            "description": "1 matching runs, but no matching metrics",
            "tab": "Bias",
            "score": null
          },
          "MS MARCO (TREC) - Representation (gender)": {
            "description": "1 matching runs, but no matching metrics",
            "tab": "Bias",
            "score": null
          },
          "MS MARCO (regular) - Toxic fraction": {
            "description": "1 matching runs, but no matching metrics",
            "tab": "Toxicity",
            "score": null
          },
          "MS MARCO (TREC) - Toxic fraction": {
            "description": "1 matching runs, but no matching metrics",
            "tab": "Toxicity",
            "score": null
          }
        }
      },
      "generation_config": {
        "additional_details": {}
      }
    },
    {
      "evaluation_name": "CNN/DailyMail",
      "source_data": {
        "dataset_name": "CNN/DailyMail",
        "source_type": "url",
        "url": [
          "https://storage.googleapis.com/crfm-helm-public/benchmark_output/releases/v0.4.0/groups/core_scenarios.json"
        ]
      },
      "metric_config": {
        "evaluation_description": "ROUGE-2 on CNN/DailyMail",
        "lower_is_better": false,
        "score_type": "continuous",
        "min_score": 0.0,
        "max_score": 1.0
      },
      "score_details": {
        "score": 0.136,
        "details": {
          "description": "min=0.119, mean=0.136, max=0.149, sum=0.816 (6)",
          "tab": "Accuracy",
          "CNN/DailyMail - Denoised inference time (s)": {
            "description": "min=1.828, mean=1.972, max=2.045, sum=11.831 (6)",
            "tab": "Efficiency",
            "score": 1.971851329588582
          },
          "CNN/DailyMail - # eval": {
            "description": "min=466, mean=466, max=466, sum=2796 (6)",
            "tab": "General information",
            "score": 466.0
          },
          "CNN/DailyMail - # train": {
            "description": "min=5, mean=5, max=5, sum=30 (6)",
            "tab": "General information",
            "score": 5.0
          },
          "CNN/DailyMail - truncated": {
            "description": "min=0, mean=0, max=0, sum=0 (6)",
            "tab": "General information",
            "score": 0.0
          },
          "CNN/DailyMail - # prompt tokens": {
            "description": "min=1531.586, mean=1549.919, max=1567.586, sum=9299.515 (6)",
            "tab": "General information",
            "score": 1549.9191702432045
          },
          "CNN/DailyMail - # output tokens": {
            "description": "min=72.955, mean=77.928, max=83.685, sum=467.567 (6)",
            "tab": "General information",
            "score": 77.9277539341917
          },
          "CNN/DailyMail - # trials": {
            "description": "min=3, mean=3, max=3, sum=18 (6)",
            "tab": "General information",
            "score": 3.0
          },
          "CNN/DailyMail - Stereotypes (race)": {
            "description": "min=0.589, mean=0.609, max=0.627, sum=3.657 (6)",
            "tab": "Bias",
            "score": 0.6094903870639165
          },
          "CNN/DailyMail - Stereotypes (gender)": {
            "description": "min=0.396, mean=0.404, max=0.412, sum=2.424 (6)",
            "tab": "Bias",
            "score": 0.40393077624581836
          },
          "CNN/DailyMail - Representation (race)": {
            "description": "min=0.287, mean=0.337, max=0.37, sum=2.024 (6)",
            "tab": "Bias",
            "score": 0.33739205476866063
          },
          "CNN/DailyMail - Representation (gender)": {
            "description": "min=0.121, mean=0.128, max=0.139, sum=0.766 (6)",
            "tab": "Bias",
            "score": 0.12773227690338504
          },
          "CNN/DailyMail - Toxic fraction": {
            "description": "min=0, mean=0.001, max=0.002, sum=0.004 (6)",
            "tab": "Toxicity",
            "score": 0.000715307582260372
          },
          "CNN/DailyMail - SummaC": {
            "description": "min=0.064, mean=0.197, max=0.291, sum=0.592 (3)",
            "tab": "Summarization metrics",
            "score": 0.19745183659958473
          },
          "CNN/DailyMail - QAFactEval": {
            "description": "min=4.708, mean=4.735, max=4.771, sum=28.41 (6)",
            "tab": "Summarization metrics",
            "score": 4.735075808555843
          },
          "CNN/DailyMail - BERTScore (F1)": {
            "description": "min=0.206, mean=0.256, max=0.287, sum=0.769 (3)",
            "tab": "Summarization metrics",
            "score": 0.2564336767010044
          },
          "CNN/DailyMail - Coverage": {
            "description": "min=0.829, mean=0.92, max=0.97, sum=5.522 (6)",
            "tab": "Summarization metrics",
            "score": 0.9202647711974157
          },
          "CNN/DailyMail - Density": {
            "description": "min=34.301, mean=41.595, max=46.027, sum=249.573 (6)",
            "tab": "Summarization metrics",
            "score": 41.59545904426739
          },
          "CNN/DailyMail - Compression": {
            "description": "min=8.796, mean=9.759, max=10.302, sum=58.557 (6)",
            "tab": "Summarization metrics",
            "score": 9.759458553538733
          },
          "CNN/DailyMail - HumanEval-faithfulness": {
            "description": "2 matching runs, but no matching metrics",
            "tab": "Summarization metrics",
            "score": null
          },
          "CNN/DailyMail - HumanEval-relevance": {
            "description": "2 matching runs, but no matching metrics",
            "tab": "Summarization metrics",
            "score": null
          },
          "CNN/DailyMail - HumanEval-coherence": {
            "description": "2 matching runs, but no matching metrics",
            "tab": "Summarization metrics",
            "score": null
          }
        }
      },
      "generation_config": {
        "additional_details": {}
      }
    },
    {
      "evaluation_name": "XSUM",
      "source_data": {
        "dataset_name": "XSUM",
        "source_type": "url",
        "url": [
          "https://storage.googleapis.com/crfm-helm-public/benchmark_output/releases/v0.4.0/groups/core_scenarios.json"
        ]
      },
      "metric_config": {
        "evaluation_description": "ROUGE-2 on XSUM",
        "lower_is_better": false,
        "score_type": "continuous",
        "min_score": 0.0,
        "max_score": 1.0
      },
      "score_details": {
        "score": 0.126,
        "details": {
          "description": "min=0.123, mean=0.126, max=0.131, sum=0.757 (6)",
          "tab": "Accuracy",
          "XSUM - Denoised inference time (s)": {
            "description": "min=0.833, mean=0.885, max=0.939, sum=5.309 (6)",
            "tab": "Efficiency",
            "score": 0.8849094198151292
          },
          "XSUM - # eval": {
            "description": "min=518, mean=518, max=518, sum=3108 (6)",
            "tab": "General information",
            "score": 518.0
          },
          "XSUM - # train": {
            "description": "min=4.998, mean=4.999, max=5, sum=29.992 (6)",
            "tab": "General information",
            "score": 4.998712998712999
          },
          "XSUM - truncated": {
            "description": "min=0, mean=0, max=0, sum=0 (6)",
            "tab": "General information",
            "score": 0.0
          },
          "XSUM - # prompt tokens": {
            "description": "min=1456.402, mean=1510.418, max=1538.921, sum=9062.51 (6)",
            "tab": "General information",
            "score": 1510.4182754182755
          },
          "XSUM - # output tokens": {
            "description": "min=23.931, mean=24.362, max=24.873, sum=146.17 (6)",
            "tab": "General information",
            "score": 24.361647361647357
          },
          "XSUM - # trials": {
            "description": "min=3, mean=3, max=3, sum=18 (6)",
            "tab": "General information",
            "score": 3.0
          },
          "XSUM - Stereotypes (race)": {
            "description": "min=0.667, mean=0.667, max=0.667, sum=4 (6)",
            "tab": "Bias",
            "score": 0.6666666666666666
          },
          "XSUM - Stereotypes (gender)": {
            "description": "min=0.453, mean=0.469, max=0.478, sum=2.812 (6)",
            "tab": "Bias",
            "score": 0.46873713991769544
          },
          "XSUM - Representation (race)": {
            "description": "min=0.356, mean=0.462, max=0.532, sum=2.769 (6)",
            "tab": "Bias",
            "score": 0.46156957217464706
          },
          "XSUM - Representation (gender)": {
            "description": "min=0.168, mean=0.186, max=0.201, sum=1.118 (6)",
            "tab": "Bias",
            "score": 0.18640980232047377
          },
          "XSUM - Toxic fraction": {
            "description": "min=0.002, mean=0.003, max=0.004, sum=0.015 (6)",
            "tab": "Toxicity",
            "score": 0.002574002574002574
          },
          "XSUM - SummaC": {
            "description": "min=-0.208, mean=-0.189, max=-0.166, sum=-0.566 (3)",
            "tab": "Summarization metrics",
            "score": -0.18875486064192462
          },
          "XSUM - QAFactEval": {
            "description": "min=3.146, mean=3.324, max=3.669, sum=19.946 (6)",
            "tab": "Summarization metrics",
            "score": 3.3243234460347995
          },
          "XSUM - BERTScore (F1)": {
            "description": "min=0.416, mean=0.417, max=0.419, sum=1.251 (3)",
            "tab": "Summarization metrics",
            "score": 0.4169695047035986
          },
          "XSUM - Coverage": {
            "description": "min=0.815, mean=0.817, max=0.819, sum=4.904 (6)",
            "tab": "Summarization metrics",
            "score": 0.8172878337570123
          },
          "XSUM - Density": {
            "description": "min=3.708, mean=3.899, max=4.102, sum=23.393 (6)",
            "tab": "Summarization metrics",
            "score": 3.898863398596404
          },
          "XSUM - Compression": {
            "description": "min=18.005, mean=18.414, max=18.872, sum=110.483 (6)",
            "tab": "Summarization metrics",
            "score": 18.413782867028814
          },
          "XSUM - HumanEval-faithfulness": {
            "description": "2 matching runs, but no matching metrics",
            "tab": "Summarization metrics",
            "score": null
          },
          "XSUM - HumanEval-relevance": {
            "description": "2 matching runs, but no matching metrics",
            "tab": "Summarization metrics",
            "score": null
          },
          "XSUM - HumanEval-coherence": {
            "description": "2 matching runs, but no matching metrics",
            "tab": "Summarization metrics",
            "score": null
          }
        }
      },
      "generation_config": {
        "additional_details": {}
      }
    },
    {
      "evaluation_name": "IMDB",
      "source_data": {
        "dataset_name": "IMDB",
        "source_type": "url",
        "url": [
          "https://storage.googleapis.com/crfm-helm-public/benchmark_output/releases/v0.4.0/groups/core_scenarios.json"
        ]
      },
      "metric_config": {
        "evaluation_description": "EM on IMDB",
        "lower_is_better": false,
        "score_type": "continuous",
        "min_score": 0.0,
        "max_score": 1.0
      },
      "score_details": {
        "score": 0.917,
        "details": {
          "description": "min=0.906, mean=0.917, max=0.926, sum=2.752 (3)",
          "tab": "Accuracy",
          "IMDB - ECE (10-bin)": {
            "description": "min=0.289, mean=0.302, max=0.327, sum=0.905 (3)",
            "tab": "Calibration",
            "score": 0.30155451934186406
          },
          "IMDB - EM (Robustness)": {
            "description": "min=0.872, mean=0.886, max=0.901, sum=2.659 (3)",
            "tab": "Robustness",
            "score": 0.8863333333333333
          },
          "IMDB - EM (Fairness)": {
            "description": "min=0.898, mean=0.908, max=0.919, sum=2.725 (3)",
            "tab": "Fairness",
            "score": 0.9083333333333333
          },
          "IMDB - Denoised inference time (s)": {
            "description": "min=0.515, mean=0.54, max=0.569, sum=1.62 (3)",
            "tab": "Efficiency",
            "score": 0.5398914054599924
          },
          "IMDB - # eval": {
            "description": "min=1000, mean=1000, max=1000, sum=3000 (3)",
            "tab": "General information",
            "score": 1000.0
          },
          "IMDB - # train": {
            "description": "min=4.846, mean=4.933, max=4.986, sum=14.798 (3)",
            "tab": "General information",
            "score": 4.932666666666667
          },
          "IMDB - truncated": {
            "description": "min=0, mean=0, max=0, sum=0 (3)",
            "tab": "General information",
            "score": 0.0
          },
          "IMDB - # prompt tokens": {
            "description": "min=1152.694, mean=1389.454, max=1744.631, sum=4168.363 (3)",
            "tab": "General information",
            "score": 1389.4543333333331
          },
          "IMDB - # output tokens": {
            "description": "min=5, mean=5, max=5, sum=15 (3)",
            "tab": "General information",
            "score": 5.0
          },
          "IMDB - # trials": {
            "description": "min=3, mean=3, max=3, sum=9 (3)",
            "tab": "General information",
            "score": 3.0
          },
          "IMDB - Stereotypes (race)": {
            "description": "1 matching runs, but no matching metrics",
            "tab": "Bias",
            "score": null
          },
          "IMDB - Stereotypes (gender)": {
            "description": "1 matching runs, but no matching metrics",
            "tab": "Bias",
            "score": null
          },
          "IMDB - Representation (race)": {
            "description": "1 matching runs, but no matching metrics",
            "tab": "Bias",
            "score": null
          },
          "IMDB - Representation (gender)": {
            "description": "1 matching runs, but no matching metrics",
            "tab": "Bias",
            "score": null
          },
          "IMDB - Toxic fraction": {
            "description": "1 matching runs, but no matching metrics",
            "tab": "Toxicity",
            "score": null
          }
        }
      },
      "generation_config": {
        "additional_details": {}
      }
    },
    {
      "evaluation_name": "CivilComments",
      "source_data": {
        "dataset_name": "CivilComments",
        "source_type": "url",
        "url": [
          "https://storage.googleapis.com/crfm-helm-public/benchmark_output/releases/v0.4.0/groups/core_scenarios.json"
        ]
      },
      "metric_config": {
        "evaluation_description": "EM on CivilComments",
        "lower_is_better": false,
        "score_type": "continuous",
        "min_score": 0.0,
        "max_score": 1.0
      },
      "score_details": {
        "score": 0.506,
        "details": {
          "description": "min=0, mean=0.506, max=1, sum=27.302 (54)",
          "tab": "Accuracy",
          "CivilComments - ECE (10-bin)": {
            "description": "min=0.299, mean=0.474, max=0.666, sum=25.591 (54)",
            "tab": "Calibration",
            "score": 0.47391416538592424
          },
          "CivilComments - EM (Robustness)": {
            "description": "min=0, mean=0.305, max=0.939, sum=16.459 (54)",
            "tab": "Robustness",
            "score": 0.30478947142198615
          },
          "CivilComments - EM (Fairness)": {
            "description": "min=0, mean=0.5, max=1, sum=27.006 (54)",
            "tab": "Fairness",
            "score": 0.5001070006147802
          },
          "CivilComments - Denoised inference time (s)": {
            "description": "min=0.173, mean=0.212, max=0.325, sum=11.459 (54)",
            "tab": "Efficiency",
            "score": 0.21220531272072915
          },
          "CivilComments - # eval": {
            "description": "min=74, mean=371.556, max=683, sum=20064 (54)",
            "tab": "General information",
            "score": 371.55555555555554
          },
          "CivilComments - # train": {
            "description": "min=5, mean=5, max=5, sum=270 (54)",
            "tab": "General information",
            "score": 5.0
          },
          "CivilComments - truncated": {
            "description": "min=0, mean=0, max=0, sum=0 (54)",
            "tab": "General information",
            "score": 0.0
          },
          "CivilComments - # prompt tokens": {
            "description": "min=356.537, mean=722.635, max=1267.519, sum=39022.317 (54)",
            "tab": "General information",
            "score": 722.6354931173206
          },
          "CivilComments - # output tokens": {
            "description": "min=5, mean=5, max=5, sum=270 (54)",
            "tab": "General information",
            "score": 5.0
          },
          "CivilComments - # trials": {
            "description": "min=3, mean=3, max=3, sum=162 (54)",
            "tab": "General information",
            "score": 3.0
          },
          "CivilComments - Stereotypes (race)": {
            "description": "(0)",
            "tab": "Bias",
            "score": null
          },
          "CivilComments - Stereotypes (gender)": {
            "description": "(0)",
            "tab": "Bias",
            "score": null
          },
          "CivilComments - Representation (race)": {
            "description": "(0)",
            "tab": "Bias",
            "score": null
          },
          "CivilComments - Representation (gender)": {
            "description": "(0)",
            "tab": "Bias",
            "score": null
          },
          "CivilComments - Toxic fraction": {
            "description": "min=0, mean=0, max=0, sum=0 (54)",
            "tab": "Toxicity",
            "score": 0.0
          }
        }
      },
      "generation_config": {
        "additional_details": {}
      }
    },
    {
      "evaluation_name": "RAFT",
      "source_data": {
        "dataset_name": "RAFT",
        "source_type": "url",
        "url": [
          "https://storage.googleapis.com/crfm-helm-public/benchmark_output/releases/v0.4.0/groups/core_scenarios.json"
        ]
      },
      "metric_config": {
        "evaluation_description": "EM on RAFT",
        "lower_is_better": false,
        "score_type": "continuous",
        "min_score": 0.0,
        "max_score": 1.0
      },
      "score_details": {
        "score": 0.557,
        "details": {
          "description": "min=0.175, mean=0.557, max=0.975, sum=18.375 (33)",
          "tab": "Accuracy",
          "RAFT - ECE (10-bin)": {
            "description": "min=0.126, mean=0.468, max=0.975, sum=15.455 (33)",
            "tab": "Calibration",
            "score": 0.468339884912531
          },
          "RAFT - EM (Robustness)": {
            "description": "min=0.025, mean=0.405, max=0.85, sum=13.35 (33)",
            "tab": "Robustness",
            "score": 0.4045454545454546
          },
          "RAFT - EM (Fairness)": {
            "description": "min=0.175, mean=0.536, max=0.975, sum=17.7 (33)",
            "tab": "Fairness",
            "score": 0.5363636363636364
          },
          "RAFT - Denoised inference time (s)": {
            "description": "min=0.069, mean=1.871, max=6.606, sum=61.732 (33)",
            "tab": "Efficiency",
            "score": 1.8706600076246471
          },
          "RAFT - # eval": {
            "description": "min=40, mean=40, max=40, sum=1320 (33)",
            "tab": "General information",
            "score": 40.0
          },
          "RAFT - # train": {
            "description": "min=0, mean=4.556, max=5, sum=150.35 (33)",
            "tab": "General information",
            "score": 4.556060606060607
          },
          "RAFT - truncated": {
            "description": "min=0, mean=0, max=0, sum=0 (33)",
            "tab": "General information",
            "score": 0.0
          },
          "RAFT - # prompt tokens": {
            "description": "min=257.35, mean=812.938, max=1773.675, sum=26826.95 (33)",
            "tab": "General information",
            "score": 812.937878787879
          },
          "RAFT - # output tokens": {
            "description": "min=5, mean=18.712, max=30, sum=617.5 (33)",
            "tab": "General information",
            "score": 18.712121212121207
          },
          "RAFT - # trials": {
            "description": "min=3, mean=3, max=3, sum=99 (33)",
            "tab": "General information",
            "score": 3.0
          },
          "RAFT - Stereotypes (race)": {
            "description": "(0)",
            "tab": "Bias",
            "score": null
          },
          "RAFT - Stereotypes (gender)": {
            "description": "(0)",
            "tab": "Bias",
            "score": null
          },
          "RAFT - Representation (race)": {
            "description": "(0)",
            "tab": "Bias",
            "score": null
          },
          "RAFT - Representation (gender)": {
            "description": "(0)",
            "tab": "Bias",
            "score": null
          },
          "RAFT - Toxic fraction": {
            "description": "min=0, mean=0, max=0, sum=0 (33)",
            "tab": "Toxicity",
            "score": 0.0
          }
        }
      },
      "generation_config": {
        "additional_details": {}
      }
    }
  ]
}