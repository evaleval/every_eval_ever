{
  "schema_version": "0.2.0",
  "evaluation_id": "helm_classic/cohere_Cohere-xlarge-v20220609-52.4B/1770834891.1472661",
  "retrieved_timestamp": "1770834891.1472661",
  "source_metadata": {
    "source_name": "helm_classic",
    "source_type": "documentation",
    "source_organization_name": "crfm",
    "evaluator_relationship": "third_party"
  },
  "model_info": {
    "name": "Cohere xlarge v20220609 52.4B",
    "id": "cohere/Cohere-xlarge-v20220609-52.4B",
    "developer": "cohere",
    "inference_platform": "unknown"
  },
  "evaluation_results": [
    {
      "evaluation_name": "Mean win rate",
      "source_data": {
        "dataset_name": "helm_classic",
        "source_type": "url",
        "url": [
          "https://storage.googleapis.com/crfm-helm-public/benchmark_output/releases/v0.4.0/groups/core_scenarios.json"
        ]
      },
      "metric_config": {
        "evaluation_description": "How many models this model outperform on average (over columns).",
        "lower_is_better": false,
        "score_type": "continuous",
        "min_score": 0.0,
        "max_score": 1.0
      },
      "score_details": {
        "score": 0.56,
        "details": {
          "tab": "Accuracy",
          "Mean win rate - Calibration": {
            "description": null,
            "tab": "Calibration",
            "score": 0.5427202179052317
          },
          "Mean win rate - Robustness": {
            "description": null,
            "tab": "Robustness",
            "score": 0.5061059259613209
          },
          "Mean win rate - Fairness": {
            "description": null,
            "tab": "Fairness",
            "score": 0.5496737226436893
          },
          "Mean win rate - Efficiency": {
            "description": null,
            "tab": "Efficiency",
            "score": 0.1992872807017544
          },
          "Mean win rate - General information": {
            "description": null,
            "tab": "General information",
            "score": null
          },
          "Mean win rate - Bias": {
            "description": null,
            "tab": "Bias",
            "score": 0.5983741692925366
          },
          "Mean win rate - Toxicity": {
            "description": null,
            "tab": "Toxicity",
            "score": 0.5744286577619911
          },
          "Mean win rate - Summarization metrics": {
            "description": null,
            "tab": "Summarization metrics",
            "score": 0.546345029239766
          }
        }
      },
      "generation_config": {
        "additional_details": {}
      }
    },
    {
      "evaluation_name": "MMLU",
      "source_data": {
        "dataset_name": "MMLU",
        "source_type": "url",
        "url": [
          "https://storage.googleapis.com/crfm-helm-public/benchmark_output/releases/v0.4.0/groups/core_scenarios.json"
        ]
      },
      "metric_config": {
        "evaluation_description": "EM on MMLU",
        "lower_is_better": false,
        "score_type": "continuous",
        "min_score": 0.0,
        "max_score": 1.0
      },
      "score_details": {
        "score": 0.353,
        "details": {
          "description": "min=0.228, mean=0.353, max=0.56, sum=5.296 (15)",
          "tab": "Accuracy",
          "MMLU - ECE (10-bin)": {
            "description": "min=0.089, mean=0.149, max=0.246, sum=2.242 (15)",
            "tab": "Calibration",
            "score": 0.14945785718149934
          },
          "MMLU - EM (Robustness)": {
            "description": "min=0.158, mean=0.29, max=0.51, sum=4.349 (15)",
            "tab": "Robustness",
            "score": 0.28992982456140354
          },
          "MMLU - EM (Fairness)": {
            "description": "min=0.158, mean=0.315, max=0.53, sum=4.729 (15)",
            "tab": "Fairness",
            "score": 0.31526315789473686
          },
          "MMLU - Denoised inference time (s)": {
            "description": "min=0.47, mean=0.489, max=0.506, sum=7.328 (15)",
            "tab": "Efficiency",
            "score": 0.4885340888157895
          },
          "MMLU - # eval": {
            "description": "min=100, mean=102.8, max=114, sum=1542 (15)",
            "tab": "General information",
            "score": 102.8
          },
          "MMLU - # train": {
            "description": "min=5, mean=5, max=5, sum=75 (15)",
            "tab": "General information",
            "score": 5.0
          },
          "MMLU - truncated": {
            "description": "min=0, mean=0, max=0, sum=0 (15)",
            "tab": "General information",
            "score": 0.0
          },
          "MMLU - # prompt tokens": {
            "description": "min=372.75, mean=481.26, max=628.421, sum=7218.903 (15)",
            "tab": "General information",
            "score": 481.2602105263158
          },
          "MMLU - # output tokens": {
            "description": "min=1, mean=1, max=1, sum=15 (15)",
            "tab": "General information",
            "score": 1.0
          },
          "MMLU - # trials": {
            "description": "min=3, mean=3, max=3, sum=45 (15)",
            "tab": "General information",
            "score": 3.0
          }
        }
      },
      "generation_config": {
        "additional_details": {}
      }
    },
    {
      "evaluation_name": "BoolQ",
      "source_data": {
        "dataset_name": "BoolQ",
        "source_type": "url",
        "url": [
          "https://storage.googleapis.com/crfm-helm-public/benchmark_output/releases/v0.4.0/groups/core_scenarios.json"
        ]
      },
      "metric_config": {
        "evaluation_description": "EM on BoolQ",
        "lower_is_better": false,
        "score_type": "continuous",
        "min_score": 0.0,
        "max_score": 1.0
      },
      "score_details": {
        "score": 0.718,
        "details": {
          "description": "min=0.702, mean=0.718, max=0.74, sum=2.153 (3)",
          "tab": "Accuracy",
          "BoolQ - ECE (10-bin)": {
            "description": "min=0.037, mean=0.04, max=0.043, sum=0.119 (3)",
            "tab": "Calibration",
            "score": 0.039674216829776156
          },
          "BoolQ - EM (Robustness)": {
            "description": "min=0.601, mean=0.614, max=0.622, sum=1.842 (3)",
            "tab": "Robustness",
            "score": 0.614
          },
          "BoolQ - EM (Fairness)": {
            "description": "min=0.657, mean=0.667, max=0.681, sum=2 (3)",
            "tab": "Fairness",
            "score": 0.6666666666666666
          },
          "BoolQ - Denoised inference time (s)": {
            "description": "min=0.519, mean=0.598, max=0.705, sum=1.795 (3)",
            "tab": "Efficiency",
            "score": 0.5984045305989586
          },
          "BoolQ - # eval": {
            "description": "min=1000, mean=1000, max=1000, sum=3000 (3)",
            "tab": "General information",
            "score": 1000.0
          },
          "BoolQ - # train": {
            "description": "min=5, mean=5, max=5, sum=15 (3)",
            "tab": "General information",
            "score": 5.0
          },
          "BoolQ - truncated": {
            "description": "min=0, mean=0, max=0, sum=0 (3)",
            "tab": "General information",
            "score": 0.0
          },
          "BoolQ - # prompt tokens": {
            "description": "min=669.307, mean=925.307, max=1269.307, sum=2775.921 (3)",
            "tab": "General information",
            "score": 925.3070000000001
          },
          "BoolQ - # output tokens": {
            "description": "min=1, mean=1.001, max=1.004, sum=3.004 (3)",
            "tab": "General information",
            "score": 1.0013333333333334
          },
          "BoolQ - # trials": {
            "description": "min=3, mean=3, max=3, sum=9 (3)",
            "tab": "General information",
            "score": 3.0
          },
          "BoolQ - Stereotypes (race)": {
            "description": "(0)",
            "tab": "Bias",
            "score": null
          },
          "BoolQ - Stereotypes (gender)": {
            "description": "(0)",
            "tab": "Bias",
            "score": null
          },
          "BoolQ - Representation (race)": {
            "description": "(0)",
            "tab": "Bias",
            "score": null
          },
          "BoolQ - Representation (gender)": {
            "description": "(0)",
            "tab": "Bias",
            "score": null
          },
          "BoolQ - Toxic fraction": {
            "description": "min=0, mean=0, max=0, sum=0 (3)",
            "tab": "Toxicity",
            "score": 0.0
          }
        }
      },
      "generation_config": {
        "additional_details": {}
      }
    },
    {
      "evaluation_name": "NarrativeQA",
      "source_data": {
        "dataset_name": "NarrativeQA",
        "source_type": "url",
        "url": [
          "https://storage.googleapis.com/crfm-helm-public/benchmark_output/releases/v0.4.0/groups/core_scenarios.json"
        ]
      },
      "metric_config": {
        "evaluation_description": "F1 on NarrativeQA",
        "lower_is_better": false,
        "score_type": "continuous",
        "min_score": 0.0,
        "max_score": 1.0
      },
      "score_details": {
        "score": 0.65,
        "details": {
          "description": "min=0.593, mean=0.65, max=0.688, sum=1.95 (3)",
          "tab": "Accuracy",
          "NarrativeQA - ECE (10-bin)": {
            "description": "min=0.048, mean=0.062, max=0.079, sum=0.185 (3)",
            "tab": "Calibration",
            "score": 0.061654179655226814
          },
          "NarrativeQA - F1 (Robustness)": {
            "description": "min=0.331, mean=0.383, max=0.42, sum=1.148 (3)",
            "tab": "Robustness",
            "score": 0.38251983624053415
          },
          "NarrativeQA - F1 (Fairness)": {
            "description": "min=0.481, mean=0.548, max=0.591, sum=1.644 (3)",
            "tab": "Fairness",
            "score": 0.5478470147843514
          },
          "NarrativeQA - Denoised inference time (s)": {
            "description": "min=1.025, mean=1.062, max=1.132, sum=3.185 (3)",
            "tab": "Efficiency",
            "score": 1.061820745305164
          },
          "NarrativeQA - # eval": {
            "description": "min=355, mean=355, max=355, sum=1065 (3)",
            "tab": "General information",
            "score": 355.0
          },
          "NarrativeQA - # train": {
            "description": "min=0.958, mean=1.562, max=1.997, sum=4.687 (3)",
            "tab": "General information",
            "score": 1.5624413145539906
          },
          "NarrativeQA - truncated": {
            "description": "min=0, mean=0, max=0, sum=0 (3)",
            "tab": "General information",
            "score": 0.0
          },
          "NarrativeQA - # prompt tokens": {
            "description": "min=1601.997, mean=1634.99, max=1693.155, sum=4904.969 (3)",
            "tab": "General information",
            "score": 1634.9896713615024
          },
          "NarrativeQA - # output tokens": {
            "description": "min=5.794, mean=7.077, max=9.031, sum=21.231 (3)",
            "tab": "General information",
            "score": 7.07699530516432
          },
          "NarrativeQA - # trials": {
            "description": "min=3, mean=3, max=3, sum=9 (3)",
            "tab": "General information",
            "score": 3.0
          },
          "NarrativeQA - Stereotypes (race)": {
            "description": "(0)",
            "tab": "Bias",
            "score": null
          },
          "NarrativeQA - Stereotypes (gender)": {
            "description": "min=0.396, mean=0.454, max=0.5, sum=1.362 (3)",
            "tab": "Bias",
            "score": 0.4541666666666666
          },
          "NarrativeQA - Representation (race)": {
            "description": "min=0.333, mean=0.556, max=0.667, sum=1.667 (3)",
            "tab": "Bias",
            "score": 0.5555555555555557
          },
          "NarrativeQA - Representation (gender)": {
            "description": "min=0.204, mean=0.208, max=0.215, sum=0.624 (3)",
            "tab": "Bias",
            "score": 0.20801619481196945
          },
          "NarrativeQA - Toxic fraction": {
            "description": "min=0.011, mean=0.021, max=0.028, sum=0.062 (3)",
            "tab": "Toxicity",
            "score": 0.020657276995305163
          }
        }
      },
      "generation_config": {
        "additional_details": {}
      }
    },
    {
      "evaluation_name": "NaturalQuestions (open-book)",
      "source_data": {
        "dataset_name": "NaturalQuestions (open-book)",
        "source_type": "url",
        "url": [
          "https://storage.googleapis.com/crfm-helm-public/benchmark_output/releases/v0.4.0/groups/core_scenarios.json"
        ]
      },
      "metric_config": {
        "evaluation_description": "F1 on NaturalQuestions (open-book)",
        "lower_is_better": false,
        "score_type": "continuous",
        "min_score": 0.0,
        "max_score": 1.0
      },
      "score_details": {
        "score": 0.595,
        "details": {
          "description": "min=0.576, mean=0.595, max=0.607, sum=1.785 (3)",
          "tab": "Accuracy",
          "NaturalQuestions (closed-book) - ECE (10-bin)": {
            "description": "min=0.061, mean=0.068, max=0.073, sum=0.203 (3)",
            "tab": "Calibration",
            "score": 0.06770990173751885
          },
          "NaturalQuestions (open-book) - ECE (10-bin)": {
            "description": "min=0.075, mean=0.085, max=0.099, sum=0.254 (3)",
            "tab": "Calibration",
            "score": 0.08482055822987211
          },
          "NaturalQuestions (closed-book) - F1 (Robustness)": {
            "description": "min=0.233, mean=0.238, max=0.241, sum=0.713 (3)",
            "tab": "Robustness",
            "score": 0.23753663022529162
          },
          "NaturalQuestions (open-book) - F1 (Robustness)": {
            "description": "min=0.411, mean=0.471, max=0.518, sum=1.414 (3)",
            "tab": "Robustness",
            "score": 0.4713418135089589
          },
          "NaturalQuestions (closed-book) - F1 (Fairness)": {
            "description": "min=0.248, mean=0.255, max=0.259, sum=0.764 (3)",
            "tab": "Fairness",
            "score": 0.25466316487855734
          },
          "NaturalQuestions (open-book) - F1 (Fairness)": {
            "description": "min=0.521, mean=0.535, max=0.546, sum=1.604 (3)",
            "tab": "Fairness",
            "score": 0.5348225692810691
          },
          "NaturalQuestions (closed-book) - Denoised inference time (s)": {
            "description": "min=0.546, mean=0.565, max=0.586, sum=1.694 (3)",
            "tab": "Efficiency",
            "score": 0.5647122317708332
          },
          "NaturalQuestions (open-book) - Denoised inference time (s)": {
            "description": "min=0.95, mean=1.085, max=1.249, sum=3.256 (3)",
            "tab": "Efficiency",
            "score": 1.0851867500000003
          },
          "NaturalQuestions (closed-book) - # eval": {
            "description": "min=1000, mean=1000, max=1000, sum=3000 (3)",
            "tab": "General information",
            "score": 1000.0
          },
          "NaturalQuestions (closed-book) - # train": {
            "description": "min=5, mean=5, max=5, sum=15 (3)",
            "tab": "General information",
            "score": 5.0
          },
          "NaturalQuestions (closed-book) - truncated": {
            "description": "min=0, mean=0, max=0, sum=0 (3)",
            "tab": "General information",
            "score": 0.0
          },
          "NaturalQuestions (closed-book) - # prompt tokens": {
            "description": "min=109.191, mean=111.191, max=115.191, sum=333.573 (3)",
            "tab": "General information",
            "score": 111.19099999999999
          },
          "NaturalQuestions (closed-book) - # output tokens": {
            "description": "min=5.31, mean=5.844, max=6.407, sum=17.531 (3)",
            "tab": "General information",
            "score": 5.843666666666667
          },
          "NaturalQuestions (closed-book) - # trials": {
            "description": "min=3, mean=3, max=3, sum=9 (3)",
            "tab": "General information",
            "score": 3.0
          },
          "NaturalQuestions (open-book) - # eval": {
            "description": "min=1000, mean=1000, max=1000, sum=3000 (3)",
            "tab": "General information",
            "score": 1000.0
          },
          "NaturalQuestions (open-book) - # train": {
            "description": "min=4.538, mean=4.633, max=4.715, sum=13.899 (3)",
            "tab": "General information",
            "score": 4.633
          },
          "NaturalQuestions (open-book) - truncated": {
            "description": "min=0.039, mean=0.039, max=0.039, sum=0.117 (3)",
            "tab": "General information",
            "score": 0.039
          },
          "NaturalQuestions (open-book) - # prompt tokens": {
            "description": "min=1261.72, mean=1481.344, max=1608.455, sum=4444.032 (3)",
            "tab": "General information",
            "score": 1481.344
          },
          "NaturalQuestions (open-book) - # output tokens": {
            "description": "min=7.154, mean=8.834, max=11.932, sum=26.502 (3)",
            "tab": "General information",
            "score": 8.834
          },
          "NaturalQuestions (open-book) - # trials": {
            "description": "min=3, mean=3, max=3, sum=9 (3)",
            "tab": "General information",
            "score": 3.0
          },
          "NaturalQuestions (closed-book) - Stereotypes (race)": {
            "description": "(0)",
            "tab": "Bias",
            "score": null
          },
          "NaturalQuestions (closed-book) - Stereotypes (gender)": {
            "description": "(0)",
            "tab": "Bias",
            "score": null
          },
          "NaturalQuestions (closed-book) - Representation (race)": {
            "description": "min=0.382, mean=0.43, max=0.498, sum=1.291 (3)",
            "tab": "Bias",
            "score": 0.4304995528213292
          },
          "NaturalQuestions (closed-book) - Representation (gender)": {
            "description": "min=0.024, mean=0.094, max=0.18, sum=0.281 (3)",
            "tab": "Bias",
            "score": 0.09357753357753357
          },
          "NaturalQuestions (open-book) - Stereotypes (race)": {
            "description": "min=0.667, mean=0.667, max=0.667, sum=2 (3)",
            "tab": "Bias",
            "score": 0.6666666666666666
          },
          "NaturalQuestions (open-book) - Stereotypes (gender)": {
            "description": "min=0.332, mean=0.388, max=0.488, sum=1.163 (3)",
            "tab": "Bias",
            "score": 0.38769841269841265
          },
          "NaturalQuestions (open-book) - Representation (race)": {
            "description": "min=0.373, mean=0.409, max=0.446, sum=1.226 (3)",
            "tab": "Bias",
            "score": 0.40861462430089884
          },
          "NaturalQuestions (open-book) - Representation (gender)": {
            "description": "min=0.026, mean=0.051, max=0.066, sum=0.153 (3)",
            "tab": "Bias",
            "score": 0.051062717190300304
          },
          "NaturalQuestions (closed-book) - Toxic fraction": {
            "description": "min=0, mean=0, max=0, sum=0 (3)",
            "tab": "Toxicity",
            "score": 0.0
          },
          "NaturalQuestions (open-book) - Toxic fraction": {
            "description": "min=0, mean=0.001, max=0.001, sum=0.002 (3)",
            "tab": "Toxicity",
            "score": 0.0006666666666666666
          }
        }
      },
      "generation_config": {
        "additional_details": {}
      }
    },
    {
      "evaluation_name": "QuAC",
      "source_data": {
        "dataset_name": "QuAC",
        "source_type": "url",
        "url": [
          "https://storage.googleapis.com/crfm-helm-public/benchmark_output/releases/v0.4.0/groups/core_scenarios.json"
        ]
      },
      "metric_config": {
        "evaluation_description": "F1 on QuAC",
        "lower_is_better": false,
        "score_type": "continuous",
        "min_score": 0.0,
        "max_score": 1.0
      },
      "score_details": {
        "score": 0.361,
        "details": {
          "description": "min=0.355, mean=0.361, max=0.365, sum=1.082 (3)",
          "tab": "Accuracy",
          "QuAC - ECE (10-bin)": {
            "description": "min=0.066, mean=0.067, max=0.07, sum=0.201 (3)",
            "tab": "Calibration",
            "score": 0.06703451532890617
          },
          "QuAC - F1 (Robustness)": {
            "description": "min=0.214, mean=0.215, max=0.216, sum=0.646 (3)",
            "tab": "Robustness",
            "score": 0.2154779030326859
          },
          "QuAC - F1 (Fairness)": {
            "description": "min=0.274, mean=0.281, max=0.287, sum=0.844 (3)",
            "tab": "Fairness",
            "score": 0.2814055112322921
          },
          "QuAC - Denoised inference time (s)": {
            "description": "min=2.057, mean=2.089, max=2.151, sum=6.267 (3)",
            "tab": "Efficiency",
            "score": 2.0889632337239585
          },
          "QuAC - # eval": {
            "description": "min=1000, mean=1000, max=1000, sum=3000 (3)",
            "tab": "General information",
            "score": 1000.0
          },
          "QuAC - # train": {
            "description": "min=0.797, mean=0.881, max=0.969, sum=2.644 (3)",
            "tab": "General information",
            "score": 0.8813333333333334
          },
          "QuAC - truncated": {
            "description": "min=0.02, mean=0.02, max=0.02, sum=0.06 (3)",
            "tab": "General information",
            "score": 0.02
          },
          "QuAC - # prompt tokens": {
            "description": "min=1600.292, mean=1639.784, max=1661.675, sum=4919.353 (3)",
            "tab": "General information",
            "score": 1639.784333333333
          },
          "QuAC - # output tokens": {
            "description": "min=31.783, mean=32.717, max=34.585, sum=98.152 (3)",
            "tab": "General information",
            "score": 32.717333333333336
          },
          "QuAC - # trials": {
            "description": "min=3, mean=3, max=3, sum=9 (3)",
            "tab": "General information",
            "score": 3.0
          },
          "QuAC - Stereotypes (race)": {
            "description": "min=0.556, mean=0.582, max=0.6, sum=1.745 (3)",
            "tab": "Bias",
            "score": 0.5815402704291595
          },
          "QuAC - Stereotypes (gender)": {
            "description": "min=0.43, mean=0.438, max=0.449, sum=1.315 (3)",
            "tab": "Bias",
            "score": 0.4381760996205441
          },
          "QuAC - Representation (race)": {
            "description": "min=0.333, mean=0.344, max=0.355, sum=1.033 (3)",
            "tab": "Bias",
            "score": 0.3443830841027822
          },
          "QuAC - Representation (gender)": {
            "description": "min=0.223, mean=0.23, max=0.237, sum=0.691 (3)",
            "tab": "Bias",
            "score": 0.23033600244512342
          },
          "QuAC - Toxic fraction": {
            "description": "min=0.001, mean=0.002, max=0.003, sum=0.006 (3)",
            "tab": "Toxicity",
            "score": 0.002
          }
        }
      },
      "generation_config": {
        "additional_details": {}
      }
    },
    {
      "evaluation_name": "HellaSwag",
      "source_data": {
        "dataset_name": "HellaSwag",
        "source_type": "url",
        "url": [
          "https://storage.googleapis.com/crfm-helm-public/benchmark_output/releases/v0.4.0/groups/core_scenarios.json"
        ]
      },
      "metric_config": {
        "evaluation_description": "EM on HellaSwag",
        "lower_is_better": false,
        "score_type": "continuous",
        "min_score": 0.0,
        "max_score": 1.0
      },
      "score_details": {
        "score": 0.811,
        "details": {
          "description": "min=0.811, mean=0.811, max=0.811, sum=0.811 (1)",
          "tab": "Accuracy",
          "HellaSwag - ECE (10-bin)": {
            "description": "min=0.341, mean=0.341, max=0.341, sum=0.341 (1)",
            "tab": "Calibration",
            "score": 0.34142560211110756
          },
          "HellaSwag - EM (Robustness)": {
            "description": "min=0.759, mean=0.759, max=0.759, sum=0.759 (1)",
            "tab": "Robustness",
            "score": 0.759
          },
          "HellaSwag - EM (Fairness)": {
            "description": "min=0.66, mean=0.66, max=0.66, sum=0.66 (1)",
            "tab": "Fairness",
            "score": 0.66
          },
          "HellaSwag - Denoised inference time (s)": {
            "description": "min=0.359, mean=0.359, max=0.359, sum=0.359 (1)",
            "tab": "Efficiency",
            "score": 0.35889839843750027
          },
          "HellaSwag - # eval": {
            "description": "min=1000, mean=1000, max=1000, sum=1000 (1)",
            "tab": "General information",
            "score": 1000.0
          },
          "HellaSwag - # train": {
            "description": "min=0, mean=0, max=0, sum=0 (1)",
            "tab": "General information",
            "score": 0.0
          },
          "HellaSwag - truncated": {
            "description": "min=0, mean=0, max=0, sum=0 (1)",
            "tab": "General information",
            "score": 0.0
          },
          "HellaSwag - # prompt tokens": {
            "description": "min=88.855, mean=88.855, max=88.855, sum=88.855 (1)",
            "tab": "General information",
            "score": 88.855
          },
          "HellaSwag - # output tokens": {
            "description": "min=0, mean=0, max=0, sum=0 (1)",
            "tab": "General information",
            "score": 0.0
          },
          "HellaSwag - # trials": {
            "description": "min=1, mean=1, max=1, sum=1 (1)",
            "tab": "General information",
            "score": 1.0
          }
        }
      },
      "generation_config": {
        "additional_details": {}
      }
    },
    {
      "evaluation_name": "OpenbookQA",
      "source_data": {
        "dataset_name": "OpenbookQA",
        "source_type": "url",
        "url": [
          "https://storage.googleapis.com/crfm-helm-public/benchmark_output/releases/v0.4.0/groups/core_scenarios.json"
        ]
      },
      "metric_config": {
        "evaluation_description": "EM on OpenbookQA",
        "lower_is_better": false,
        "score_type": "continuous",
        "min_score": 0.0,
        "max_score": 1.0
      },
      "score_details": {
        "score": 0.55,
        "details": {
          "description": "min=0.55, mean=0.55, max=0.55, sum=0.55 (1)",
          "tab": "Accuracy",
          "OpenbookQA - ECE (10-bin)": {
            "description": "min=0.235, mean=0.235, max=0.235, sum=0.235 (1)",
            "tab": "Calibration",
            "score": 0.23470136403728084
          },
          "OpenbookQA - EM (Robustness)": {
            "description": "min=0.448, mean=0.448, max=0.448, sum=0.448 (1)",
            "tab": "Robustness",
            "score": 0.448
          },
          "OpenbookQA - EM (Fairness)": {
            "description": "min=0.47, mean=0.47, max=0.47, sum=0.47 (1)",
            "tab": "Fairness",
            "score": 0.47
          },
          "OpenbookQA - Denoised inference time (s)": {
            "description": "min=0.314, mean=0.314, max=0.314, sum=0.314 (1)",
            "tab": "Efficiency",
            "score": 0.3138882968749995
          },
          "OpenbookQA - # eval": {
            "description": "min=500, mean=500, max=500, sum=500 (1)",
            "tab": "General information",
            "score": 500.0
          },
          "OpenbookQA - # train": {
            "description": "min=0, mean=0, max=0, sum=0 (1)",
            "tab": "General information",
            "score": 0.0
          },
          "OpenbookQA - truncated": {
            "description": "min=0, mean=0, max=0, sum=0 (1)",
            "tab": "General information",
            "score": 0.0
          },
          "OpenbookQA - # prompt tokens": {
            "description": "min=5.358, mean=5.358, max=5.358, sum=5.358 (1)",
            "tab": "General information",
            "score": 5.358
          },
          "OpenbookQA - # output tokens": {
            "description": "min=0, mean=0, max=0, sum=0 (1)",
            "tab": "General information",
            "score": 0.0
          },
          "OpenbookQA - # trials": {
            "description": "min=1, mean=1, max=1, sum=1 (1)",
            "tab": "General information",
            "score": 1.0
          }
        }
      },
      "generation_config": {
        "additional_details": {}
      }
    },
    {
      "evaluation_name": "TruthfulQA",
      "source_data": {
        "dataset_name": "TruthfulQA",
        "source_type": "url",
        "url": [
          "https://storage.googleapis.com/crfm-helm-public/benchmark_output/releases/v0.4.0/groups/core_scenarios.json"
        ]
      },
      "metric_config": {
        "evaluation_description": "EM on TruthfulQA",
        "lower_is_better": false,
        "score_type": "continuous",
        "min_score": 0.0,
        "max_score": 1.0
      },
      "score_details": {
        "score": 0.198,
        "details": {
          "description": "min=0.177, mean=0.198, max=0.225, sum=0.593 (3)",
          "tab": "Accuracy",
          "TruthfulQA - ECE (10-bin)": {
            "description": "min=0.075, mean=0.099, max=0.119, sum=0.298 (3)",
            "tab": "Calibration",
            "score": 0.0994665665272844
          },
          "TruthfulQA - EM (Robustness)": {
            "description": "min=0.122, mean=0.151, max=0.182, sum=0.454 (3)",
            "tab": "Robustness",
            "score": 0.15137614678899083
          },
          "TruthfulQA - EM (Fairness)": {
            "description": "min=0.138, mean=0.156, max=0.182, sum=0.469 (3)",
            "tab": "Fairness",
            "score": 0.1564729867482161
          },
          "TruthfulQA - Denoised inference time (s)": {
            "description": "min=0.49, mean=0.501, max=0.506, sum=1.502 (3)",
            "tab": "Efficiency",
            "score": 0.50081436353211
          },
          "TruthfulQA - # eval": {
            "description": "min=654, mean=654, max=654, sum=1962 (3)",
            "tab": "General information",
            "score": 654.0
          },
          "TruthfulQA - # train": {
            "description": "min=5, mean=5, max=5, sum=15 (3)",
            "tab": "General information",
            "score": 5.0
          },
          "TruthfulQA - truncated": {
            "description": "min=0, mean=0, max=0, sum=0 (3)",
            "tab": "General information",
            "score": 0.0
          },
          "TruthfulQA - # prompt tokens": {
            "description": "min=505.315, mean=514.648, max=532.315, sum=1543.945 (3)",
            "tab": "General information",
            "score": 514.6483180428135
          },
          "TruthfulQA - # output tokens": {
            "description": "min=1, mean=1, max=1, sum=3 (3)",
            "tab": "General information",
            "score": 1.0
          },
          "TruthfulQA - # trials": {
            "description": "min=3, mean=3, max=3, sum=9 (3)",
            "tab": "General information",
            "score": 3.0
          }
        }
      },
      "generation_config": {
        "additional_details": {}
      }
    },
    {
      "evaluation_name": "MS MARCO (TREC)",
      "source_data": {
        "dataset_name": "MS MARCO (TREC)",
        "source_type": "url",
        "url": [
          "https://storage.googleapis.com/crfm-helm-public/benchmark_output/releases/v0.4.0/groups/core_scenarios.json"
        ]
      },
      "metric_config": {
        "evaluation_description": "NDCG@10 on MS MARCO (TREC)",
        "lower_is_better": false,
        "score_type": "continuous",
        "min_score": 0.0,
        "max_score": 1.0
      },
      "score_details": {
        "score": 0.459,
        "details": {
          "description": "min=0.429, mean=0.459, max=0.479, sum=1.378 (3)",
          "tab": "Accuracy",
          "MS MARCO (regular) - RR@10 (Robustness)": {
            "description": "min=0.191, mean=0.207, max=0.223, sum=0.622 (3)",
            "tab": "Robustness",
            "score": 0.20732857142857117
          },
          "MS MARCO (TREC) - NDCG@10 (Robustness)": {
            "description": "min=0.371, mean=0.397, max=0.414, sum=1.19 (3)",
            "tab": "Robustness",
            "score": 0.39663320695609633
          },
          "MS MARCO (regular) - RR@10 (Fairness)": {
            "description": "min=0.211, mean=0.233, max=0.251, sum=0.698 (3)",
            "tab": "Fairness",
            "score": 0.23262777777777743
          },
          "MS MARCO (TREC) - NDCG@10 (Fairness)": {
            "description": "min=0.394, mean=0.431, max=0.457, sum=1.292 (3)",
            "tab": "Fairness",
            "score": 0.4307144032412258
          },
          "MS MARCO (regular) - Denoised inference time (s)": {
            "description": "min=0.492, mean=0.499, max=0.504, sum=1.496 (3)",
            "tab": "Efficiency",
            "score": 0.4985355449218751
          },
          "MS MARCO (TREC) - Denoised inference time (s)": {
            "description": "min=0.487, mean=0.501, max=0.511, sum=1.504 (3)",
            "tab": "Efficiency",
            "score": 0.501260492369186
          },
          "MS MARCO (regular) - # eval": {
            "description": "min=1000, mean=1000, max=1000, sum=3000 (3)",
            "tab": "General information",
            "score": 1000.0
          },
          "MS MARCO (regular) - # train": {
            "description": "min=2, mean=2, max=2, sum=6 (3)",
            "tab": "General information",
            "score": 2.0
          },
          "MS MARCO (regular) - truncated": {
            "description": "min=0, mean=0, max=0, sum=0 (3)",
            "tab": "General information",
            "score": 0.0
          },
          "MS MARCO (regular) - # prompt tokens": {
            "description": "min=497.281, mean=536.614, max=583.281, sum=1609.843 (3)",
            "tab": "General information",
            "score": 536.6143333333333
          },
          "MS MARCO (regular) - # output tokens": {
            "description": "min=1, mean=1, max=1, sum=3 (3)",
            "tab": "General information",
            "score": 1.0
          },
          "MS MARCO (regular) - # trials": {
            "description": "min=3, mean=3, max=3, sum=9 (3)",
            "tab": "General information",
            "score": 3.0
          },
          "MS MARCO (TREC) - # eval": {
            "description": "min=43, mean=43, max=43, sum=129 (3)",
            "tab": "General information",
            "score": 43.0
          },
          "MS MARCO (TREC) - # train": {
            "description": "min=2, mean=2, max=2, sum=6 (3)",
            "tab": "General information",
            "score": 2.0
          },
          "MS MARCO (TREC) - truncated": {
            "description": "min=0, mean=0, max=0, sum=0 (3)",
            "tab": "General information",
            "score": 0.0
          },
          "MS MARCO (TREC) - # prompt tokens": {
            "description": "min=480.163, mean=519.496, max=566.163, sum=1558.488 (3)",
            "tab": "General information",
            "score": 519.4961240310078
          },
          "MS MARCO (TREC) - # output tokens": {
            "description": "min=1, mean=1, max=1, sum=3 (3)",
            "tab": "General information",
            "score": 1.0
          },
          "MS MARCO (TREC) - # trials": {
            "description": "min=3, mean=3, max=3, sum=9 (3)",
            "tab": "General information",
            "score": 3.0
          },
          "MS MARCO (regular) - Stereotypes (race)": {
            "description": "1 matching runs, but no matching metrics",
            "tab": "Bias",
            "score": null
          },
          "MS MARCO (regular) - Stereotypes (gender)": {
            "description": "1 matching runs, but no matching metrics",
            "tab": "Bias",
            "score": null
          },
          "MS MARCO (regular) - Representation (race)": {
            "description": "1 matching runs, but no matching metrics",
            "tab": "Bias",
            "score": null
          },
          "MS MARCO (regular) - Representation (gender)": {
            "description": "1 matching runs, but no matching metrics",
            "tab": "Bias",
            "score": null
          },
          "MS MARCO (TREC) - Stereotypes (race)": {
            "description": "1 matching runs, but no matching metrics",
            "tab": "Bias",
            "score": null
          },
          "MS MARCO (TREC) - Stereotypes (gender)": {
            "description": "1 matching runs, but no matching metrics",
            "tab": "Bias",
            "score": null
          },
          "MS MARCO (TREC) - Representation (race)": {
            "description": "1 matching runs, but no matching metrics",
            "tab": "Bias",
            "score": null
          },
          "MS MARCO (TREC) - Representation (gender)": {
            "description": "1 matching runs, but no matching metrics",
            "tab": "Bias",
            "score": null
          },
          "MS MARCO (regular) - Toxic fraction": {
            "description": "1 matching runs, but no matching metrics",
            "tab": "Toxicity",
            "score": null
          },
          "MS MARCO (TREC) - Toxic fraction": {
            "description": "1 matching runs, but no matching metrics",
            "tab": "Toxicity",
            "score": null
          }
        }
      },
      "generation_config": {
        "additional_details": {}
      }
    },
    {
      "evaluation_name": "CNN/DailyMail",
      "source_data": {
        "dataset_name": "CNN/DailyMail",
        "source_type": "url",
        "url": [
          "https://storage.googleapis.com/crfm-helm-public/benchmark_output/releases/v0.4.0/groups/core_scenarios.json"
        ]
      },
      "metric_config": {
        "evaluation_description": "ROUGE-2 on CNN/DailyMail",
        "lower_is_better": false,
        "score_type": "continuous",
        "min_score": 0.0,
        "max_score": 1.0
      },
      "score_details": {
        "score": 0.144,
        "details": {
          "description": "min=0.14, mean=0.144, max=0.146, sum=0.861 (6)",
          "tab": "Accuracy",
          "CNN/DailyMail - Denoised inference time (s)": {
            "description": "min=4.313, mean=4.337, max=4.381, sum=26.024 (6)",
            "tab": "Efficiency",
            "score": 4.3373758759723735
          },
          "CNN/DailyMail - # eval": {
            "description": "min=466, mean=466, max=466, sum=2796 (6)",
            "tab": "General information",
            "score": 466.0
          },
          "CNN/DailyMail - # train": {
            "description": "min=5, mean=5, max=5, sum=30 (6)",
            "tab": "General information",
            "score": 5.0
          },
          "CNN/DailyMail - truncated": {
            "description": "min=0, mean=0, max=0, sum=0 (6)",
            "tab": "General information",
            "score": 0.0
          },
          "CNN/DailyMail - # prompt tokens": {
            "description": "min=1555.036, mean=1575.036, max=1602.036, sum=9450.219 (6)",
            "tab": "General information",
            "score": 1575.0364806866953
          },
          "CNN/DailyMail - # output tokens": {
            "description": "min=88.871, mean=89.431, max=90.324, sum=536.588 (6)",
            "tab": "General information",
            "score": 89.43133047210301
          },
          "CNN/DailyMail - # trials": {
            "description": "min=3, mean=3, max=3, sum=18 (6)",
            "tab": "General information",
            "score": 3.0
          },
          "CNN/DailyMail - Stereotypes (race)": {
            "description": "min=0.616, mean=0.626, max=0.635, sum=3.753 (6)",
            "tab": "Bias",
            "score": 0.6255738197534654
          },
          "CNN/DailyMail - Stereotypes (gender)": {
            "description": "min=0.377, mean=0.387, max=0.397, sum=2.32 (6)",
            "tab": "Bias",
            "score": 0.38662344919565644
          },
          "CNN/DailyMail - Representation (race)": {
            "description": "min=0.244, mean=0.301, max=0.358, sum=1.808 (6)",
            "tab": "Bias",
            "score": 0.30129162776221596
          },
          "CNN/DailyMail - Representation (gender)": {
            "description": "min=0.104, mean=0.117, max=0.128, sum=0.7 (6)",
            "tab": "Bias",
            "score": 0.116591581511673
          },
          "CNN/DailyMail - Toxic fraction": {
            "description": "min=0, mean=0.002, max=0.004, sum=0.013 (6)",
            "tab": "Toxicity",
            "score": 0.002145922746781116
          },
          "CNN/DailyMail - SummaC": {
            "description": "min=0.393, mean=0.469, max=0.516, sum=1.407 (3)",
            "tab": "Summarization metrics",
            "score": 0.46891720389173397
          },
          "CNN/DailyMail - QAFactEval": {
            "description": "min=4.621, mean=4.683, max=4.752, sum=28.101 (6)",
            "tab": "Summarization metrics",
            "score": 4.683468662049275
          },
          "CNN/DailyMail - BERTScore (F1)": {
            "description": "min=0.257, mean=0.264, max=0.275, sum=0.792 (3)",
            "tab": "Summarization metrics",
            "score": 0.2639259716833397
          },
          "CNN/DailyMail - Coverage": {
            "description": "min=0.897, mean=0.945, max=0.971, sum=5.671 (6)",
            "tab": "Summarization metrics",
            "score": 0.945166441130516
          },
          "CNN/DailyMail - Density": {
            "description": "min=43.963, mean=49.713, max=55.846, sum=298.279 (6)",
            "tab": "Summarization metrics",
            "score": 49.713109703758754
          },
          "CNN/DailyMail - Compression": {
            "description": "min=8.816, mean=9.072, max=9.547, sum=54.43 (6)",
            "tab": "Summarization metrics",
            "score": 9.071669466217989
          },
          "CNN/DailyMail - HumanEval-faithfulness": {
            "description": "min=0.978, mean=0.993, max=1, sum=5.956 (6)",
            "tab": "Summarization metrics",
            "score": 0.9925925925925926
          },
          "CNN/DailyMail - HumanEval-relevance": {
            "description": "min=4.422, mean=4.539, max=4.667, sum=27.237 (6)",
            "tab": "Summarization metrics",
            "score": 4.5394335511982575
          },
          "CNN/DailyMail - HumanEval-coherence": {
            "description": "min=3.556, mean=3.69, max=3.81, sum=22.142 (6)",
            "tab": "Summarization metrics",
            "score": 3.6903205726735138
          }
        }
      },
      "generation_config": {
        "additional_details": {}
      }
    },
    {
      "evaluation_name": "XSUM",
      "source_data": {
        "dataset_name": "XSUM",
        "source_type": "url",
        "url": [
          "https://storage.googleapis.com/crfm-helm-public/benchmark_output/releases/v0.4.0/groups/core_scenarios.json"
        ]
      },
      "metric_config": {
        "evaluation_description": "ROUGE-2 on XSUM",
        "lower_is_better": false,
        "score_type": "continuous",
        "min_score": 0.0,
        "max_score": 1.0
      },
      "score_details": {
        "score": 0.129,
        "details": {
          "description": "min=0.125, mean=0.129, max=0.134, sum=0.775 (6)",
          "tab": "Accuracy",
          "XSUM - Denoised inference time (s)": {
            "description": "min=1.735, mean=1.741, max=1.747, sum=10.443 (6)",
            "tab": "Efficiency",
            "score": 1.7405486446267702
          },
          "XSUM - # eval": {
            "description": "min=518, mean=518, max=518, sum=3108 (6)",
            "tab": "General information",
            "score": 518.0
          },
          "XSUM - # train": {
            "description": "min=4.996, mean=4.998, max=5, sum=29.988 (6)",
            "tab": "General information",
            "score": 4.998069498069498
          },
          "XSUM - truncated": {
            "description": "min=0, mean=0, max=0, sum=0 (6)",
            "tab": "General information",
            "score": 0.0
          },
          "XSUM - # prompt tokens": {
            "description": "min=1484.608, mean=1537.452, max=1572.616, sum=9224.71 (6)",
            "tab": "General information",
            "score": 1537.4517374517375
          },
          "XSUM - # output tokens": {
            "description": "min=24.515, mean=24.802, max=25.066, sum=148.815 (6)",
            "tab": "General information",
            "score": 24.802445302445303
          },
          "XSUM - # trials": {
            "description": "min=3, mean=3, max=3, sum=18 (6)",
            "tab": "General information",
            "score": 3.0
          },
          "XSUM - Stereotypes (race)": {
            "description": "min=0.667, mean=0.667, max=0.667, sum=4 (6)",
            "tab": "Bias",
            "score": 0.6666666666666666
          },
          "XSUM - Stereotypes (gender)": {
            "description": "min=0.456, mean=0.463, max=0.468, sum=2.78 (6)",
            "tab": "Bias",
            "score": 0.4633319142897687
          },
          "XSUM - Representation (race)": {
            "description": "min=0.532, mean=0.622, max=0.667, sum=3.73 (6)",
            "tab": "Bias",
            "score": 0.6216216216216217
          },
          "XSUM - Representation (gender)": {
            "description": "min=0.184, mean=0.205, max=0.224, sum=1.231 (6)",
            "tab": "Bias",
            "score": 0.2051781150126976
          },
          "XSUM - Toxic fraction": {
            "description": "min=0, mean=0.001, max=0.002, sum=0.004 (6)",
            "tab": "Toxicity",
            "score": 0.0006435006435006435
          },
          "XSUM - SummaC": {
            "description": "min=-0.265, mean=-0.253, max=-0.236, sum=-0.758 (3)",
            "tab": "Summarization metrics",
            "score": -0.252571659198599
          },
          "XSUM - QAFactEval": {
            "description": "min=2.761, mean=2.981, max=3.213, sum=17.888 (6)",
            "tab": "Summarization metrics",
            "score": 2.981288283366219
          },
          "XSUM - BERTScore (F1)": {
            "description": "min=0.431, mean=0.434, max=0.438, sum=1.301 (3)",
            "tab": "Summarization metrics",
            "score": 0.4335328367301425
          },
          "XSUM - Coverage": {
            "description": "min=0.794, mean=0.8, max=0.803, sum=4.797 (6)",
            "tab": "Summarization metrics",
            "score": 0.7995514803953769
          },
          "XSUM - Density": {
            "description": "min=2.71, mean=2.945, max=3.142, sum=17.67 (6)",
            "tab": "Summarization metrics",
            "score": 2.945005615644467
          },
          "XSUM - Compression": {
            "description": "min=18.323, mean=18.422, max=18.574, sum=110.533 (6)",
            "tab": "Summarization metrics",
            "score": 18.422086618359014
          },
          "XSUM - HumanEval-faithfulness": {
            "description": "min=0.638, mean=0.661, max=0.697, sum=3.968 (6)",
            "tab": "Summarization metrics",
            "score": 0.6612578878025103
          },
          "XSUM - HumanEval-relevance": {
            "description": "min=4.212, mean=4.239, max=4.275, sum=25.431 (6)",
            "tab": "Summarization metrics",
            "score": 4.238517902133463
          },
          "XSUM - HumanEval-coherence": {
            "description": "min=4.773, mean=4.825, max=4.877, sum=28.952 (6)",
            "tab": "Summarization metrics",
            "score": 4.825335737235052
          }
        }
      },
      "generation_config": {
        "additional_details": {}
      }
    },
    {
      "evaluation_name": "IMDB",
      "source_data": {
        "dataset_name": "IMDB",
        "source_type": "url",
        "url": [
          "https://storage.googleapis.com/crfm-helm-public/benchmark_output/releases/v0.4.0/groups/core_scenarios.json"
        ]
      },
      "metric_config": {
        "evaluation_description": "EM on IMDB",
        "lower_is_better": false,
        "score_type": "continuous",
        "min_score": 0.0,
        "max_score": 1.0
      },
      "score_details": {
        "score": 0.956,
        "details": {
          "description": "min=0.941, mean=0.956, max=0.965, sum=2.867 (3)",
          "tab": "Accuracy",
          "IMDB - ECE (10-bin)": {
            "description": "min=0.05, mean=0.069, max=0.081, sum=0.206 (3)",
            "tab": "Calibration",
            "score": 0.06875792133691605
          },
          "IMDB - EM (Robustness)": {
            "description": "min=0.907, mean=0.923, max=0.933, sum=2.768 (3)",
            "tab": "Robustness",
            "score": 0.9226666666666667
          },
          "IMDB - EM (Fairness)": {
            "description": "min=0.93, mean=0.949, max=0.96, sum=2.846 (3)",
            "tab": "Fairness",
            "score": 0.9486666666666667
          },
          "IMDB - Denoised inference time (s)": {
            "description": "min=0.709, mean=0.796, max=0.865, sum=2.389 (3)",
            "tab": "Efficiency",
            "score": 0.7963252441406254
          },
          "IMDB - # eval": {
            "description": "min=1000, mean=1000, max=1000, sum=3000 (3)",
            "tab": "General information",
            "score": 1000.0
          },
          "IMDB - # train": {
            "description": "min=2.903, mean=4.229, max=4.983, sum=12.688 (3)",
            "tab": "General information",
            "score": 4.229333333333333
          },
          "IMDB - truncated": {
            "description": "min=0, mean=0, max=0, sum=0 (3)",
            "tab": "General information",
            "score": 0.0
          },
          "IMDB - # prompt tokens": {
            "description": "min=1283.038, mean=1562.808, max=1784.2, sum=4688.425 (3)",
            "tab": "General information",
            "score": 1562.8083333333334
          },
          "IMDB - # output tokens": {
            "description": "min=1, mean=1, max=1, sum=3 (3)",
            "tab": "General information",
            "score": 1.0
          },
          "IMDB - # trials": {
            "description": "min=3, mean=3, max=3, sum=9 (3)",
            "tab": "General information",
            "score": 3.0
          },
          "IMDB - Stereotypes (race)": {
            "description": "1 matching runs, but no matching metrics",
            "tab": "Bias",
            "score": null
          },
          "IMDB - Stereotypes (gender)": {
            "description": "1 matching runs, but no matching metrics",
            "tab": "Bias",
            "score": null
          },
          "IMDB - Representation (race)": {
            "description": "1 matching runs, but no matching metrics",
            "tab": "Bias",
            "score": null
          },
          "IMDB - Representation (gender)": {
            "description": "1 matching runs, but no matching metrics",
            "tab": "Bias",
            "score": null
          },
          "IMDB - Toxic fraction": {
            "description": "1 matching runs, but no matching metrics",
            "tab": "Toxicity",
            "score": null
          }
        }
      },
      "generation_config": {
        "additional_details": {}
      }
    },
    {
      "evaluation_name": "CivilComments",
      "source_data": {
        "dataset_name": "CivilComments",
        "source_type": "url",
        "url": [
          "https://storage.googleapis.com/crfm-helm-public/benchmark_output/releases/v0.4.0/groups/core_scenarios.json"
        ]
      },
      "metric_config": {
        "evaluation_description": "EM on CivilComments",
        "lower_is_better": false,
        "score_type": "continuous",
        "min_score": 0.0,
        "max_score": 1.0
      },
      "score_details": {
        "score": 0.532,
        "details": {
          "description": "min=0.001, mean=0.532, max=1, sum=28.726 (54)",
          "tab": "Accuracy",
          "CivilComments - ECE (10-bin)": {
            "description": "min=0.051, mean=0.327, max=0.708, sum=17.639 (54)",
            "tab": "Calibration",
            "score": 0.32664532725883244
          },
          "CivilComments - EM (Robustness)": {
            "description": "min=0, mean=0.32, max=0.817, sum=17.265 (54)",
            "tab": "Robustness",
            "score": 0.31971446667223646
          },
          "CivilComments - EM (Fairness)": {
            "description": "min=0.001, mean=0.479, max=1, sum=25.855 (54)",
            "tab": "Fairness",
            "score": 0.4787922217178853
          },
          "CivilComments - Denoised inference time (s)": {
            "description": "min=0.464, mean=0.546, max=0.711, sum=29.484 (54)",
            "tab": "Efficiency",
            "score": 0.5459943267746123
          },
          "CivilComments - # eval": {
            "description": "min=74, mean=371.556, max=683, sum=20064 (54)",
            "tab": "General information",
            "score": 371.55555555555554
          },
          "CivilComments - # train": {
            "description": "min=5, mean=5, max=5, sum=270 (54)",
            "tab": "General information",
            "score": 5.0
          },
          "CivilComments - truncated": {
            "description": "min=0, mean=0, max=0, sum=0 (54)",
            "tab": "General information",
            "score": 0.0
          },
          "CivilComments - # prompt tokens": {
            "description": "min=362.293, mean=732.514, max=1288.441, sum=39555.782 (54)",
            "tab": "General information",
            "score": 732.5144825548033
          },
          "CivilComments - # output tokens": {
            "description": "min=1, mean=1, max=1, sum=54 (54)",
            "tab": "General information",
            "score": 1.0
          },
          "CivilComments - # trials": {
            "description": "min=3, mean=3, max=3, sum=162 (54)",
            "tab": "General information",
            "score": 3.0
          },
          "CivilComments - Stereotypes (race)": {
            "description": "(0)",
            "tab": "Bias",
            "score": null
          },
          "CivilComments - Stereotypes (gender)": {
            "description": "(0)",
            "tab": "Bias",
            "score": null
          },
          "CivilComments - Representation (race)": {
            "description": "(0)",
            "tab": "Bias",
            "score": null
          },
          "CivilComments - Representation (gender)": {
            "description": "(0)",
            "tab": "Bias",
            "score": null
          },
          "CivilComments - Toxic fraction": {
            "description": "min=0, mean=0, max=0, sum=0 (54)",
            "tab": "Toxicity",
            "score": 0.0
          }
        }
      },
      "generation_config": {
        "additional_details": {}
      }
    },
    {
      "evaluation_name": "RAFT",
      "source_data": {
        "dataset_name": "RAFT",
        "source_type": "url",
        "url": [
          "https://storage.googleapis.com/crfm-helm-public/benchmark_output/releases/v0.4.0/groups/core_scenarios.json"
        ]
      },
      "metric_config": {
        "evaluation_description": "EM on RAFT",
        "lower_is_better": false,
        "score_type": "continuous",
        "min_score": 0.0,
        "max_score": 1.0
      },
      "score_details": {
        "score": 0.633,
        "details": {
          "description": "min=0.1, mean=0.633, max=0.95, sum=20.875 (33)",
          "tab": "Accuracy",
          "RAFT - ECE (10-bin)": {
            "description": "min=0.093, mean=0.274, max=0.825, sum=9.044 (33)",
            "tab": "Calibration",
            "score": 0.274053604040966
          },
          "RAFT - EM (Robustness)": {
            "description": "min=0, mean=0.563, max=0.925, sum=18.575 (33)",
            "tab": "Robustness",
            "score": 0.5628787878787879
          },
          "RAFT - EM (Fairness)": {
            "description": "min=0.05, mean=0.598, max=0.95, sum=19.75 (33)",
            "tab": "Fairness",
            "score": 0.5984848484848486
          },
          "RAFT - Denoised inference time (s)": {
            "description": "min=0.458, mean=0.667, max=0.987, sum=22.019 (33)",
            "tab": "Efficiency",
            "score": 0.6672338778409089
          },
          "RAFT - # eval": {
            "description": "min=40, mean=40, max=40, sum=1320 (33)",
            "tab": "General information",
            "score": 40.0
          },
          "RAFT - # train": {
            "description": "min=0, mean=4.557, max=5, sum=150.375 (33)",
            "tab": "General information",
            "score": 4.556818181818182
          },
          "RAFT - truncated": {
            "description": "min=0, mean=0, max=0, sum=0 (33)",
            "tab": "General information",
            "score": 0.0
          },
          "RAFT - # prompt tokens": {
            "description": "min=270.325, mean=814.446, max=1777.025, sum=26876.725 (33)",
            "tab": "General information",
            "score": 814.446212121212
          },
          "RAFT - # output tokens": {
            "description": "min=0.275, mean=3.051, max=5.95, sum=100.675 (33)",
            "tab": "General information",
            "score": 3.0507575757575767
          },
          "RAFT - # trials": {
            "description": "min=3, mean=3, max=3, sum=99 (33)",
            "tab": "General information",
            "score": 3.0
          },
          "RAFT - Stereotypes (race)": {
            "description": "(0)",
            "tab": "Bias",
            "score": null
          },
          "RAFT - Stereotypes (gender)": {
            "description": "(0)",
            "tab": "Bias",
            "score": null
          },
          "RAFT - Representation (race)": {
            "description": "(0)",
            "tab": "Bias",
            "score": null
          },
          "RAFT - Representation (gender)": {
            "description": "(0)",
            "tab": "Bias",
            "score": null
          },
          "RAFT - Toxic fraction": {
            "description": "min=0, mean=0, max=0, sum=0 (33)",
            "tab": "Toxicity",
            "score": 0.0
          }
        }
      },
      "generation_config": {
        "additional_details": {}
      }
    }
  ]
}