{
  "schema_version": "0.2.0",
  "evaluation_id": "global-mmlu-lite/anthropic_claude-3-7-sonnet-20250219/1770682039.8556428",
  "retrieved_timestamp": "1770682039.8556428",
  "source_metadata": {
    "source_name": "Global MMLU Lite",
    "source_type": "documentation",
    "source_organization_name": "Cohere Labs",
    "source_organization_url": "https://cohere.com",
    "evaluator_relationship": "third_party"
  },
  "model_info": {
    "name": "claude-3-7-sonnet-20250219",
    "id": "anthropic/claude-3-7-sonnet-20250219",
    "developer": "anthropic",
    "inference_platform": "unknown",
    "additional_details": {
      "display_name": "Claude 3.7 Sonnet"
    }
  },
  "evaluation_results": [
    {
      "evaluation_name": "Global MMLU Lite",
      "source_data": {
        "dataset_name": "global-mmlu-lite",
        "source_type": "url",
        "url": [
          "https://www.kaggle.com/datasets/cohere-labs/global-mmlu-lite"
        ]
      },
      "metric_config": {
        "evaluation_description": "Global MMLU Lite - Global MMLU Lite",
        "lower_is_better": false,
        "score_type": "continuous",
        "min_score": 0.0,
        "max_score": 1.0
      },
      "score_details": {
        "score": 0.8078
      }
    },
    {
      "evaluation_name": "Culturally Sensitive",
      "source_data": {
        "dataset_name": "global-mmlu-lite",
        "source_type": "url",
        "url": [
          "https://www.kaggle.com/datasets/cohere-labs/global-mmlu-lite"
        ]
      },
      "metric_config": {
        "evaluation_description": "Global MMLU Lite - Culturally Sensitive",
        "lower_is_better": false,
        "score_type": "continuous",
        "min_score": 0.0,
        "max_score": 1.0
      },
      "score_details": {
        "score": 0.7794
      }
    },
    {
      "evaluation_name": "Culturally Agnostic",
      "source_data": {
        "dataset_name": "global-mmlu-lite",
        "source_type": "url",
        "url": [
          "https://www.kaggle.com/datasets/cohere-labs/global-mmlu-lite"
        ]
      },
      "metric_config": {
        "evaluation_description": "Global MMLU Lite - Culturally Agnostic",
        "lower_is_better": false,
        "score_type": "continuous",
        "min_score": 0.0,
        "max_score": 1.0
      },
      "score_details": {
        "score": 0.8362
      }
    },
    {
      "evaluation_name": "Arabic",
      "source_data": {
        "dataset_name": "global-mmlu-lite",
        "source_type": "url",
        "url": [
          "https://www.kaggle.com/datasets/cohere-labs/global-mmlu-lite"
        ]
      },
      "metric_config": {
        "evaluation_description": "Global MMLU Lite - Arabic",
        "lower_is_better": false,
        "score_type": "continuous",
        "min_score": 0.0,
        "max_score": 1.0
      },
      "score_details": {
        "score": 0.7925,
        "details": {
          "confidence_interval": 0.039739901042451
        }
      }
    },
    {
      "evaluation_name": "English",
      "source_data": {
        "dataset_name": "global-mmlu-lite",
        "source_type": "url",
        "url": [
          "https://www.kaggle.com/datasets/cohere-labs/global-mmlu-lite"
        ]
      },
      "metric_config": {
        "evaluation_description": "Global MMLU Lite - English",
        "lower_is_better": false,
        "score_type": "continuous",
        "min_score": 0.0,
        "max_score": 1.0
      },
      "score_details": {
        "score": 0.7625,
        "details": {
          "confidence_interval": 0.0417032427788918
        }
      }
    },
    {
      "evaluation_name": "Bengali",
      "source_data": {
        "dataset_name": "global-mmlu-lite",
        "source_type": "url",
        "url": [
          "https://www.kaggle.com/datasets/cohere-labs/global-mmlu-lite"
        ]
      },
      "metric_config": {
        "evaluation_description": "Global MMLU Lite - Bengali",
        "lower_is_better": false,
        "score_type": "continuous",
        "min_score": 0.0,
        "max_score": 1.0
      },
      "score_details": {
        "score": 0.825,
        "details": {
          "confidence_interval": 0.0372360919417476
        }
      }
    },
    {
      "evaluation_name": "German",
      "source_data": {
        "dataset_name": "global-mmlu-lite",
        "source_type": "url",
        "url": [
          "https://www.kaggle.com/datasets/cohere-labs/global-mmlu-lite"
        ]
      },
      "metric_config": {
        "evaluation_description": "Global MMLU Lite - German",
        "lower_is_better": false,
        "score_type": "continuous",
        "min_score": 0.0,
        "max_score": 1.0
      },
      "score_details": {
        "score": 0.8125,
        "details": {
          "confidence_interval": 0.0382499098762049
        }
      }
    },
    {
      "evaluation_name": "French",
      "source_data": {
        "dataset_name": "global-mmlu-lite",
        "source_type": "url",
        "url": [
          "https://www.kaggle.com/datasets/cohere-labs/global-mmlu-lite"
        ]
      },
      "metric_config": {
        "evaluation_description": "Global MMLU Lite - French",
        "lower_is_better": false,
        "score_type": "continuous",
        "min_score": 0.0,
        "max_score": 1.0
      },
      "score_details": {
        "score": 0.7675,
        "details": {
          "confidence_interval": 0.0413969901513152
        }
      }
    },
    {
      "evaluation_name": "Hindi",
      "source_data": {
        "dataset_name": "global-mmlu-lite",
        "source_type": "url",
        "url": [
          "https://www.kaggle.com/datasets/cohere-labs/global-mmlu-lite"
        ]
      },
      "metric_config": {
        "evaluation_description": "Global MMLU Lite - Hindi",
        "lower_is_better": false,
        "score_type": "continuous",
        "min_score": 0.0,
        "max_score": 1.0
      },
      "score_details": {
        "score": 0.805,
        "details": {
          "confidence_interval": 0.0388269557903546
        }
      }
    },
    {
      "evaluation_name": "Indonesian",
      "source_data": {
        "dataset_name": "global-mmlu-lite",
        "source_type": "url",
        "url": [
          "https://www.kaggle.com/datasets/cohere-labs/global-mmlu-lite"
        ]
      },
      "metric_config": {
        "evaluation_description": "Global MMLU Lite - Indonesian",
        "lower_is_better": false,
        "score_type": "continuous",
        "min_score": 0.0,
        "max_score": 1.0
      },
      "score_details": {
        "score": 0.8175,
        "details": {
          "confidence_interval": 0.037852399096026
        }
      }
    },
    {
      "evaluation_name": "Italian",
      "source_data": {
        "dataset_name": "global-mmlu-lite",
        "source_type": "url",
        "url": [
          "https://www.kaggle.com/datasets/cohere-labs/global-mmlu-lite"
        ]
      },
      "metric_config": {
        "evaluation_description": "Global MMLU Lite - Italian",
        "lower_is_better": false,
        "score_type": "continuous",
        "min_score": 0.0,
        "max_score": 1.0
      },
      "score_details": {
        "score": 0.8225,
        "details": {
          "confidence_interval": 0.0374442578609762
        }
      }
    },
    {
      "evaluation_name": "Japanese",
      "source_data": {
        "dataset_name": "global-mmlu-lite",
        "source_type": "url",
        "url": [
          "https://www.kaggle.com/datasets/cohere-labs/global-mmlu-lite"
        ]
      },
      "metric_config": {
        "evaluation_description": "Global MMLU Lite - Japanese",
        "lower_is_better": false,
        "score_type": "continuous",
        "min_score": 0.0,
        "max_score": 1.0
      },
      "score_details": {
        "score": 0.8425,
        "details": {
          "confidence_interval": 0.0356979542967269
        }
      }
    },
    {
      "evaluation_name": "Korean",
      "source_data": {
        "dataset_name": "global-mmlu-lite",
        "source_type": "url",
        "url": [
          "https://www.kaggle.com/datasets/cohere-labs/global-mmlu-lite"
        ]
      },
      "metric_config": {
        "evaluation_description": "Global MMLU Lite - Korean",
        "lower_is_better": false,
        "score_type": "continuous",
        "min_score": 0.0,
        "max_score": 1.0
      },
      "score_details": {
        "score": 0.83,
        "details": {
          "confidence_interval": 0.036811337913744
        }
      }
    },
    {
      "evaluation_name": "Portuguese",
      "source_data": {
        "dataset_name": "global-mmlu-lite",
        "source_type": "url",
        "url": [
          "https://www.kaggle.com/datasets/cohere-labs/global-mmlu-lite"
        ]
      },
      "metric_config": {
        "evaluation_description": "Global MMLU Lite - Portuguese",
        "lower_is_better": false,
        "score_type": "continuous",
        "min_score": 0.0,
        "max_score": 1.0
      },
      "score_details": {
        "score": 0.77,
        "details": {
          "confidence_interval": 0.0412408279846843
        }
      }
    },
    {
      "evaluation_name": "Spanish",
      "source_data": {
        "dataset_name": "global-mmlu-lite",
        "source_type": "url",
        "url": [
          "https://www.kaggle.com/datasets/cohere-labs/global-mmlu-lite"
        ]
      },
      "metric_config": {
        "evaluation_description": "Global MMLU Lite - Spanish",
        "lower_is_better": false,
        "score_type": "continuous",
        "min_score": 0.0,
        "max_score": 1.0
      },
      "score_details": {
        "score": 0.8075,
        "details": {
          "confidence_interval": 0.0386371183112584
        }
      }
    },
    {
      "evaluation_name": "Swahili",
      "source_data": {
        "dataset_name": "global-mmlu-lite",
        "source_type": "url",
        "url": [
          "https://www.kaggle.com/datasets/cohere-labs/global-mmlu-lite"
        ]
      },
      "metric_config": {
        "evaluation_description": "Global MMLU Lite - Swahili",
        "lower_is_better": false,
        "score_type": "continuous",
        "min_score": 0.0,
        "max_score": 1.0
      },
      "score_details": {
        "score": 0.8125,
        "details": {
          "confidence_interval": 0.0382499098762049
        }
      }
    },
    {
      "evaluation_name": "Yoruba",
      "source_data": {
        "dataset_name": "global-mmlu-lite",
        "source_type": "url",
        "url": [
          "https://www.kaggle.com/datasets/cohere-labs/global-mmlu-lite"
        ]
      },
      "metric_config": {
        "evaluation_description": "Global MMLU Lite - Yoruba",
        "lower_is_better": false,
        "score_type": "continuous",
        "min_score": 0.0,
        "max_score": 1.0
      },
      "score_details": {
        "score": 0.81,
        "details": {
          "confidence_interval": 0.0384447822371523
        }
      }
    },
    {
      "evaluation_name": "Chinese",
      "source_data": {
        "dataset_name": "global-mmlu-lite",
        "source_type": "url",
        "url": [
          "https://www.kaggle.com/datasets/cohere-labs/global-mmlu-lite"
        ]
      },
      "metric_config": {
        "evaluation_description": "Global MMLU Lite - Chinese",
        "lower_is_better": false,
        "score_type": "continuous",
        "min_score": 0.0,
        "max_score": 1.0
      },
      "score_details": {
        "score": 0.835,
        "details": {
          "confidence_interval": 0.0363750253959063
        }
      }
    },
    {
      "evaluation_name": "Burmese",
      "source_data": {
        "dataset_name": "global-mmlu-lite",
        "source_type": "url",
        "url": [
          "https://www.kaggle.com/datasets/cohere-labs/global-mmlu-lite"
        ]
      },
      "metric_config": {
        "evaluation_description": "Global MMLU Lite - Burmese",
        "lower_is_better": false,
        "score_type": "continuous",
        "min_score": 0.0,
        "max_score": 1.0
      },
      "score_details": {
        "score": 0.8125,
        "details": {
          "confidence_interval": 0.0382499098762049
        }
      }
    }
  ]
}