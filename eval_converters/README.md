## Automatic Evaluation Log Converters
A collection of scripts to convert evaluation logs from local runs from evaluation frameworks (e.g., `Inspect AI` and `lm-eval-harness`). 

### Installation
- Install the required dependencies:

```bash
uv sync
```

### Inspect
`
The conversion script from `Inspect AI` to the unified schema can be run using `eval_converters/inspect/__main__.py`.

Using the `--log_path` argument, you can choose one of three ways to specify evaluations to convert:
- Provide an `Inspect AI` evaluation log with the `.eval` extension (e.g., `2026-02-07T11-26-57+00-00_gaia_4V8zHbbRKpU5Yv2BMoBcjE.eval`)
- Provide an `Inspect AI` evaluation log with the `.json` extension (e.g., `2026-02-07T11-26-57+00-00_gaia_4V8zHbbRKpU5Yv2BMoBcjE.json`)
- Provide a directory containing multiple `Inspect AI` evaluation logs

Exact command for converting example evaluation log is:

```bash
uv run python3 -m eval_converters.inspect --log_path tests/data/inspect/2026-02-07T11-26-57+00-00_gaia_4V8zHbbRKpU5Yv2BMoBcjE.json
```


Full manual for conversion of your own Inspect evaluation log into unified is available below:

```bash
usage: __main__.py [-h] [--log_path LOG_PATH] [--output_dir OUTPUT_DIR] [--source_organization_name SOURCE_ORGANIZATION_NAME]
                   [--evaluator_relationship {first_party,third_party,collaborative,other}] [--source_organization_url SOURCE_ORGANIZATION_URL]
                   [--source_organization_logo_url SOURCE_ORGANIZATION_LOGO_URL]

options:
  -h, --help            show this help message and exit
  --log_path LOG_PATH
  --output_dir OUTPUT_DIR
  --source_organization_name SOURCE_ORGANIZATION_NAME
                        Orgnization which pushed evaluation to the every-eval-ever.
  --evaluator_relationship {first_party,third_party,collaborative,other}
                        Relationship of evaluation author to the model
  --source_organization_url SOURCE_ORGANIZATION_URL
  --source_organization_logo_url SOURCE_ORGANIZATION_LOGO_URL
```

### HELM

You can convert HELM evaluation log into unified schema via `eval_converters/helm/__main__.py`. For example:

```bash
uv run python3 -m scripts.eval_converters.helm --log_path tests/data/helm
```

The automatic conversion script requires following files generated by HELM to work correctly:
- per_instance_stats.json
- run_spec.json
- scenario_state.json
- scenario.json
- stats.json

Full manual for conversion of your own HELM evaluation log into unified is available below:

```bash
usage: __main__.py [-h] [--log_path LOG_PATH] [--output_dir OUTPUT_DIR] [--source_organization_name SOURCE_ORGANIZATION_NAME] [--evaluator_relationship {first_party,third_party,collaborative,other}]
                   [--source_organization_url SOURCE_ORGANIZATION_URL] [--source_organization_logo_url SOURCE_ORGANIZATION_LOGO_URL]

options:
  -h, --help            show this help message and exit
  --log_path LOG_PATH   Path to directory with single evaluaion or multiple evaluations to convert
  --output_dir OUTPUT_DIR
  --source_organization_name SOURCE_ORGANIZATION_NAME
                        Orgnization which pushed evaluation to the evalHub.
  --evaluator_relationship {first_party,third_party,collaborative,other}
                        Relationship of evaluation author to the model
  --source_organization_url SOURCE_ORGANIZATION_URL
  --source_organization_logo_url SOURCE_ORGANIZATION_LOGO_URL
```